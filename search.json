[{"title":"Arm64麒麟V10安装Kata","url":"/2022/11/19/Arm64 麒麟V10安装Kata/","content":"\n# 前置条件检查是否支持虚拟化\n- 通过dmesg查看是否支持虚拟化，arm不同于x86，lscpu看不出来\n```\n# dmesg |grep kvm\n[    0.499391] kvm [1]: Hisi ncsnp: enabled\n[    0.499605] kvm [1]: 16-bit VMID\n[    0.499606] kvm [1]: IPA Size Limit: 48bits\n[    0.499644] kvm [1]: GICv4 support disabled\n[    0.499645] kvm [1]: vgic-v2@9b020000\n[    0.499647] kvm [1]: GIC system register CPU interface enabled\n[    0.500407] kvm [1]: vgic interrupt IRQ1\n[    0.501131] kvm [1]: VHE mode initialized successfully\n```\n- 如果是下面这样，就不用继续了，浪费时间\n```\n# dmesg |grep kvm\n[    0.136111] kvm [1]: HYP mode not available\n```\n- 注意：Arm架构不支持嵌套虚拟化，也就是说只能在物理机下运行kata，无法在虚拟机下运行\n\n\n# 下载&编译&安装\n\n## gcc (yum源7以上无需编译)\n- 编译qemu需要\n- 下载源码 \n```\nwget https://github.com/gcc-mirror/gcc/archive/refs/tags/releases/gcc-8.5.0.zip\n```\n- 解压后，检查依赖项\n```\n./contrib/download_prerequisites\n```\n- yum安装依赖\n```\n# yum -y install bzip2 gcc gcc-c++ gmp-devel mpfr-devel libmpc-devel make zlib-devel flex bison-devel\n```\n- 进入gcc8.5.0目录进行编译安装, make -j 后面的数字是编译的并行数，可适当调整\n```\n# mkdir build && cd build\n# ../configure --prefix=/opt/gcc-8.5.0 --enable-languages=c,c++ --disable-multilib\n# make -j8 && sudo make install\n```\n- 进行软链接,软链前删除/usr/bin/下的cc和c++\n```\n# ln -s  /opt/gcc-8.5.0/bin/gcc /usr/bin/cc\n# ln -s  /opt/gcc-8.5.0/bin/c++ /usr/bin/c++\n```\n\n## rust\n- 编译kata需要\n- 直接在线安装\n```\ncurl --proto '=https' --tlsv1.2 -sSf sh.rustup.rs | sh\n```\n## golang\n- 编译kata需要\n- 直接下载二进制\n```\nwget https://studygolang.com/dl/golang/go1.19.3.linux-arm64.tar.gz\n```\n- 解压后将bin目录添加至PATH即可\n\n\n## kata\n- 下载源码 \n```\ngit clone https://github.com/kata-containers/kata-containers.git\n```\n- 在kata-containers目录编译安装\n```\n$ pushd kata-containers/src/runtime\n$ make && sudo -E \"PATH=$PATH\" make install\n$ sudo mkdir -p /etc/kata-containers/\n$ sudo install -o root -g root -m 0640 /usr/share/defaults/kata-containers/configuration.toml /etc/kata-containers\n$ popd\n```\n\n## containerd\n- 直接下载对应的rpm包\n```\n# yum install \thttp://mirror.centos.org/altarch/7/extras/aarch64/Packages/container-selinux-2.107-1.el7_6.noarch.rpm\n# yum install \thttps://download.docker.com/linux/centos/7/aarch64/stable/Packages/containerd.io-1.5.11-3.1.el7.aarch64.rpm\n```\n\n\n## python3.7 （yum源3.7以上无需编译）\n- 编译re2c需要\n- 下载源码\n```\n# wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz\n```\n- 安装依赖\n```\n# yum install libffi-devel \n```\n\n- 解压并编译\n```\n# tar -zxvf Python-3.7.0.tgz\n# mv Python-3.7.0 /usr/local\n# rm -rf /usr/bin/python\n# cd /usr/local/Python-3.7.0/\n# ./configure\n# make\n# make install\n```\n\n\n## re2c \n- 编译ninja需要\n- 下载源码\n    ```\n    git clone https://github.com/skvadrik/re2c.git\n    ```\n- 安装依赖\n    ```\n    # yum install automake libtool gcc gcc-c++\n    ```\n- 编译安装,进入re2c目录\n    ```\n    # autoreconf -i -W all\n    # ./configure && make && make install\n    ```\n\n\n## ninja\n- 编译qemu需要\n- 下载源码\n```\ngit clone https://github.com/ninja-build/ninja.git\n```\n- 编译，进入ninja目录\n```\n./configure.py --bootstrap\n```\n- 将ninja拷贝至PATH\n```\nmv ninja /usr/bin/\n```\n## yq\n- 直接下载二进制就行\n```\nhttps://github.com/mikefarah/yq/releases\nhttps://github.com/mikefarah/yq/releases/download/v4.30.4/yq_darwin_arm64\n```\n\n## qemu\n- 可以通过tests脚本下载(是网络情况决定)\n- 提前下载源码,后续直接进行编译\n```\ngit clone https://gitlab.com/qemu-project/qemu.git\ngit clone https://gitlab.com/qemu-project/dtc.git\ngit clone https://gitlab.com/qemu-project/meson.git\nhttps://gitlab.com/qemu-project/keycodemapdb.git\n\n```\n- 这里采用kata-tests的脚本进行编译安装，具体见[<a href=\"#kata-tests\">kata-tests</a>]\n\n## <a id=\"kata-tests\">kata-tests</a>\n- 进入kata-containers目录,下载源码tests\n    ```\n    git clone https://github.com/kata-containers/tests.git\n    ```\n- 调整目录结构（方便执行install_qemu脚本）\n    ```\n    将kata-containers移动到/opt/kata/src/github.com/kata-containers\n\n    /opt/kata/src/github.com/kata-containers/\n        - tests\n        - kata-containers (软连接至当前目录ln -s /opt/kata/src/github.com/kata-containers kata-containers)\n        - 其他kata-containsers文件\n\n    ```\n\n    ```\n    将上面下载的qemu目录mv到/opt/kata/src/github.com/qemu\n    ```\n\n    ```\n    /opt/kata (下面的GOPATH)路径下增加bin目录\n    将yq二进制文件拷贝至bin目录下（跳过install_yq）\n    ```\n- 修改脚本(必须)\n    - 修改./kata-containers/tests/.ci/lib.sh, 增加如下\n    - ```export GOPATH=上面调整的目录，我这里是/opt/kata```\n- 修改脚本(可选，网速不好参考)\n    - ./kata-containers/tests/.ci/install_qemu.sh\n        - 方便调试增加```set -x```\n    - ./kata-containers/tests/.ci/lib.sh\n    - ./kata-containers/tests/.ci/aarch64/lib_install_qemu_aarch64.sh\n        - 如果上面已经移动了qemu目录,执行下面的注释，否则不用执行\n        - 注释掉```clone_qemu_repo```\n        - 注释掉 ```sudo -E git fetch```\n    - ./kata-containers/tools/packaging/scripts/configure-hypervisor.sh\n        - 如果提前clone了目录，增加如下，这样可以在config qemu的时候忽略子模块校验\n        ```        \n        qemu_options+=' --with-git-submodules=ignore'\n        ```\n\n- 执行安装\n```\n# ./kata-containers/tests/.ci/install_qemu.sh\n```\n\n## kata-agent(可选)\n- 需要跨平台编译组件，下载地址\n    - https://musl.cc/#binaries\n    - https://musl.cc/aarch64-linux-musl-native.tgz\n    - aarch64-linux-musl-native解压后，bin目录加到path中\n- 执行编译 \n    ```\n    make -C kata-containers/src/agent SECCOMP=no\n    ```\n\n\n## kernel (除非你有arm内核，否则还是需要编译)\n- 下载对应版本的内核并解压\n- 进入内核目录执行\n    ```make -j 8```\n- 编译完成后拷贝```./arch/arm64/boot/Image```至对应目录\n    - 可软链，默认```/usr/share/kata-containers/vmlinux.container```\n- 编译模块部分（需要内核开启模块，自己根据版本调整，如果guestImage需要使用则需要编译）\n    ```\n    修改makefile的EXTRAVERSION 适配自己的版本，然后执行编译\n    mkdir -p ../build/lib/modules/5.4.160-1.el7.aarch64\n    make modules -j64\n    make modules_install INSTALL_MOD_PATH=../build\n    ```\n\n## guest Image (同kernel，如果有则无需编译)\n- 进入kata-containers/tools/osbuilder/rootfs-builder/centos, 根据自己rootfs选择\n- copy kernel modules （按需）\n    ```\n    cp -r -d ${kernel}/../build/lib/modules/5.4.160-1.el7.aarch64/ lib/modules/5.4.160-1.el7.aarch64\n    ```\n- 修改 config.sh(主要将yum或者dnf源修改为适配aarch64的，如果使用官方无需修改)\n    ```\n    BASE_URL=\"https://mirrors.aliyun.com/centos/8-stream/BaseOS/aarch64/os/\"\n    ```\n- 增加rust加速config, 打到Docker镜像中\n    ```\n        [source.crates-io]\n        registry = \"https://github.com/rust-lang/crates.io-index\"\n        replace-with = 'ustc'\n        [source.ustc]\n        registry = \"git://mirrors.ustc.edu.cn/crates.io-index\"\n    ```\n- 修改Dockerfile(我这里rust加速，copy了config)\n    ```\n    增加\n    COPY config /root/.cargo/config\n    ```\n\n- 回到进入kata-containers/tools/osbuilder，执行编译(如果哪一步有超时，自己修改dns或者修改代理)\n    ```\n    make DISTRO=centos OS_VERSION=stream8 SECCOMP=no DEBUG=true USE_DOCKER=true AGENT_INIT=yes rootfs\n    make USE_DOCKER=true image-centos -j 16\n    ```\n- 拷贝编译好的Image(我这里是kata-containers-image-centos.img)\n\n    \n# 配置\n## kata\n-  /etc/kata-containers/configuration.toml   //过滤空行和注释后，我这里开启了debug模式\n    ```\n    [hypervisor.qemu]\n    path = \"/usr/bin/qemu-system-aarch64\"\n    kernel = \"/usr/share/kata-containers/vmlinux.container\"\n    image = \"/usr/share/kata-containers/kata-containers.img\"\n    machine_type = \"virt\"\n    enable_annotations = []\n    valid_hypervisor_paths = [\"/usr/bin/qemu-system-aarch64\"]\n    kernel_params = \" initcall_debug\"\n    firmware = \"\"\n    machine_accelerators=\"\"\n    cpu_features=\"pmu=off\"\n    default_vcpus = 1\n    default_maxvcpus = 1\n    default_bridges = 1\n    default_memory = 2048\n    disable_block_device_use = false\n    shared_fs = \"virtio-9p\"\n    virtio_fs_daemon = \"/usr/libexec/kata-qemu/virtiofsd\"\n    valid_virtio_fs_daemon_paths = [\"/usr/libexec/kata-qemu/virtiofsd\"]\n    virtio_fs_cache_size = 0\n    virtio_fs_extra_args = [\"--thread-pool-size=1\"]\n    virtio_fs_cache = \"auto\"\n    block_device_driver = \"virtio-blk\"\n    enable_iothreads = false\n    enable_vhost_user_store = false\n    vhost_user_store_path = \"/var/run/kata-containers/vhost-user\"\n    valid_vhost_user_store_paths = [\"/var/run/kata-containers/vhost-user\"]\n    valid_file_mem_backends = [\"\"]\n    pflashes = []\n    enable_debug = true\n    disable_image_nvdimm = true\n    valid_entropy_sources = [\"/dev/urandom\",\"/dev/random\",\"\"]\n    [factory]\n    [agent.kata]\n    enable_debug = true\n    enable_tracing = true\n    kernel_modules=[]\n    debug_console_enabled = true\n    [netmon]\n    path = \"/usr/libexec/kata-containers/kata-netmon\"\n    enable_debug = true\n    [runtime]\n    enable_debug = true\n    internetworking_model=\"tcfilter\"\n    disable_guest_seccomp=true\n    disable_selinux=false\n    sandbox_cgroup_only=false\n    sandbox_bind_mounts=[]\n    vfio_mode=\"guest-kernel\"\n    experimental=[]\n    [image]\n    ```\n\n\n\n## containerd\n- /etc/containerd/config.toml\n    ```\n    disabled_plugins = []\n\n    [debug]\n    #  address = \"/run/containerd/debug.sock\"\n    #  uid = 0\n    #  gid = 0\n    level = \"debug\" # 我这里为了debug观察用\n\n    [plugins]\n    [plugins.cri.cni]\n        conf_dir = \"/etc/cni/net.d\"\n    [plugins.linux]\n        shim_debug = true\n    [plugins.cri]\n        [plugins.cri.containerd]\n        [plugins.cri.containerd.runtimes]\n            [plugins.cri.containerd.runtimes.kata]\n            runtime_type = \"io.containerd.kata.v2\"\n            privileged_without_host_devices = true\n            [plugins.cri.containerd.runtimes.kata.options]\n            ConfigPath = \"/etc/kata-containers/configuration.toml\"   # 指定kata配置文件\n    ```\n\n## cni\n- /etc/containerd/config.toml\n    ```\n    {\n        \"cniVersion\": \"0.2.0\",\n        \"name\": \"mynet\",\n        \"type\": \"bridge\",\n        \"bridge\": \"cni0\",\n        \"isGateway\": true,\n        \"ipMasq\": true,\n        \"ipam\": {\n            \"type\": \"host-local\",\n            \"subnet\": \"172.19.0.0/24\",\n            \"routes\": [\n                { \"dst\": \"0.0.0.0/0\" }\n            ]\n        }\n    }\n    ```\n\n# 验证\n## check\n```\n# kata-runtime check\nINFO[0000] IOMMUPlatform is disabled by default.\nSystem is capable of running Kata Containers\nSystem can currently create Kata Containers\n```\n\n## 启动容器\n```\n$ sudo ctr image pull docker.io/library/busybox:latest\n$ sudo ctr run --cni --runtime io.containerd.run.kata.v2 -t --rm docker.io/library/busybox:latest hello sh\n```\n\n\n# Q&A 编译阶段\n\n## python\n1. ModuleNotFoundError: No module named '_ctypes'\n    ```\n    yum install libffi-devel \n    然后重新configure make make install\n    ```\n\n## gcc\n1. g++: 错误：gengtype-lex.c：没有那个文件或目录\n    ```\n    yum install flex\n    ```\n\n## qemu\n1. ERROR: glib-2.56 gthread-2.0 is required to compile QEMU\n    ```\n    yum install glib2-devel\n    ```\n2. ERROR: Dependency \"pixman-1\" not found, tried pkgconfig\n    ```\n    yum install pixman-devel\n    ```\n3. ERROR: Dependency \"libseccomp\" not found, tried pkgconfig\n    ```\n    yum install libseccomp-devel\n    ```\n4. ERROR: C header 'cap-ng.h' not found\n    ```\n    yum install libcap-ng-devel\n    ```\n5. ERROR: C shared or static library 'rados' not found\n    ```\n    yum install libcephfs-devel librbd-devel librados-devel\n    ```\n\n# Q&A 运行阶段\n\n1. ctr: failed to create shim: failed to launch qemu: exit status 1, error messages from qemu log: qemu-system-aarch64: -device nvdimm,id=nv0,memdev=mem0: memory hotplug is not enabled: missing acpi-ged device : unknown   \n   ```   \n   修改kata-container的configuration.toml\n   disable_image_nvdimm = true      \n   ```\n   ```\n   或者qemu应用下面补丁\n   https://patchwork.kernel.org/project/qemu-devel/cover/20181018143042.29588-1-eric.auger@redhat.com/\n   ```\n\n\n2. ctr: failed to create shim: Failed to Check if grpc server is working: rpc error: code = DeadlineExceeded desc = timed out connecting to vsock 2680247850:1024: unknown\n    ```\n    内核文件问题，参考上面内核文件编译\n    ```\n\n3. Err:Could not create the sandbox resource controller cgroups: cgroup mountpoint does not exist\n    ```\n    sudo mkdir /sys/fs/cgroup/systemd\n    sudo mount -t cgroup -o none,name=systemd cgroup /sys/fs/cgroup/systemd\n    ```","tags":["Qemu, Kata, Containerd, KVM, Arm64, 虚拟化"],"categories":["虚拟化, Kata, Arm64"]},{"title":"三年没写东西了，随便写点什么","url":"/2022/11/18/三年没写东西了，随便写点什么/","content":"## 回顾\n不知不觉三年过去了，也是这疫情闹了三年，也是高德呆着的三年。我的工作经历还比较简单，研究生毕业之后，传统企业2年，京东1年，高德3年，算是2年传统企业+4年互联网经验吧。自己上次写Blog还是三年前，那个时候应该还是我再京东那边各种准备面试的时候。在京东那段时间工作说忙吧，也能划水，天天比较多的事情就是开会，当时的领导一言不合拉我们到会议室一开会就是1-2小时，也确实挺磨人的。不过在京东的那一年，也算是初次接触了互联网行业吧，毕竟以前做的还是toB项目，也算是从这里进行了入门，Es也是这一年用的最多的时候了，Java的知识，jvm什么的，也是这个时候逐渐开始尝试在项目中使用吧，然后就是在这里真真正正的体会到数据结构的作用。我们的一个搜索项目，调整数据结构之后搜索的rt从800+ms降低到50ms，真真正正的就是靠数据结构的优化。\n\n离开了京东，来到了高德，也可以说是阿里吧，算是真真正正的在互联网呆了3年，也真的是成长最快的3年了。在这边很幸运，开始遇到了好老大，对我也比较认可，项目什么的，我也一点点逐步自己扛起来。在这边切切实实的感觉到Java那些参数，数据结构的选择，超时，索引等各种设计的重要性，当你的应用只有几十QPS的时候，其实只要能用就行，也不会出什么大问题，但是如果你的应用动不动就是成千上万的请求量，那就是对数据结构对算法的一个真正的考核了，也是到了这里我才明白大学让我们学习数据结构的重要性。\n\n高德3年，在经历了一次晋升失败之后，今年成功晋升到技术专家。但是自己的身体状况也是每况愈下，明显感觉到自己的身体一天不如一天，加上老婆也怀孕了，自己也就选择了离开，为了照顾老婆以及即将出生的孩子，我选择了去国企，主要是为了稳定。经历京东的毕业，阿里的滚动式裁员，虽然都没有轮到自己，但是还是很后怕，互联网就是青春饭，熬上个几年能扯出来就撤出来吧。\n\n## 工作及规划\n\n当过技术负责人，当过业务组组长，觉得自己还是不喜欢做管理，后来找工作的时候，还是找偏向技术一点的国企，就是为了不放下技术，而且这次也是去了一个全新的领域，基本上全都是从0开始学习，刚开始的时候确实有压力，尤其是最近弄容器适配这块，屡屡没有成效，让自己的信心收到了打击，自己都感觉有点抑郁了，不过还好，后面各种尝试后，问题算是解决了。\n\n技术栈这块想想自己每次换工作也是换一个领域，从做数据ETL到做搜索项目，到做业务项目，到做Iaas层应用，每次换完工作基本都是从0开始，不过也觉得这一路走来收获颇丰，后面还是继续保持学习。\n\n## 学习\n\n说到学习，回想一下最近3年，好像看过的书，都不到10本吧，还多是什么半小时漫画之类的，想想自己在京东那一年下去，自己看过的书都有几十本了，后面还是继续保持看书的习惯吧，毕竟自己现在工作不像在互联网那会了，多少有点自己的时间了。\n\n## 以后\n\n稀里糊涂写了一堆，大概就是自己这几年互联网到逃离互联网的感想吧，也没什么思路什么的，就想到什么写什么，后面还是继续更新一些自己学习总结什么的。\n现在业务上自己主方向换了，java基本上逐渐用不上了，后面语言主要应该是go+rust吧，自己瞎捣鼓可能还会用python之类的，其他的可能主要研究虚拟化或者容器相关内容了，唉，随着工作业务方向走吧，就先写这么多。","tags":["随笔"],"categories":["随笔"]},{"title":"Java Thread 的状态","url":"/2019/08/18/JavaThread的状态/","content":"\n# 概述\nJava中线程的状态(也可以理解为生命周期)，主要有以下几种：NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED 。\n这些状态存在于Thread类中的一个枚举中如下：\n```\npublic enum State {\n        NEW,\n        RUNNABLE,\n        BLOCKED,\n        WAITING,\n        TIMED_WAITING,\n        TERMINATED;\n    }\n```\n\n# 具体状态\n\n## NEW\n- JDK原生的注释说的是一个还没有开始(started)的线程, 也就是说当new了一个线程之后，并没有调用start方法的时候，线程的状态就是NEW。\n\n## RUNNABLE\n- 这个状态代表线程处于一个可运行的状态，但是不一定会执行，因为要考虑cpu核心数等影响，直到CPU时间分片给到当前线程，才会真正的执行。\n\n## BLOCKED\n- 阻塞状态，通常都是在等待获取某个监视器的锁的时候会处于当前状态。\n- 已知：\n    - 等待synchronized获取监视器对象锁的时候，线程的状态为：BLOCKED (on object monitor)\n    - 线程从WAITING/TIMED_WAITING(object.wait()方法)状态唤醒后，因为需要重新获取synchronized监视器对象，会先进入BLOCKED状态，待获取了监视器对象锁后，变为RUNNABLE状态。\n\n## WAITING\n- 等待状态，一般是由于调用了如下方法而进入等待状态：\n    - Object#wait()\n    - Thread#join()\n    - LockSupport#park()\n- 线程进入WAITING状态后，等待其他线程调用对应的通知对象才会唤醒。比如：\n    - Object.notify()\n    - Object.notifyAll()    \n\n## TIMED_WAITING\n- 一样是等待状态，但是区别是带有一个超时时间，超过这个时间后，线程会被自动唤醒。以下几个方法会进入该状态：\n    - Thread.sleep(long)\n    - Object#wait(long)\n    - Thread#join(long)\n    - LockSupport#parkNanos(long)\n    - LockSupport#parkUntil(long)\n\n## TERMINATED\n- 线程的终止状态，也就是当前线程已经执行完成。\n\n# 状态转换\n- 这个网上图片已经一大把了，有一张图看着简单明了，我就直接引用了：\n    - (原地址：https://blog.csdn.net/shi2huang/article/details/80289155)\n- ![线程转换图](JavaThread的状态/20180512102914671.png)\n\n# 关于释放资源方面\n## 锁的释放\n- 通过synchronized获取监视器对象锁之后，有如下几个方式会释放锁资源：\n    - 方法或者代码块正常执行完成\n    - 方法或者代码块抛出异常，代码终止执行\n    - 调用监视器对象的wait方法，会释放锁资源\n- 补充：\n    - 调用Thread.sleep方法不会释放锁资源\n\n## CPU资源的释放\n    - Thread.sleep()，会释放CPU资源，但是不会释放锁。\n    - Thread.yield()，会尝试放弃CPU资源，但是不会释放锁。（可能放弃后又立即获取到）\n    - 还有suspend()方法，由于已经过时，不再解释。\n\n# 其他\n\n## obj.notify/notifyAll区别\n- notify会随机唤醒监视obj的一个线程，具体是哪个无法指定，由JVM确定。\n- notifyAll会唤醒所有监视obj的线程，然后重新去竞争，只有一个可以获取到资源。\n\n## wait/sleep/yield区别\n- sleep()方法会释放CPU资源但是不会释放锁资源。\n- wait()方法会释放CPU资源和锁资源。\n- yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。\n\n## 虚假唤醒\n- 就是在没有调用obj.notify/notifyAll的前提下，obj.wait被唤醒了。\n- 等待线程即使没有收到正确的信号，也能够执行后续的操作，这就可能影响程序执行的正常逻辑。\n- 为了防止假唤醒，保存信号的成员变量将在一个while循环里接受检查，而不是在if表达式里。\n- 示例如下：\n```\nclass Sign {\n    private final Object obj = new Object();\n    private boolean flag = false;\n\n    public void doWait() throws InterruptedException {\n        synchronized (obj) {\n            while (!flag) {\n                obj.wait();\n            }\n            flag = false;\n        }\n    }\n    public void doNotify() {\n        synchronized (obj) {\n            flag = true;\n            obj.notifyAll();\n        }\n    }\n}\n```\n\n## RUNNABLE状态\n- Java中没有线程所谓的RUNNING和READY状态，这两个状态合并到一起，为RUNNABLE状态。\n- 也就是说即使线程处于RUNNABLE状态，也不一定就正在执行，可能正在等待CPU时间分片。","tags":["Java","Thread","State"],"categories":["Java"]},{"title":"Redis AOF Vs RDB","url":"/2019/08/18/Redis AOF Vs RDB/","content":"\n# 概述\n\nRedis持久化主要有2种方式，一种是基于内存快照的RDB格式，另外一种是基于操作日志的AOF格式，下面简单整理一下相关知识点。\n\n# RDB\n- RDB是基于内存快照的方式对Redis数据进行持久化，方式有两种，一种是自动触发，一种是手动触发。\n- 对于生成的RDB文件，Redis默认采用LZF算法进行压缩，然后进行网络传输。\n\n## 手动触发\n- 方式1:执行save命令\n    - 优点：整体执行时间快\n    - 缺点：执行过程中，阻塞Redis相关操作\n- 方式2:执行bgsave命令\n    - fork一个子进程，RDB持久化过程由子进程负责，整个过程中只有fork阶段是阻塞的。\n    - 优点：阻塞Redis相关操作时间较短\n    - 缺点：整体执行时间较长\n\n## 自动触发\n- 配置文件中配置了：m秒内执行的n次修改，则触发bgsave \n```\nsave m n\n```\n- 新加入从节点，需要复制主节点全部数据，则触发bgsave生成RDB文件，提供给从节点恢复数据\n- 执行shutdown命令时，如果没有配置AOF，则触发bgsave生成RDB文件，下次启动时进行恢复。\n\n## 优缺点\n- 优点\n    - RDB文件是一个经过压缩的二进制文件，非常适合全量备份，全量复制等场景。\n    - Redis加载并恢复RDB文件速度非常快，远超过AOF方式。\n- 缺点\n    - 创建RDB文件多少需要导致Redis停顿(无论save还是bgsave)，所以不适合实时生成，无法实时备份\n    - 不同版本的Redis可能无法互相兼容\n    - 如果最后一次备份RDB时候down机，数据可能丢失，数据完整性无法得到保障。\n\n# AOF\n- AOF实际上是Append Only File的缩写，该方式会生成一个独立的日志文件，记录每次的写入的命令。恢复的时候则重新执行AOF文件中的每一条命令。\n- 如果需要开启AOF格式，需要修改Redis配置文件,这个配置默认是不开启的:\n```\nappendonly yes\n```\n\n- 重写触发配置如下：\n```\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 500mb\n```\n- AOF执行分4个阶段：\n    - 命令写入（append）：将所有命令追加到缓冲区中\n    - 文件同步（sync）：将缓冲区中的数据同步落盘\n    - 文件重写（rewrite）：定期对AOF文件进行重写操作，主要是进行压缩(比如插入后又删除，这种数据直接从aof中移除)。\n    - 重启加载（load）：读取aof文件，并重写加载数据\n\n## 优缺点\n- 优点\n    - 提供多种同步策略：\n        - 每秒同步（一般推荐使用这个）\n        - 每次修改同步（效率较低，但是数据可靠）\n        - 不同步\n    - 适合数据完整性要求较高场景    \n- 缺点\n    - 随着追加数据越来越多，AOF越来越大。\n    - 数据恢复过程较慢。\n    - 通常同等情况下，AOF文件大于RDB文件大小。\n\n# 其他\n- 其实目前生产环境中很少有只是使用其中一种模式的，往往都是两种模式开启，作为互补使用。\n- 对于一些特殊场景，比如只是用来做缓存，则可以关闭持久化，以提升性能。\n\n","tags":["AOF","RDB","Redis"],"categories":["Redis"]},{"title":"MySQL学习笔记-MySQL大促销实战","url":"/2019/08/04/MySQL/","content":"\n## 监控信息\n\n### QPS&TPS\n\n### 并发量&CPU使用率\n\n### 磁盘IO\n\n## 大促销\n\n### 问题\n\n- 超高的QPS和TPS\n\n\t- 风险：低下效率的查询\n\n- 大量的并发和超高的CPU使用率\n\n\t- 大量的并发\n\n\t\t- 数据库连接数被占满\n\n\t- 超高的CPU使用率\n\n\t\t- 因为CPU资源耗尽出现宕机\n\n- 磁盘IO\n\n\t- 磁盘IO性能突然下降（使用更快的磁盘设备）\n\t- 其他大量消耗磁盘性能的计划任务\n\n- 网卡IO\n\n\t- 网卡IO被沾满\n\n\t\t- 减少从服务器数量\n\t\t- 进行分级缓存\n\t\t- 避免使用select * 查询\n\t\t- 分离业务网络和服务器网络\n\n### 影响数据库性能因素\n\n- SQL查询速度\n- 网卡浏览\n- 服务器应急\n- 磁盘IO\n\n## 大表带来的问题\n\n### 超过千万行或者10G\n\n### 查询影响\n\n- 慢查询：很难在一定时间内过滤出所需要的数据\n\n### DDL影响\n\n- 建立索引需要很长的时间\n\n\t- >5.5版本，引起主从延迟\n\n- 修改表结构需要长时间锁表\n\n\t- 造成长时间的主从延迟\n\t- 影响正常的数据操作\n\n### 处理大表\n\n- 分库分表\n\n\t- 分表主键选择\n\t- 分表跨分区数据查询统计\n\n- 历史数据归档\n\n\t- 归档时间点的选择\n\t- 如何进行归档操作\n\n## 大事务带来的问题\n\n### 什么是事务\n\n- 原子性\n- 一致性\n- 隔离性\n\n\t- 未提交读\n\t- 已提交读\n\t- 可重读\n\t- 串行化\n\n- 持久性\n\n### 大事务\n\n- 运行时间比较长，操作的数据比较多的事务\n\n\t- 锁定数据太多，大量阻塞和锁超时\n\t- 回滚所需时间较长\n\t- 执行时间长，容易造成主从延迟\n\n### 如何处理\n\n- 避免一次处理太多数据\n- 移除不必要在事务中的查询\n\n# 附Xmind\n![MySQL大促销实战](MySQL/MySQL.png)","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL学习笔记-MySQL基准测试","url":"/2019/08/03/MySQL基准测试/","content":"\n## 基准测试\n\n### 基准测试：直接简单易于比较，用于评估服务器的处理能力\n\n### 压力测试：对真实的业务数据进行测试，活得真实系统所能承受的压力\n\n## 目的\n\n### 建立MySQL服务器的性能基准线\n\n### 模拟比当前系统更高的负载，以找出系统的扩展瓶颈\n\n### 测试不同的软件硬件和操作系统配置\n\n### 证明新的硬件设备是否配置正确\n\n## 如何\n\n### 对整个系统进行基准测试\n\n- 优点\n\n\t- 能够测试整个系统的性能，包括Web服务器缓存。数据库等\n\t- 能反映出系统中各个组件接口间的性能问题，体现真是性能状况\n\n- 缺点\n\n\t- 测试设计复杂，消耗时间长\n\n### 单独针对MySQL进行基准测试\n\n- 优点\n\n\t- 测试设计简单，所需耗费时间短\n\n- 缺点\n\n\t- 无法全面了解整个系统的性能基线\n\n## 常见指标\n\n### TPS\n\n- 单位时间内处理事务数\n\n### QPS\n\n- 单位时间内查询数量\n\n### 响应时间\n\n- 平均响应时间\n- 最小响应时间\n- 最大响应时间\n- 各时间所占百分比\n\n### 并发量\n\n- 同时处理查询请求的数量\n\n# 附Xmind\n![MySQL基准测试](MySQL基准测试/MySQL基准测试.png)","tags":["Index","MySQL","基准测试"],"categories":["MySQL"]},{"title":"MySQL学习笔记-SQL查询优化","url":"/2019/08/02/SQL查询优化/","content":"\n## 如何获取有性能问题的SQL\n\n### 通过用户反馈获取存在性能问题的SQL\n\n### 通过慢查询日志获取存在性能问题的SQL\n\n### 实时获取存在性能问题的SQL\n\n## 使用慢查询日志获取有性能问题的SQL\n\n### slow_query_log 启动停止记录慢查询日志\n\n### slow_query_log_file指定慢查询日志存储路径及文件\n\n### long_query_time指定记录慢查询日志SQL执行时间的伐值\n\n- 默认10秒\n\n### 记录所有符合条件的SQL\n\n- 包括查询语句\n- 数据修改语句\n- 已经回滚的SQL\n\n### log_queries_not_using_indexes是否记录未使用索引的SQL\n\n## 常用的慢查询日志分析工具\n\n### mysqldumpslow\n\n### pt-query-digest\n\n## 实时获取性能问题SQL\n\n### information_schema -> PROCESSLIST表\n\n## SQL的解析预处理及生成执行计划\n\n### 搞清楚这些查询为什么会慢\n\n- 客户端发送sQL请求到服务器\n- 检查是否可以在查询换存储命中\n- 服务器端执行SQL解析，预处理，再由优化器声称对应的执行计划\n- 根据执行计划，调用存储引擎API来查询数据\n- 将结果返回给客户端\n\n### 查询缓存对SQL性能的影响\n\n- query_cache_type\n\n\t- 设置查询缓存是否可用\n\n- query_cache_size\n\n\t- 设置查询缓存的内存大小\n\n- query_cache_limit\n\n\t- 设置查询缓存可用存储的最大值\n\n- query_cache_wlock_invalidate\n\n\t- 设置数据表被锁后是否返回缓存中的数据\n\n- query_cache_min_res_unit\n\n\t- 设置查询缓存非配的内存块的最小单位\n\n- 读写比较频繁的系统，建议关闭缓存\n\n### MySQL依照执行计划和存储引擎进行交互\n\n- 解析SQL\n\n\t- 语法解析阶段通过关键字对MySQL语句进行解析，并生成一颗对应的解析树\n\t- MySQL解析器将使用MySQL语法规则验证和解析查询\n\n\t\t- 检查语法是否使用了正确的关键字\n\t\t- 关键字的顺序是否正确\n\n- 预处理\n\n\t- 根据MySQL规则进一步检查解析树是否合法\n\n\t\t- 查询中所涉及的表和数据列是否存在，名字或者别名是否存在歧义等\n\n\t- 查询优化器生成查询计划\n\n- 优化SQL执行计划\n\n### SQL的解析预处理以及生成执行计划\n\n- 会造成MySQL生成错误的执行计划的原因\n\n\t- 统计信息不准确\n\t- 执行计划中的成本估算不等同于实际的执行计划的成本\n\n\t\t- MySQL服务器层不知道哪些页面在内存中\n\t\t- 哪些页面在磁盘上\n\t\t- 哪些页面要顺序读取\n\t\t- 哪些页面需要随机读取\n\n\t- MySQL优化器所认为的最优可能与你所认为的最优不一样\n\n\t\t- 基于成本模型选择最优的执行计划\n\n\t- MySQL从不考虑其他并发的查询，这可能会影响当前查询的速度\n\t- MySQL有时候也会基于一些固定的规则来生成执行计划\n\t- MySQL不会考虑不收其控制的成本\n\n\t\t- 存储过程\n\t\t- 用户自定义的函数\n\n### MySQL优化器可优化的SQL类型\n\n- 重新定义表的关联顺序\n- 将外链接转化为内连接\n- 使用等价变换规则\n- 优化count，min，max\n\n\t- select tables optimized away\n\n- 建一个表达式转化为常数表达式\n- 子查询优化\n\n\t- 子查询->连接查询\n\n- 提前终止查询\n- 对in条件进行优化\n\n## 如何确定查询处理各个阶段所消耗的时间\n\n### 使用profile\n\n- set profiling=1\n\n\t- session级别\n\n- 执行查询\n- show profiles\n- show profile for query x\n- show profile cpu for query x\n\n### 使用performance_schema\n\n## 特定SQL的查询优化\n\n### 大批量删除\n\n- 分批次删除\n\n### 修改大表的表结构\n\n- 主从切换，先从后主\n- 新老表同步，比较复杂\n\n\t- pt-online-schema-change\n\n### 优化not in 和<>查询\n\n- 优化为LEFT JOIN方法\n\n### 使用汇总表优化查询\n\n- 截止到前一天的数据汇总count\n- 今天的全部数据进行count\n- 把两部分数据汇总\n\n# 附Xmind\n![SQL查询优化](SQL查询优化/SQL查询优化.png)","tags":["MySQL","分表","分库"],"categories":["MySQL"]},{"title":"MySQL学习笔记-数据库分库分表设计","url":"/2019/08/02/数据库分库分表设计/","content":"\n## 数据库分库分表的几种方式\n\n### 把一个实例中的多个数据库拆分到不同的实例\n\n### 把一个库中的表分离到不同的数据库中\n\n## 数据库分片前的准备\n\n### 对一个库中相关表进行水平拆分到不同实例的数据库中\n\n### 如何选择分区键\n\n- 分区键要能尽量避免跨分片查询的发生\n- 尽量使各个分片中的数据平均\n\n### 如何存储无需分片的表\n\n- 冗余到每一个分片中\n- 使用额外的节点统一存储\n\n### 如何在节点上部署分片\n\n- 每个分片使用单一数据库，并且数据库名也相同\n- 将多个分片表存储在一个数据库中，并且在表名上加入分片号后缀\n- 在一个节点中部署多个数据库，每个数据库中包含一个分片\n\n### 如何分配分片中的数据\n\n- 按分区键Hash值取模分配分片数据\n- 按分区键的范围来分配分片数据\n- 利用分区键和分片的映射表来分配分片数据\n\n### 如何生成全局唯一Id\n\n- 使用auto_increment_increment和auto_increment_offset参数\n- 配置全局节点生成Id\n\n\t- 容易成为系统瓶颈\n\n- 在Redis等缓存服务器中创建全局ID\n\n## 附件：Xmind图\n\n![数据库分库分表设计](数据库分库分表设计/数据库分库分表设计.png)","tags":["MySQL","分表","分库"],"categories":["MySQL"]},{"title":"MySQL学习笔记-MySQL数据库索引优化","url":"/2019/08/01/数据库索引优化/","content":"\n## MySQL支持的索引类型\n\n### Btree索引\n\n- 通过B+Tree结构存储数据\n- 加快数据的查询速度\n- 更适合进行范围查找\n- 顺序存储\n- 什么情况下可以使用到\n\n\t- 全值匹配的查询\n\t- 匹配最左前缀的查询\n\t- 匹配列前缀查询\n\t- 匹配范围值的查询\n\t- 精确匹配左前列并范围匹配另外一列\n\t- 只访问索引的查询\n\n- 使用限制\n\n\t- 如果不是按照索引最左列开始查找，则无法使用索引\n\t- 使用索引时不能跳过索引中的列\n\t- not in和<>不能使用索引\n\t- 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引\n\n### Hash索引\n\n- 特点\n\n\t- 基于hash表实现，只有查询条件精确匹配hash索引中的所有列的时候才能够使用hash索引\n\t- 对于hash索引中的所有列，存储引擎都会为每一行计算一个hash码，hash索引中存储的就是hash码\n\n- 限制\n\n\t- hash索引必须进行二次查找\n\t- hash索引无法用于排序\n\t- hash索引无法进行范围查找，不支持部分索引查找\n\t- hash索引中的hash码的计算可能存在has冲突\n\n## 为什么要使用索引\n\n- 索引大大减少了存储引擎需要扫描的数据量\n\n- 索引可以帮助我们进行排序，以避免使用临时表\n\n- 索引可以把随机I/O改变为顺序I/O\n\n## 索引不是越多越好\n\n- 索引会增加写操作的成本\n\n- 太多的索引会增加查询优化器的选择时间\n\n## 索引优化策略\n\n### 索引列上不能使用表达式或者函数\n\n### 前缀索引和索引列的选择性\n\n- 索引的选择性是不重复的索引值和表的记录数的比值\n\n### 联合索引\n\n- 如何选择索引列的顺序\n\n\t- 经常被使用到的列优先\n\t- 选择性高的列优先\n\t- 宽度小的列优先\n\n### 覆盖索引\n\n- 优点\n\n\t- 可以优化缓存，减少磁盘IO操作\n\t- 可以减少随机I/O，变随机I/O操作为顺序I/O操作\n\t- 可以避免对Innodb主键索引的二次查询\n\t- 可以避免MyISAM表进行系统调用\n\n- 无法使用覆盖索引的情况\n\n\t- 存储引擎不支持覆盖索引\n\t- 查询中使用了太多的列\n\t- 使用了双%号的like查询\n\n### 使用索引来优化查询\n\n- 使用索引扫描来优化排序\n\n\t- 通过排序操作\n\t- 按照索引顺序扫描数据\n\t- 索引的列顺序和Order By子句的顺序完全一致\n\t- 索引中所有列的方向（升序，降序）和Order By子句完全一致\n\t- Order by中的字段全部在关联表中的第一张表中\n\n- 模拟Hash索引优化查询\n\n\t- 只能处理键值的全值匹配\n\t- 所使用的Hash函数决定着索引键的大小\n\n- 利用索引优化锁\n\n\t- 索引可以减少锁定的行数\n\t- 索引可以加快处理速度，同时也加快了锁的释放\n\n### 索引的维护和优化\n\n- 删除重复和冗余的索引\n- 查找未被使用过的索引\n- 更新索引统计信息以及减少索引碎片\n\n\t- analyze table table_name\n\t- optimize table table_name\n\n## 附件：Xmind图\n\n![MySQL数据库索引优化](数据库索引优化/数据库索引优化.png)","tags":["Index","MySQL","优化"],"categories":["MySQL"]},{"title":"MySQL学习笔记-数据库结构优化","url":"/2019/07/31/数据库结构优化/","content":"\n## 目的\n\n### 减少数据冗余\n\n### 尽量避免数据维护中出现更新，插入和删除异常\n\n- 插入异常\n\n\t- 如果表中的某个实体随着另外一个实体存在而存在\n\n- 更新异常\n\n\t- 如果更高表中的某个实体的单独属性时，需要对多行进行更新\n\n- 删除异常\n\n\t- 如果删除表中的某一实体则会导致其他实体的消失\n\n### 节约数据存储空间\n\n### 提高查询效率\n\n## 数据库设计范式\n\n### 第一设计范式\n\n- 数据库中表的所有字段都只具有单一属性\n- 单一属性的列是由基本的数据类型所构成的\n- 设计出来的表都是简单的二维表\n\n### 第二设计范式\n\n- 一个表中具有一个业务主键\n\n### 第三设计范式\n\n- 每一个非主属性，既不部分依赖于也不传递依赖于业务主键\n\n### 反范式化设计\n\n- 少量的数据冗余，提高查询效率。空间换时间。\n\n### 优缺点\n\n- 范式化\n\n\t- 优点\n\n\t\t- 可以尽量的减少数据冗余\n\n\t\t\t- 数据表更新快，体积小\n\n\t\t- 范式化的更新操作比反范式化更快\n\t\t- 范式化的表通常比反范式化更小\n\n\t- 缺点\n\n\t\t- 对于查询需要对多个表进行关联\n\t\t- 更难进行索引优化\n\n- 反范式化\n\n\t- 优点\n\n\t\t- 减少表关联\n\t\t- 更好的进行索引优化\n\n\t- 缺点\n\n\t\t- 存在数据冗余以及数据维护异常\n\t\t- 对数据的修改需要更多的成本\n\n## 物理设计原则\n\n### 定义数据库，表以及字段的命名规范\n\n- 可读性原则\n- 表意性原则\n- 长名原则\n\n### 选择合适的存储引擎\n\n### 为表中的字段选择合适的数据类型\n\n- 当一个列可以选择多种数据类型的时候，应该优先考虑数字类型，其次是日期或者二进制类型，最后是字符类型。对于相同级别的数据类型，应该优先考虑占用空间小的数据类型\n- Varchar和char\n\n\t- varchar\n\n\t\t- Varchar类型的存储特点\n\n\t\t\t- VARCHAR用于存储变长字符串，只占用必要的存储空间\n\t\t\t- 列的最大长度小于255则只占用一个额外的字节，用于记录字符串长度\n\t\t\t- 列的最大长度大于255则占用两个额外的字节，用于记录字符串长度\n\n\t\t- VARCHAR长度的选择问题\n\n\t\t\t- 使用最小的符合需求的长度\n\t\t\t- varchar(5)和varchar(200)存储‘MYSQL’字符串性能不同\n\n\t\t- varchar的适用场景\n\n\t\t\t- 字符串列最大长度比平均长度大很多\n\t\t\t- 字符串列很少被更新\n\t\t\t- 使用了多字节字符集存储字符串\n\n\t\t- char类型是定长的\n\n\t- char\n\n\t\t- Char类型的存储特点\n\n\t\t\t- 字符串存储在char类型的列中会删除末尾的空格\n\t\t\t- Char类型的最大宽度为255\n\n\t\t- char类型的适用场景\n\n\t\t\t- char类型适合存储长度近似的值\n\n\t\t\t\t- 比如MD5，手机号，身份证号\n\n\t\t\t- char类型适合存储短字符串\n\t\t\t- char类型适合经常更新的字符串列\n\n- 如何存储日期类型\n\n\t- DATATIME类型\n\n\t\t- 占用8字节存储空间\n\t\t- 时区无关\n\t\t- 时间范围\n\n\t\t\t- 1000-01-01 00：00：00 ~ 9999-12-31 23：59：59\n\n\t\t- 存储格式\n\n\t\t\t- YYYY-MM-DD HH:MM:SS[.fraction]\n\n\t- TIMESTAMP\n\n\t\t- 存储了由格林尼治时间到当前时间的秒数\n\t\t- 占用4字节\n\t\t- 时间范围\n\n\t\t\t- 1970-01-01到2038-01-19\n\n\t\t- 依赖于所指定的时区\n\t\t- 在行的数据修改时，可以自动修改timestamp列的值（根据时间戳自动更新）\n\t\t- 默认第一个列是随着更改自动更新\n\n\t- date类型\n\n\t\t- 只需要3个字节\n\t\t- 可以使用时间函数\n\t\t- 时间范围1000-01-01~9999-12-31\n\n\t- time类型\n\n\t\t- 用于存储时间数据\n\t\t- HH:MM:SS\n\n\t- 存储日期时间数据的注意事项\n\n\t\t- 不要使用字符串类型来存储日期时间数据\n\t\t- 日期时间类型通常比字符串占用的存储空间小\n\t\t- 日期时间类型在进行查找过滤时可以利用日期来进行对比\n\t\t- 日期时间类型还有着丰富的处理函数，可以方便的对时间进行日期计算\n\t\t- 使用Int存储日期时间不如使用Timestamp类型\n\n## 附件：Xmind图\n\n![数据库结构优化](数据库结构优化/数据库结构优化.png)","tags":["MySQL","优化","结构"],"categories":["MySQL"]},{"title":"MySQL学习笔记-什么影响了MySQL性能","url":"/2019/07/30/什么影响了MySQL性能/","content":"\n## 服务器硬件\n\n### CPU资源\n\n- Web应用-Core重于频率\n\n### 内存大小\n\n- 主板支持最大频率的内存\n\n### 网络\n\n### IO子系统\n\n- 传统硬盘\n\n\t- 存储容量\n\t- 传输速度\n\t- 访问时间\n\t- 主轴转速\n\t- 物理尺寸\n\n- RAID\n\n\t- RAID0\n\n\t\t- 多个独立磁盘串行\n\t\t- 最简单\n\t\t- 性价比最高\n\t\t- 数据没有冗余\n\n\t- RAID1\n\n\t\t- 磁盘镜像\n\t\t- 安全性最高\n\n\t- RAID5\n\n\t\t- 分布式奇偶校验磁盘阵列\n\n\t- RAID10\n\n\t\t- 分片镜像\n\n- 固态存储\n\n\t- 更好的随机读写性能\n\t- 更好的支持并发\n\t- 更容易损坏\n\t- 使用场景\n\n\t\t- 大量随机I/O场景\n\t\t- 单线程负载I/O瓶颈\n\n- 网络存储\n\n\t- SAN\n\n\t\t- 大量顺序读写\n\n\t- NAS\n\n\t\t- 有一定网络延迟\n\n\t- 适合数据库备份\n\n### 网络性能的限制\n\n- 延迟\n- 带宽\n- 网络质量影响\n\n## 操作系统\n\n### CentOS\n\n- 内核相关参数（/etc/sysctl.conf）\n\n\t- 网络参数\n\n\t\t- net.core.somaxconn=65535  #监听队列长度\n\t\t- net.core.netdev_max_backlog=65535\n\t\t- net.ipv4.tcp_max_syn_backlog=65535\n\t\t- net.ipv4.tcp_fin_timeout =10\n\t\t- net.ipv4.tcp_tw_reuse  =1\n\t\t- net.ipv4.tcp_tw_recycle  =1\n\t\t- net.core.wmem_default = 87380\n\t\t- net.core.wmem_max = 16777216\n\t\t- net.core.rmem_default = 87380\n\t\t- net.core.rmem_max = 16777216\n\t\t- net.ipv4.tcp_keepalive_time =120\n\t\t- net.ipv4.tcp_keepalive_intvl =30\n\t\t- net.ipv4.tcp_keepalive_probes =3\n\n\t- 内核参数\n\n\t\t- kernel.shmmax=4294967295\n\n\t\t\t- Linux内核参数中最重要的参数之一，用于定义单个共享内存段的最大值\n\t\t\t- 注意事项\n\n\t\t\t\t- 这个参数应该设置的足够大，以便能在一个共享内存段下容纳下整个的Innodb缓冲池的大小\n\t\t\t\t- 这个值的大小对于64位Linux系统，可取的最大值为物理内存值-1byte，建议设置为大于物理内存的一半，一般取值大于Innodb缓冲池的大小即可。\n\n\t\t- vm.swappiness = 0\n\n\t\t\t- 当内存不足时会对性能产生比较明显的影响\n\t\t\t- 如果完全禁用Swap\n\n\t\t\t\t- 降低操作系统性能\n\t\t\t\t- 容易造成内存溢出，崩溃，或都被操作系统Kill\n\n\t\t\t- 结论\n\n\t\t\t\t- 需要保留交换分区，但是要控制何时使用交换分区\n\n\t\t\t- 为0\n\n\t\t\t\t- 除非内存使用满了，否则不要使用交换分区\n\n- 增加资源限制（/etc/security/limit.conf）\n\n\t- `* soft nofile 65535`\n\t- `* hard nofile 65535`\n\t- 解释\n\n\t\t- `* 所有用户有效`\n\t\t- `soft指的是当前系统生效的配置`\n\t\t- `hard表明系统中所能设定的最大值`\n\t\t- `nofile表示所限制的资源师打开文件的最大数目`\n\t\t- `65535 限制的数量`\n\n\t- 结论：把可以打开的文件数量增加到65535个以保证可以打开足够多的文件句柄\n\t- 注意：这个文件的修改需要重启系统才可以生效\n\n- 磁盘调度策略（/sys/block/devname/queue/scheduler）\n\n\t- noop\n\n\t\t- 电梯式调度策略（适合闪存，RAM，嵌入式系统）\n\n\t- cfq\n\n\t\t- 完全公平队列（默认，不适合MySQL）\n\n\t- deadline\n\n\t\t- 截止时间调度策略（适合数据库）\n\n\t- anticipatory\n\n\t\t- 预料I/O调度测量（适合写入较多的环境，比如文件服务器，不适合数据库）\n\n\t- 修改方法\n\n\t\t- echo deadlin > /sys/block/sda/queue/scheduler\n\n- 文件系统影响\n\n\t- Linux\n\n\t\t- 推荐使用XFS\n\t\t- EXT3/4\n\n\t\t\t- 系统挂载参数（/etc/fstab）\n\n\t\t\t\t- data = writeback | ordered | journal\n\n\t\t\t\t\t- Innodb适用于writeback，ordered较慢，journal最慢，最安全\n\n\t\t\t\t- noatime,nodiratime\n\n\t\t\t\t\t- 禁用相关时间\n\n\t\t\t\t- 示例：\n\n\t\t\t\t\t- /dev/sda1/ext3\tnoatime,nodiratime,data=writeback 1 1\n\n## 数据库存储引擎的选择\n\n### MyISAM\n\n- MySQL5.5之前的默认存储引擎\n- 存储为MYD，MYI两个文件\n- 特性\n\n\t- 并发性与锁级别\n\n\t\t- 表锁\n\n\t- 表损坏修复\n\n\t\t- check table tablename\n\t\t- repire table tablename\n\n\t- 支持索引类型\n\n\t\t- 全文索引\n\t\t- Text等前缀索引\n\n\t- 支持数据压缩\n\n\t\t- myisampack\n\t\t- 只读\n\n- 限制\n\n\t- 单表<256T\n\n- 适用场景\n\n\t- 非事务型应用\n\t- 只读类应用（支持压缩）\n\t- 空间类应用\n\n\t\t- 支持空间函数\n\n### Innodb\n\n- 使用表空间进行数据存储\n\n\t- innodb_file_per_table\n\n\t\t- ON：独立表空间：tablename.ibd\n\t\t- OFF：系统表空间：ibdataX\n\n\t- 比较\n\n\t\t- 系统表空间无法简单的收缩文件大小\n\t\t- 独立表空间可以通过optimize table命令收缩系统文件\n\t\t- 系统表空间会产生I/O瓶颈\n\t\t- 独立表空间可以同时向多个文件刷新数据\n\n\t- 建议\n\n\t\t- 对Innodb使用独立表空间\n\n- 系统表空间\n\n\t- Innodb数据字典信息\n\t- Undo回滚段\n\n- 特性\n\n\t- Innodb是一种事务性的存储引擎\n\t- 完全支持事务的ACID特性\n\t- Redo Log和Undo Log\n\t- 支持行级锁\n\t- 行级锁可以最大程度支持并发\n\t- 行级锁是由存储引擎层实现的\n\n- 什么是锁\n\n\t- 锁主要作用是管理共享资源的并发访问\n\t- 锁用于实现事务的隔离性\n\t- 锁的类型\n\n\t\t- 共享锁（读锁）\n\t\t- 独占锁（写锁）\n\n\t- 锁的粒度\n\n\t\t- 表级锁\n\t\t- 行级锁\n\n\t- 阻塞和死锁\n\n- Innodb状态检查\n\n\t- show engine innodb status\n\n- 适用场景\n\n\t- 使用大多数OLTP应用\n\n### CSV\n\n- 文件系统存储特点\n\n\t- 数据以文本方式存储在文件中\n\t- .csv文件存储表内容\n\t- CSM文件存储表的元数据如表的状态和数据量\n\t- frm文件存储表结构信息\n\n- 特点\n\n\t- 以CSV格式进行数据存储\n\t- 所有列必须都是不能为null的\n\t- 不支持索引\n\n\t\t- 不适合大表\n\n\t- 可以对数据文件直接进行编辑\n\n\t\t- 保存文本文件内容\n\n- 适用场景\n\n\t- 适合作为数据交换的中间表\n\n### Archive\n\n- 文件存储特点\n\n\t- 以Zlib对表数据进行压缩，磁盘I/O更少\n\t- 数据存储在ARZ为后缀的文件中\n\t- 只支持Insert和select操作\n\t- 只允许在自增ID列上加索引\n\n- 适用场景\n\n\t- 日志和数据采集类应用\n\n### Memory\n\n- 文件系统特点\n\n\t- 也称为HEAP存储引擎，数据保存在内存中\n\n- 功能特点\n\n\t- 支持HASH索引和BTree索引\n\n\t\t- HASH适合等值\n\t\t- BTree适合范围\n\n\t- 所有字段都为固定长度\n\t- 不支持Blog和Text等大字段\n\t- 使用表级锁\n\t- 最大大小由max_heap_table_size参数决定\n\n\t\t- 默认16M\n\n- 容易混淆的概念\n\n\t- Memory存储引擎表\n\t- 临时表\n\n\t\t- 系统使用临时表\n\n\t\t\t- 超过限制使用MyISAM临时表\n\t\t\t- 未超过限制使用Memory表\n\n\t\t- create temporary table 建立的临时表\n\n- 适用场景\n\n\t- 用于查找或者映射表\n\t- 用于保存数据分析过程中产生的中间表\n\t- 用于缓存周期性聚合数据的结果表\n\t- MEMory数据容易丢失，所以要求数据可再生\n\n### Federated\n\n- 特点\n\n\t- 提供了访问MySQL服务器上表的方法\n\t- 本地不存储数据，数据全部存放到远程服务器上\n\t- 本地需要保存表结构和服务器连接信息\n\n- 如何使用\n\n\t- 默认禁止，启用需要在启动时增加federated参数\n\n- 适用场景\n\n\t- 偶尔统计分析以及手工查询\n\n### 如何选择正确的存储引擎\n\n- 一般选择InnoDB\n- 参考条件\n\n\t- 事务\n\t- 备份\n\t- 崩溃恢复\n\t- 存储引擎的特有特性\n\n- 尽量不要混合使用存储引擎\n\n## 数据库参数配置\n\n### MySQL获取配置信息路径\n\n- 命令行参数\n- 配置文件\n\n### MySQL配置参数的作用域\n\n- 全局参数\n\n\t- set global 参数名=参数值;\n\t- set @@global.参数名:=参数值；\n\n- 会话参数\n\n\t- set [session] 参数名=参数值\n\t- set @@session.参数名:=参数值\n\n### 内存配置相关参数\n\n- 确定可以使用的内存的上限\n- 确定MySQL的每个连接使用的内存\n\n\t- sort_buffer_size\n\t- join_buffer_size\n\t- read_buffer_size\n\t- read_rnd_buffer_size\n\n- 确定需要为操作系统保留多少内存\n- 如何为缓存池分配内存\n\n\t- Innodb_buffer_pool_size\n\n\t\t- 总内存 -（每个线程所需要的内存*连接数）- 系统保留内存\n\n\t- key_buffer_size\n\n\t\t- 主要MyISAM使用\n\n### IO相关配置参数\n\n- Innodb I/O 相关配置\n\n\t- Innodb_log_file_size\n\t- Innodb_log_files_in_group\n\t- 事务日志总大小 = Innodb_log_file_size *  Innodb_log_files_in_group\n\t- Innodb_log_buffer_size\n\t- Innodb_flush_log_at_trx_commit\n\n\t\t- 0：每秒进行一次log写入cache，并flush log到磁盘\n\t\t- 1：每次事务提交执行log写入cache，并flush log到磁盘\n\t\t- 2：每次事务提交，执行log数据写入到cache，每秒执行一次flush log到磁盘\n\n\t- Innodb_flush_method=O_DIRECT\n\n\t\t- 关闭操作系统缓存(Linux建议)\n\n\t- Innodb_file_per_table = 1\n\t- Innodb_doublewriter = 1\n\n- MyISAM\n\n\t- delay_key_write\n\n\t\t- OFF:每次写操作后刷新键缓冲中的脏块到磁盘\n\t\t- ON: 支队在键表时制定了delay_key_write选项的表使用延迟刷新\n\t\t- ALL:对所有MyISAM表都是用延迟建写入\n\n### 安全相关配置参数\n\n- expire_logs_days\n\n\t- 指定自动清理binlog的天数\n\n- max_allowed_packet\n\n\t- 控制MySQL可以接受的包的大小\n\n- skip_name_resolve\n\n\t- 禁用DNS查找\n\n- sysdate_is_now\n\n\t- 确保sysdate()返回确定性日期\n\n- read_only\n\n\t- 禁止非super权限的用户写权限\n\n- skip_slave_start\n\n\t- 禁用Salve恢复\n\n- sql_mode\n\n\t- 设置MySQL所使用的SQL模式\n\t- strict_trans_tables\n\t- no_engine_subtitution\n\t- no_zero_date\n\t- no_zero_in_date\n\t- only_full_group_by\n\n### 其他常用配置参数\n\n- sync_binlog\n\n\t- 控制MySQL如何向磁盘刷新binlog\n\n- tmp_table_size/max_heap_table_size\n\n\t- 控制内存临时表大小\n\n- max_connections\n\n\t- 控制允许的最大连接数\n\n## 数据库结构设计和SQL语句\n\n### 数据库设计对性能的影响\n\n- 过分的反范式化为表建立太多的列\n- 过分的范式化造成太多的表关联\n- OLTP环境中使用了不恰当的分区表\n- 使用外键保证数据的完整性\n\n# 附Xmind\n![什么影响了MySQL性能](什么影响了MySQL性能/什么影响了MySQL性能.png)","tags":["MySQL","性能"],"categories":["MySQL"]},{"title":"Java多线程分析-ReentrantLock","url":"/2019/07/21/ReentrantLock/","content":"\n\n# Field\n\n## final Sync sync;\n- 核心Field，实际锁相关操作均在这里，实际上是对ReentrantLock的包装\n\n\n# 方法\n\n## lock()\n- 获取锁操作，直接委托给sync，有公平和非公平两种实现，具体看NonfairSync和FairSync\n\n```\n    public void lock() {\n        sync.lock();\n    }\n```\n\n## lockInterruptibly()\n- 支持中断的获取锁\n\n```\n    public void lockInterruptibly() throws InterruptedException {\n        sync.acquireInterruptibly(1);\n    }\n```\n\n## tryLock()\n- 非阻塞方式获取锁\n\n```\n    public boolean tryLock() {\n        return sync.nonfairTryAcquire(1);\n    }\n```\n\n## tryLock(long timeout, TimeUnit unit)\n- 带有超时的获取锁\n\n```\n    public boolean tryLock(long timeout, TimeUnit unit)\n            throws InterruptedException {\n        return sync.tryAcquireNanos(1, unit.toNanos(timeout));\n    }\n```\n\n## unlock()\n- 释放锁\n\n```\n    public void unlock() {\n        sync.release(1);\n    }\n```\n\n## newCondition()\n- 创建条件变量\n\n```\n    public Condition newCondition() {\n        return sync.newCondition();\n    }\n```\n\n## getHoldCount()\n- 当前线程持有锁的个数\n\n```\n    public int getHoldCount() {\n        return sync.getHoldCount();\n    }\n```\n\n## isHeldByCurrentThread()\n- 锁是否被当前线程支持\n\n```\n    public boolean isHeldByCurrentThread() {\n        return sync.isHeldExclusively();\n    }\n```\n\n## isLocked()\n- 是否处于锁定状态\n\n```\n    public boolean isLocked() {\n        return sync.isLocked();\n    }\n```\n\n## isFair()\n- 是否为公平锁\n\n```\n    public final boolean isFair() {\n        return sync instanceof FairSync;\n    }\n```\n\n## getOwner()\n- 持有锁的线程\n\n```\n    protected Thread getOwner() {\n        return sync.getOwner();\n    }\n```\n\n## hasQueuedThreads()\n- 是否有线程在等待获取锁\n\n```\n    public final boolean hasQueuedThreads() {\n        return sync.hasQueuedThreads();\n    }\n```\n\n## hasQueuedThread(Thread thread)\n- 线程是否在等待获取锁的队列中\n\n```\n    public final boolean hasQueuedThread(Thread thread) {\n        return sync.isQueued(thread);\n    }\n```\n\n## getQueueLength()\n- 等待队列的长度\n\n```\n    public final int getQueueLength() {\n        return sync.getQueueLength();\n    }\n```\n\n## getQueuedThreads()\n- 等待的线程集合\n\n```\n    protected Collection<Thread> getQueuedThreads() {\n        return sync.getQueuedThreads();\n    }\n```\n\n## hasWaiters(Condition condition)\n- 是否有线程阻塞在condition的await()的方法上\n\n```\n    public boolean hasWaiters(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(\"not owner\");\n        return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n```\n\n## getWaitQueueLength(Condition condition)\n- 阻塞在condition的await()的方法上的线程数量\n\n```\n    public int getWaitQueueLength(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(\"not owner\");\n        return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n```\n\n## getWaitingThreads(Condition condition)\n- 阻塞在condition的await()的方法上的线程集合\n\n```\n    protected Collection<Thread> getWaitingThreads(Condition condition) {\n        if (condition == null)\n            throw new NullPointerException();\n        if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject))\n            throw new IllegalArgumentException(\"not owner\");\n        return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition);\n    }\n```\n\n\n# 内部类\n\n内部类有三个，公共抽象类Sync，非公平锁实现NonfairSync，公平锁实现FairSync，下面分别进行分析\n\n# Sync\n\n## void lock()\n- 核心加锁方法，因为公平锁和非公平锁实现不同，所以这里为抽象方法。\n\n## boolean nonfairTryAcquire(int acquires)\n- 非公平获取锁(资源)的实际实现，从以下源码可以看出，获取锁的时候，哪个先来，哪个就可以获取到，CAS操作成功的就获取到锁了，没有所谓的先来后到。\n```\n        final boolean nonfairTryAcquire(int acquires) {\n            final Thread current = Thread.currentThread();//当前线程\n            int c = getState();//获取加锁状态\n            if (c == 0) {//为0则代表还没有上锁\n                if (compareAndSetState(0, acquires)) {//执行CAS操作并且上锁\n                    setExclusiveOwnerThread(current);//设置持有锁的线程\n                    return true;//加锁成功\n                }\n            }\n            else if (current == getExclusiveOwnerThread()) {//执行到这里说明已经有某个线程获取到锁了，因为是可重入锁，判断持有锁的线程是否为当前线程\n                int nextc = c + acquires;//执行到这里说明是已经不是第一次上锁，并且当前线程是锁的持有线程，则可以直接进行累加(也就是重入)\n                if (nextc < 0) // 额，超过int的最大值，出现溢出了(真的存在这种场景么= =？？)\n                    throw new Error(\"Maximum lock count exceeded\");\n                setState(nextc);//更新state\n                return true;\n            }\n            return false;//获取失败\n        }\n```\n\n## boolean tryRelease(int releases)\n- 非阻塞方式尝试释放资源，具体看源码分析\n```\n        protected final boolean tryRelease(int releases) {\n            int c = getState() - releases;//待更新资源\n            if (Thread.currentThread() != getExclusiveOwnerThread())//判断是否为锁的持有现成\n                throw new IllegalMonitorStateException();\n            boolean free = false;//释放标识位置。为true则代表当前线程不再持有当前锁的任何资源\n            if (c == 0) {//如果释放资源后，资源数量为0，代表释放锁，其他线程可以尝试获取锁，如果不为0，则需要继续释放(因为是重入多次，需要释放多次)\n                free = true;\n                setExclusiveOwnerThread(null);//清空锁持有线程\n            }\n            setState(c);//更新状态标志位\n            return free;\n        }\n```\n\n## boolean isHeldExclusively()\n- 判断当前线程是否为锁持有线程\n```\n        protected final boolean isHeldExclusively() {\n            return getExclusiveOwnerThread() == Thread.currentThread();\n        }\n```\n\n## ConditionObject newCondition()\n- 创建条件变量对象,ConditionObject之后分析\n```\n        final ConditionObject newCondition() {\n            return new ConditionObject();\n        }\n```\n\n## Thread getOwner() \n- 如果锁没有被线程持有，返回null，否则返回持有的线程\n```\n        final Thread getOwner() {\n            return getState() == 0 ? null : getExclusiveOwnerThread();\n        }\n```\n\n## int getHoldCount()\n- 获取重入次数。如果当前线程没有持有锁，返回0；\n```\n        final int getHoldCount() {\n            return isHeldExclusively() ? getState() : 0;\n        }\n```\n\n## boolean isLocked()\n- 是否处于锁定状态\n```\n        final boolean isLocked() {\n            return getState() != 0;\n        }\n```\n\n# NonfairSync\n\n- 非公平锁的委托实现，继承了Sync类，间接继承了AQS\n\n## void lock() \n- 获取锁操作，直接通过cas获取，失败则通过aqs的acquire获取，acquire在父类AQS中，会调用子类的tryAcquire方法。\n```\n        final void lock() {\n            if (compareAndSetState(0, 1))\n                setExclusiveOwnerThread(Thread.currentThread());\n            else\n                acquire(1);\n        }\n\n        public final void acquire(int arg) {\n            if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n                selfInterrupt();\n        }\n```\n\n## boolean tryAcquire(int acquires)\n- 直接调用sync抽象类中的nonfairTryAcquire，非公平方式获取资源\n```\n        protected final boolean tryAcquire(int acquires) {\n            return nonfairTryAcquire(acquires);\n        }\n```\n\n# FairSync\n- 公平锁的委托实现，继承了Sync类，间接继承了AQS\n\n## void lock()\n- 没有快速路径，直接调用acquire去获取资源，内部委托依旧是调用tryAcquire\n```\n        final void lock() {\n            acquire(1);\n        }\n```\n\n## boolean tryAcquire(int acquires)\n- 与非公平获取资源相比，区别在于多了条件!hasQueuedPredecessors() ，也就是说按照队列的方式获取，如果队列中尚有未获取的在等待，则当前线程等待并且入队(参考AQS部分)\n```\n        protected final boolean tryAcquire(int acquires) {\n            final Thread current = Thread.currentThread();\n            int c = getState();\n            if (c == 0) {\n                if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) {\n                    setExclusiveOwnerThread(current);\n                    return true;\n                }\n            }\n            else if (current == getExclusiveOwnerThread()) {\n                int nextc = c + acquires;\n                if (nextc < 0)\n                    throw new Error(\"Maximum lock count exceeded\");\n                setState(nextc);\n                return true;\n            }\n            return false;\n        }\n```\n\n# 总结\n\n- 其实相对而言，可重入锁实现很简单，基本都是继承了AQS的方法，重点实现了可重入(线程相同则累加state)，以及公平非公平。\n- 重点还是在于理解AQS，这里的可重入锁，以及之后的可重入读写锁,CountDownLatch，Semaphore,CyclicBarrier等都是基于AQS实现的。","tags":["Java","多线程","AbstractQueuedSynchronizer","ReentrantLock","Lock"],"categories":["Java"]},{"title":"Maven将程序及依赖打成一个jar包","url":"/2019/07/20/maven package 打包/","content":"\n平时写一些简单工具类，经常要打包ftp到服务器上面，懒得zip压缩，直接生成jar包。\nmaven配置如下：\n\n```\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-assembly-plugin</artifactId>\n                <version>2.5.5</version>\n                <configuration>\n                    <archive>\n                        <manifest>\n                            <mainClass>com.xxx.xxx.xxx.xxx</mainClass>\n                        </manifest>\n                    </archive>\n                    <descriptorRefs>\n                        <descriptorRef>jar-with-dependencies</descriptorRef>\n                    </descriptorRefs>\n                </configuration>\n                <executions>\n                    <execution>\n                        <id>make-assembly</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>single</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n```\n\n","tags":["Java","Maven"],"categories":["Java"]},{"title":"Java线程池分析-AbstractQueuedSynchronizer","url":"/2019/07/14/Java线程池分析-AbstractQueuedSynchronizer/","content":"\nAQS分析第一篇，整理得快吐血了，不过话说回来，看一遍和整理了一遍真的完全不一样，收获还是很多的。\n这里基本把AQS整个类分析了一遍，剩下还有就是条件对象以及AQS应用了，后续有时间在整理了。\n\n----\n\n\n# AbstractOwnableSynchronizer\n- 比较简单，内部一个exclusiveOwnerThread，附带get和set方法，不多说\n\n# Node\n- AbstractQueuedSynchronizer 核心依赖，内部队列就是由Node组成\n\n## 核心Field\n\n### 状态类\n\n- int CANCELLED =  1;\n    - 代表被取消了\n- int SIGNAL    = -1;\n    - 代表需要被唤醒\n- int CONDITION = -2;\n    - 代表在条件队列中等待\n- int PROPAGATE = -3;\n    - 代表释放资源的时候需要通知其他Node\n- int waitStatus\n    - 代表当前Node的等待状态，取值为CANCELLED、SIGNAL、CONDITION、PROPAGATE，默认初始化为0\n\n### 记录阻塞模式\n\n- Node SHARED\n    - 代表该Node是因为获取共享资源被阻塞而放入AQS\n- Node EXCLUSIVE\n    - 代表该Node是因为获取独占资源被阻塞而放入AQS\n\n### 链表相关\n\n- 提供前驱和后继节点的访问方法，也就是说链表是双向的\n- Node prev\n    - 记录当前节点的前驱节点\n- Node next\n    - 记录当前节点的后继节点\n\n### 其他\n- Thread thread\n    - thread用于存放进入AQS队列的里面的线程\n- Node nextWaiter\n    - 在Node作为同步队列节点时，nextWaiter可能有两个值：EXCLUSIVE、SHARED标识当前节点是独占模式还是共享模式；\n    - 在Node作为等待队列节点使用时，nextWaiter保存后继节点。\n\n## 核心方法\n\n### boolean isShared()\n- 当前节点获取资源采用的是否为共享方式\n    ```\n        final boolean isShared() {\n            return nextWaiter == SHARED;\n        }\n    ```\n\n### Node predecessor()\n- 获取前置节点，如果前置节点为null，则抛出NPE异常\n```\n    final Node predecessor() throws NullPointerException {\n        Node p = prev;\n        if (p == null)\n            throw new NullPointerException();\n        else\n            return p;\n    }\n```\n\n# AbstractQueuedSynchronizer\n\n## 核心Field\n\n- Node head\n    - 内部队列的头结点\n- Node tail\n    - 内部队列的尾节点\n- int state\n    - 状态位，在不同的子类中有不同的含义\n- long spinForTimeoutThreshold\n    - 自旋时间，低于这个时间则直接进行空循环，然后重新尝试获取资源\n\n## 核心方法\n### int getState()\n- 用的很多，但是没啥可说的\n\n### void setState(int newState)\n- 用的很多，但是没啥可说的\n\n### boolean compareAndSetState(int expect, int update)\n- Cas更新状态操作，也没啥可说的\n\n### Node enq(final Node node)\n- 入队操作，如果队列没有节点，则tail为null，这个时候需要加入一个哨兵节点\n```\n    private Node enq(final Node node) {\n        for (;;) {\n            Node t = tail;\n            if (t == null) { // Must initialize\n                if (compareAndSetHead(new Node()))//加入一个哨兵节点到队列尾部，再次循环\n                    tail = head;\n            } else {\n                node.prev = t;\n                if (compareAndSetTail(t, node)) {\n                    t.next = node;\n                    return t;//返回原末尾节点\n                }\n            }\n        }\n    }\n```\n\n### Node addWaiter(Node mode)\n- 这个作者实现比较有趣，先用快速方式尝试添加节点，成功则返回新添加的节点，失败则通过enq以循环的方式将node入队\n```\n    private Node addWaiter(Node mode) {\n        //根据当前线程以及模式（共享或者独占）创建一个节点\n        Node node = new Node(Thread.currentThread(), mode);\n        //尝试直接添加到队列尾部(所谓的快速添加)\n        Node pred = tail;\n        if (pred != null) {\n            node.prev = pred;\n            //CAS添加成功则返回结果，失败则只需enq\n            if (compareAndSetTail(pred, node)) {\n                pred.next = node;\n                return node;\n            }\n        }\n        //说明快速添加遇到竞争，通过enq进行入队操作\n        enq(node);\n        return node;\n    }\n```\n\n### void setHead(Node node)\n- 设置头结点，注意一下node的thread和prev会设置为null\n\n### void unparkSuccessor(Node node)\n- 该方法用于唤醒等待队列中的下一个线程,下一个线程并不一定是当前节点的next节点，需要根据其状态来进行查找，找到之后执行LockSupport.unpark唤醒对应的线程。\n```\n    private void unparkSuccessor(Node node) {\n        int ws = node.waitStatus;\n        if (ws < 0)\n            compareAndSetWaitStatus(node, ws, 0);\n        Node s = node.next;\n        if (s == null || s.waitStatus > 0) {\n            s = null;\n            for (Node t = tail; t != null && t != node; t = t.prev)\n                if (t.waitStatus <= 0)\n                    s = t;\n        }\n        if (s != null)\n            LockSupport.unpark(s.thread);\n    }\n```\n\n### void doReleaseShared()\n- 共享模式的释放操作，一般来说，只需要判断两种情况：\n    - SIGNAL代表后继节点之前被阻塞了需要释放\n    - PROPAGATE代表共享模式下可以继续进行acquire\n```\n    private void doReleaseShared() {\n        for (;;) {\n            Node h = head;\n            //这里的判断是处理头结点和尾结点都存在的情况，并且队列里节点总数大于1\n            if (h != null && h != tail) {\n                int ws = h.waitStatus;\n                //Node.SIGNAL表示后继节点需要被唤醒\n                if (ws == Node.SIGNAL) {\n                    //h从SIGNAL设置为0\n                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                        continue;\n                    //执行唤醒操作，这里会将h.waitStatus设置为0，补充，每次只唤醒一个线程\n                    unparkSuccessor(h);\n                }\n                //如果后继节点暂时不需要唤醒，则把当前节点状态设置为PROPAGATE确保以后可以传递下去，也就是h从0设置为PROPAGATE，\n                else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                    continue;\n            }\n            //头节点没有发生变化，可以退出循环，如果头结点发生了变化，为了使自己的唤醒动作可以传递，必须进行重试\n            if (h == head)\n                break;\n        }\n    }\n```\n\n### void setHeadAndPropagate(Node node, int propagate)\n- 首先执行setHead方法，在这之后检查条件，如果满足条件则唤醒后继节点(因为是共享模式，所以后继节点也一并唤醒)\n```\n    private void setHeadAndPropagate(Node node, int propagate) {\n        Node h = head; // Record old head for check below\n        setHead(node);\n        //检查条件\n        // propagate > 0 表示调用方指明了后继节点需要被唤醒\n        // 头节点后面的节点需要被唤醒（waitStatus<0），不论是老的头结点还是新的头结点(看第一行和第二行代码)\n        if (propagate > 0 || h == null || h.waitStatus < 0 || (h = head) == null || h.waitStatus < 0) {\n            Node s = node.next;\n            if (s == null || s.isShared())\n                doReleaseShared();\n        }\n    }\n```\n\n### void cancelAcquire(Node node)\n- 取消正在获取资源的操作\n```\nprivate void cancelAcquire(Node node) {\n        if (node == null)\n            return;\n        //首先当前node不在关联任何线程\n        node.thread = null;\n        Node pred = node.prev;\n        //CANCELLED的值为1，该判断也就是跳过已经取消的节点\n        while (pred.waitStatus > 0)\n            node.prev = pred = pred.prev;\n        //这里指找到一个有效的前置节点\n        Node predNext = pred.next;\n         //将节点node设置为CANCELLED状态\n        node.waitStatus = Node.CANCELLED;\n        //判断node是否为tail节点，如果是tail节点，则cas进行替换，替换为找到的有效前置节点pred\n        if (node == tail && compareAndSetTail(node, pred)) {\n            执行成则pred的下一个节点为null(已经是tail节点)\n            compareAndSetNext(pred, predNext, null);\n        } else {\n            //执行到这里说明node不是tail节点，或者cas操作失败了\n            int ws;\n            // pred如果不是head节点，并且thread不为空，并且满足下面条件之一\n            // 1. pred.waitStatus为SIGNAL\n            // 2. pred.waitStatus <= 0 （SIGNAL,CONDITION,PROPAGATE,0），并成功将pred的WaitStatus进行cas替换为SIGNAL\n            if (pred != head && (   (ws = pred.waitStatus) == Node.SIGNAL ||(ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL)) ) && pred.thread != null) {\n                Node next = node.next;\n                //将前置节点的next指向当前节点的next（说白了就是删除链表中的当前节点，只不过是在cas中进行操作）\n                if (next != null && next.waitStatus <= 0)\n                    compareAndSetNext(pred, predNext, next);\n            } else {\n                //不满足条件，也就是说node为head的后继节点，直接进行唤醒\n                unparkSuccessor(node);\n            }\n            // 这个就是清除引用，快速gc用的\n            node.next = node; \n        }\n    }\n```\n\n### boolean shouldParkAfterFailedAcquire(Node pred, Node node)\n- 根据前置节点判断当前节点是否应该被阻塞，同时清理掉CANCELLED节点\n```\n    private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n        int ws = pred.waitStatus;\n        //如果继的节点状态为SIGNAL，则当前节点需要unpark，返回true\n        if (ws == Node.SIGNAL)\n            return true;\n        //否则返回false，并进行如下操作\n        //ws > 0说明前置节点已经被取消(CANCELLED = 1), 这时需要继续往前找，直到找到 waitStatus 不为 CANCELLED ，然后返回false。所谓清理CANCELLED节点就是在这里跳过对应的节点。\n        if (ws > 0) {\n            do {\n                node.prev = pred = pred.prev;\n            } while (pred.waitStatus > 0);\n            pred.next = node;\n        } else {\n            //如果节点状态不是CANCELLED，则cas更新waitStatus为SIGNAL\n            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n        }\n        return false;\n    }\n```\n\n### void selfInterrupt()\n- 这个方法比较简单，就是调用当前线程的中断方法\n```\n    static void selfInterrupt() {\n        Thread.currentThread().interrupt();\n    }\n```\n\n### boolean parkAndCheckInterrupt()\n- 阻塞当前线程并执行中断检查(会清除中断标识)\n```\n    private final boolean parkAndCheckInterrupt() {\n        LockSupport.park(this);\n        return Thread.interrupted();\n    }\n```\n\n### boolean acquireQueued(final Node node, int arg)\n- 尝试获取锁，成功返回中断状态，失败则则阻塞。阻塞过程中被中断，会返回被中断过标识\n```\n    final boolean acquireQueued(final Node node, int arg) {\n        boolean failed = true;\n        try {\n            boolean interrupted = false;//默认非中断\n            for (;;) {\n                //获取当前节点的前置节点\n                final Node p = node.predecessor();\n                //如果前置节点为head节点，则尝试获取资源\n                //每次只允许当构造节点的前驱节点是头结点才去获取同步状态\n                if (p == head && tryAcquire(arg)) { //只有一个线程可以通过\n                    setHead(node);\n                    p.next = null; // help GC\n                    failed = false;\n                    return interrupted;\n                }\n                //否则根据是否可以进行park操作进行阻塞\n                if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                    interrupted = true;\n            }\n        } finally {\n            //如果没有更新failed标志为，则发生异常，取消node节点\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n\n### void doAcquireInterruptibly(int arg)\n- 获取资源操作，如果阻塞过程中被中断，则会抛出异常\n```\nprivate void doAcquireInterruptibly(int arg) throws InterruptedException {\n        //添加一个独占资源到队列末尾\n        final Node node = addWaiter(Node.EXCLUSIVE);\n        //以下代码基本同acquireQueued\n        boolean failed = true;\n        try {\n            for (;;) {\n                final Node p = node.predecessor();\n                if (p == head && tryAcquire(arg)) {\n                    setHead(node);\n                    p.next = null; // help GC\n                    failed = false;\n                    return;\n                }\n                if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                    throw new InterruptedException();//这里直接抛出异常\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n\n### boolean doAcquireNanos(int arg, long nanosTimeout)\n- 带有超时的去获取独占资源，如果被中断，会抛出异常\n```\n    private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException {\n        if (nanosTimeout <= 0L)//时间判断\n            return false;\n        final long deadline = System.nanoTime() + nanosTimeout;//结束时间\n        final Node node = addWaiter(Node.EXCLUSIVE);//添加独占资源node到队列\n        boolean failed = true;\n        try {\n            for (;;) {\n                //获取资源\n                final Node p = node.predecessor();\n                if (p == head && tryAcquire(arg)) {\n                    setHead(node);\n                    p.next = null; // help GC\n                    failed = false;\n                    return true;\n                }\n                nanosTimeout = deadline - System.nanoTime();//当前还可以等待时间\n                if (nanosTimeout <= 0L)//已经超时\n                    return false;\n                if (shouldParkAfterFailedAcquire(p, node) && nanosTimeout > spinForTimeoutThreshold)//阻塞nanosTimeout\n                    LockSupport.parkNanos(this, nanosTimeout);\n                if (Thread.interrupted())//线程被中断，则抛出异常\n                    throw new InterruptedException();\n            }\n        } finally {\n            if (failed)//没有成功则取消节点\n                cancelAcquire(node);\n        }\n    }\n```\n\n### void doAcquireShared(int arg)\n- 以共享的方式获取资源，失败则阻塞\n```\n    private void doAcquireShared(int arg) {\n        final Node node = addWaiter(Node.SHARED);//添加一个共享节点到队列尾部\n        boolean failed = true;//失败标志位\n        try {\n            boolean interrupted = false;//中断标志位\n            for (;;) {\n                final Node p = node.predecessor();\n                if (p == head) {//必须是头节点才可以\n                    int r = tryAcquireShared(arg);//获取资源\n                    //r等于0表示不用唤醒后继节点，大于0需要\n                    if (r >= 0) {\n                        //尝试唤醒后继节点\n                        setHeadAndPropagate(node, r);\n                        p.next = null; // help GC\n                        //没有中断，则返回\n                        if (interrupted)\n                            selfInterrupt();\n                        failed = false;\n                        return;\n                    }\n                }\n                //获取失败，则进行阻塞，并将前驱节点的状态改成SIGNAL\n                if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                    interrupted = true;\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n\n### void doAcquireSharedInterruptibly(int arg)\n- 基本同doAcquireShared，被中断则抛出异常\n```\n    private void doAcquireSharedInterruptibly(int arg)\n        throws InterruptedException {\n        final Node node = addWaiter(Node.SHARED);\n        boolean failed = true;\n        try {\n            for (;;) {\n                final Node p = node.predecessor();\n                if (p == head) {\n                    int r = tryAcquireShared(arg);\n                    if (r >= 0) {\n                        setHeadAndPropagate(node, r);\n                        p.next = null; // help GC\n                        failed = false;\n                        return;\n                    }\n                }\n                if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                    throw new InterruptedException();//这里抛出异常\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n\n### boolean doAcquireSharedNanos(int arg, long nanosTimeout)\n- 和上面的没啥区别，就是多了超时控制而已，被中断也是抛出异常\n```\n    private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException {\n        if (nanosTimeout <= 0L)\n            return false;\n        final long deadline = System.nanoTime() + nanosTimeout;\n        final Node node = addWaiter(Node.SHARED);\n        boolean failed = true;\n        try {\n            for (;;) {\n                final Node p = node.predecessor();\n                if (p == head) {\n                    int r = tryAcquireShared(arg);\n                    if (r >= 0) {\n                        setHeadAndPropagate(node, r);\n                        p.next = null; // help GC\n                        failed = false;\n                        return true;\n                    }\n                }\n                nanosTimeout = deadline - System.nanoTime();\n                if (nanosTimeout <= 0L)\n                    return false;\n                if (shouldParkAfterFailedAcquire(p, node) && nanosTimeout > spinForTimeoutThreshold)\n                    LockSupport.parkNanos(this, nanosTimeout);\n                if (Thread.interrupted())\n                    throw new InterruptedException();\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n\n### boolean tryAcquire(int arg)\n- AQS没有提供具体实现，需要子类实现\n```\n    protected boolean tryAcquire(int arg) {\n        throw new UnsupportedOperationException();\n    }\n```\n\n### boolean tryRelease(int arg)\n- AQS没有提供具体实现，需要子类实现\n```\n    protected boolean tryRelease(int arg) {\n        throw new UnsupportedOperationException();\n    }\n```\n\n### int tryAcquireShared(int arg)\n- AQS没有提供具体实现，需要子类实现\n```\n    protected int tryAcquireShared(int arg) {\n        throw new UnsupportedOperationException();\n    }\n```\n\n### boolean tryReleaseShared(int arg)\n- AQS没有提供具体实现，需要子类实现\n```\n    protected boolean tryReleaseShared(int arg) {\n        throw new UnsupportedOperationException();\n    }\n```\n\n### boolean isHeldExclusively()\n- AQS没有提供具体实现，需要子类实现\n```\n    protected boolean isHeldExclusively() {\n        throw new UnsupportedOperationException();\n    }\n```\n\n### void acquire(int arg)\n- 以独占的方式去获取资源，忽略中断。\n```\n    public final void acquire(int arg) {\n        //至少执行一次tryAcquire，成功则返回，失败则进行线程阻塞状态，等待唤醒重新获取资源\n        if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n```\n\n### void acquireInterruptibly(int arg)\n- 以独占的方式去获取资源，等待期间会被中断。如果线程本身已经被中断，调用该方法会立即抛出异常\n```\n    public final void acquireInterruptibly(int arg) throws InterruptedException {\n        if (Thread.interrupted())\n            throw new InterruptedException();\n        if (!tryAcquire(arg))\n            doAcquireInterruptibly(arg);\n    }\n```\n\n### boolean tryAcquireNanos(int arg, long nanosTimeout)\n- 带有超时的获取独占资源，也会抛出中断异常\n```\n    public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException {\n        if (Thread.interrupted())\n            throw new InterruptedException();\n        return tryAcquire(arg) ||\n            doAcquireNanos(arg, nanosTimeout);\n    }\n```\n\n### boolean release(int arg)\n- 资源释放\n```\n    public final boolean release(int arg) {\n        //保证原子方式释放资源,同一时刻只能有一个线程成功\n        if (tryRelease(arg)) {\n            Node h = head;\n            if (h != null && h.waitStatus != 0)\n                unparkSuccessor(h);//唤醒当前节点的后继节点所包含的线程\n            return true;\n        }\n        return false;\n    }\n```\n\n### void acquireShared(int arg)\n- 以共享模式获取状态\n```\n    public final void acquireShared(int arg) {\n        //尝试获取共享状态\n        if (tryAcquireShared(arg) < 0)\n            //获取失败进入sync队列\n            doAcquireShared(arg);\n    }\n```\n\n### void acquireSharedInterruptibly(int arg)\n- 相比acquireShared，只是增加了可中断\n```\n    public final void acquireSharedInterruptibly(int arg) throws InterruptedException {\n        if (Thread.interrupted())\n            throw new InterruptedException();\n        if (tryAcquireShared(arg) < 0)\n            doAcquireSharedInterruptibly(arg);\n    }\n```\n\n### boolean tryAcquireSharedNanos(int arg, long nanosTimeout)\n- 在acquireSharedInterruptibly的基础上增加了超时\n```\n    public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)\n            throws InterruptedException {\n        if (Thread.interrupted())\n            throw new InterruptedException();\n        return tryAcquireShared(arg) >= 0 ||\n            doAcquireSharedNanos(arg, nanosTimeout);\n    }\n```\n\n### boolean releaseShared(int arg)\n- 释放共享资源\n```\n    public final boolean releaseShared(int arg) {\n        //尝试释放共享资源\n        if (tryReleaseShared(arg)) {\n            //唤醒的过程，上文已经分析\n            doReleaseShared();\n            return true;\n        }\n        return false;\n    }\n```\n\n### boolean hasQueuedThreads()\n- 队列中是否有线程在等待获取资源\n```\n    public final boolean hasQueuedThreads() {\n        return head != tail;\n    }\n```\n\n### boolean hasContended()\n- 是否其他线程也竞争获取资源(因为head是公用的)\n```\n    public final boolean hasContended() {\n        return head != null;\n    }\n```\n\n### Thread getFirstQueuedThread()\n- 返回队列中的第一个线程，如果快速路径失败(head == tail)，则调用fullGetFirstQueuedThread查找\n```\n    public final Thread getFirstQueuedThread() {\n        // handle only fast path, else relay\n        return (head == tail) ? null : fullGetFirstQueuedThread();\n    }\n```\n\n### Thread fullGetFirstQueuedThread()\n- 返回队列中第一个（等待时间最长的）线程，如果目前没有将任何线程加入队列，则返回 null.\n- 在此实现中，该操作是以固定时间返回的，但是，如果其他线程目前正在并发修改该队列，则可能出现循环争用。\n```\n    private Thread fullGetFirstQueuedThread() {\n        Node h, s;\n        Thread st;\n        if (((h = head) != null && (s = h.next) != null &&\n             s.prev == head && (st = s.thread) != null) ||\n            ((h = head) != null && (s = h.next) != null &&\n             s.prev == head && (st = s.thread) != null))\n            return st;\n        Node t = tail;\n        Thread firstThread = null;\n        while (t != null && t != head) {\n            Thread tt = t.thread;\n            if (tt != null)\n                firstThread = tt;\n            t = t.prev;\n        }\n        return firstThread;\n    }\n```\n\n### boolean isQueued(Thread thread)\n- 判断thread是否在队列中等待获取资源\n```\n    public final boolean isQueued(Thread thread) {\n        if (thread == null)\n            throw new NullPointerException();\n        for (Node p = tail; p != null; p = p.prev)\n            if (p.thread == thread)\n                return true;\n        return false;\n    }\n```\n\n### boolean apparentlyFirstQueuedIsExclusive()\n- 在head不为null，head的next不为null，head的next不是共享的，head的thread不为空的条件下返回true，否则返回false\n- 作用就是读锁不应该让写锁始终等待。\n```\n    final boolean apparentlyFirstQueuedIsExclusive() {\n        Node h, s;\n        return (h = head) != null &&\n            (s = h.next)  != null &&\n            !s.isShared()         &&\n            s.thread != null;\n    }\n```\n\n### boolean hasQueuedPredecessors()\n- 判断当前线程是不是在CLH队列的队首，来返回AQS中是不是有比当前线程等待更久的线程。\n```\n    public final boolean hasQueuedPredecessors() {\n        Node t = tail; // Read fields in reverse initialization order\n        Node h = head;\n        Node s;\n        return h != t &&\n            ((s = h.next) == null || s.thread != Thread.currentThread());\n    }\n```\n\n### int getQueueLength()\n- 获取队列长度\n```\n    public final int getQueueLength() {\n        int n = 0;\n        for (Node p = tail; p != null; p = p.prev) {\n            if (p.thread != null)\n                ++n;\n        }\n        return n;\n    }\n```\n\n### Collection<Thread> getQueuedThreads()\n- 获取线程队列\n```\n    public final Collection<Thread> getQueuedThreads() {\n        ArrayList<Thread> list = new ArrayList<Thread>();\n        for (Node p = tail; p != null; p = p.prev) {\n            Thread t = p.thread;\n            if (t != null)\n                list.add(t);\n        }\n        return list;\n    }\n```\n\n### Collection<Thread> getExclusiveQueuedThreads()\n- 获取独占资源的线程队列\n```\n    public final Collection<Thread> getExclusiveQueuedThreads() {\n        ArrayList<Thread> list = new ArrayList<Thread>();\n        for (Node p = tail; p != null; p = p.prev) {\n            if (!p.isShared()) {\n                Thread t = p.thread;\n                if (t != null)\n                    list.add(t);\n            }\n        }\n        return list;\n    }\n```\n\n### Collection<Thread> getSharedQueuedThreads()\n- 获取共享资源的线程队列\n```\n    public final Collection<Thread> getSharedQueuedThreads() {\n        ArrayList<Thread> list = new ArrayList<Thread>();\n        for (Node p = tail; p != null; p = p.prev) {\n            if (p.isShared()) {\n                Thread t = p.thread;\n                if (t != null)\n                    list.add(t);\n            }\n        }\n        return list;\n    }\n```\n\n### boolean isOnSyncQueue(Node node)\n- 判断该节点是否在CLH队列中\n```\n    final boolean isOnSyncQueue(Node node) {\n        //如果该节点的状态为CONDITION（该状态只能在CONDITION队列中出现，CLH队列中不会出现CONDITION状态），或者该节点的prev指针为null，则该节点一定不在CLH队列中\n        if (node.waitStatus == Node.CONDITION || node.prev == null)\n            return false;\n        //如果该节点的next（不是nextWaiter，next指针在CLH队列中指向下一个节点）状态不为null，则该节点一定在CLH队列中\n        if (node.next != null) // If has successor, it must be on queue\n            return true;\n        //遍历CLH队列（从尾节点开始遍历）查找该节点            \n        return findNodeFromTail(node);\n    }\n```\n\n### boolean findNodeFromTail(Node node) \n- 从tail往前寻找节点\n```\n    private boolean findNodeFromTail(Node node) {\n        Node t = tail;\n        for (;;) {\n            if (t == node)\n                return true;\n            if (t == null)\n                return false;\n            t = t.prev;\n        }\n    }\n```\n\n### boolean transferForSignal(Node node)\n- 将节点添加到CLH队列中\n```\n    final boolean transferForSignal(Node node) {\n        //如果CAS失败，则当前节点的状态为CANCELLED\n        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n            return false;\n        //首先enq将该node添加到CLH队列中\n        Node p = enq(node);\n        int ws = p.waitStatus;\n        //如果p是一个取消(ws > 0)了的节点，或者对p进行CAS设置失败，则唤醒node节点，让node所在线程进入到acquireQueue方法中，重新进行相关操作\n\t\t//否则，由于该节点的前驱节点已经是signal状态了，不用在此处唤醒await中的线程，唤醒工作留给CLH队列中前驱节点\n        if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n            LockSupport.unpark(node.thread);//唤醒\n        return true;\n    }\n```\n\n### boolean transferAfterCancelledWait(Node node)\n- 将当前Node强制transfer到CLH队列中\n```\n    final boolean transferAfterCancelledWait(Node node) {\n        //将该节点状态由CONDITION变成0，调用enq将该节点从CONDITION队列添加到CLH队列中（但是在CONDITION队列中的nextWaiter连接并没有取消）\n        if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {\n            enq(node);\n            return true;\n        }\n        //循环检测该node是否已经成功添加到CLH队列中\n        while (!isOnSyncQueue(node))\n            Thread.yield();\n        return false;\n    }\n```\n\n### int fullyRelease(Node node)\n- 完全释放锁,释放成功则返回，失败则将当前节点的状态设置成cancelled表示当前节点失效\n```\n    final int fullyRelease(Node node) {\n        boolean failed = true;\n        try {\n            int savedState = getState();\n            if (release(savedState)) {\n                failed = false;\n                return savedState;\n            } else {\n                throw new IllegalMonitorStateException();\n            }\n        } finally {\n            if (failed)\n                node.waitStatus = Node.CANCELLED;//失败则当前node状态为CANCELLED\n        }\n    }\n```\n\n### boolean owns(ConditionObject condition)\n- 判断条件对象拥有者\n```\n    public final boolean owns(ConditionObject condition) {\n        return condition.isOwnedBy(this);\n    }\n```\n\n### boolean hasWaiters(ConditionObject condition)\n- 条件队列是否有等待者\n```\n    public final boolean hasWaiters(ConditionObject condition) {\n        if (!owns(condition))\n            throw new IllegalArgumentException(\"Not owner\");\n        return condition.hasWaiters();\n    }\n```\n\n### int getWaitQueueLength(ConditionObject condition)\n- 获取条件队列等待者数量\n```\n    public final int getWaitQueueLength(ConditionObject condition) {\n        if (!owns(condition))\n            throw new IllegalArgumentException(\"Not owner\");\n        return condition.getWaitQueueLength();\n    }\n```\n\n### Collection<Thread> getWaitingThreads(ConditionObject condition)\n- 获取条件队列等待者线程\n```\n    public final Collection<Thread> getWaitingThreads(ConditionObject condition) {\n        if (!owns(condition))\n            throw new IllegalArgumentException(\"Not owner\");\n        return condition.getWaitingThreads();\n    }\n```\n\n\n\n## 辅助Field及方法\n就不一一解释了\n- Cas相关Field\n    - Unsafe unsafe;\n    - long stateOffset;\n    - long headOffset;\n    - long tailOffset;\n    - long waitStatusOffset;\n    - long nextOffset;\n- Cas相关Method\n    - boolean compareAndSetHead(Node update)\n    - boolean compareAndSetTail(Node expect, Node update)\n    - boolean compareAndSetWaitStatus(Node node, int expect, int update)\n    - boolean compareAndSetNext(Node node, Node expect, Node update)\n\n\n# 参考\n\n- 《Java并发编程之美》\n- https://blog.csdn.net/u011470552/article/details/76571472\n- https://www.jianshu.com/p/4eef16131bb8\n- https://www.jianshu.com/p/e4301229f59e\n- https://blog.csdn.net/weixin_34235371/article/details/87147929\n- https://blog.csdn.net/lkg_vvk/article/details/79130070","tags":["Java","ThreadPool","多线程","AbstractQueuedSynchronizer","AQS"],"categories":["Java"]},{"title":"Java线程池分析-AbstractExecutorService","url":"/2019/07/08/Java线程池分析-AbstractExecutorService/","content":"\n内部只有若干方法\n\n# 内部依赖方法\n\n## newTaskFor(Runnable runnable, T value)\n- 构造一个FutureTask，FutureTask 实现了 RunnableFuture，既是Runnable接口，也是Future接口，类似于适配器。\n    ```\n    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\n        return new FutureTask<T>(runnable, value);\n    }\n    ```\n## newTaskFor(Callable<T> callable)\n- 同上，将一个Callable适配到RunnableFuture\n    ```\n    protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {\n        return new FutureTask<T>(callable);\n    }\n    ```\n\n# submit 提交任务方法\n\n## submit(Runnable task)\n- 将Runnable接口封装为 RunnableFuture<Void>，并由子类实现执行逻辑\n    ```\n    public Future<?> submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<Void> ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }\n    ```\n\n## submit(Runnable task, T result)\n- 将Runnable接口封装为 RunnableFuture<T>，并由子类实现执行逻辑\n    ```\n    public <T> Future<T> submit(Runnable task, T result) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<T> ftask = newTaskFor(task, result);\n        execute(ftask);\n        return ftask;\n    }\n    ```\n\n## submit(Callable<T> task)\n- 将Callable接口封装为 RunnableFuture<T>，并由子类实现执行逻辑\n    ```\n    public <T> Future<T> submit(Callable<T> task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<T> ftask = newTaskFor(task);\n        execute(ftask);\n        return ftask;\n    }\n    ```\n\n# Invoke系列方法\n\n## doInvokeAny\n- 执行tasks任务，可以指定是否带有超时参数。invokeAny方法底层依赖该方法\n    ```\n    private <T> T doInvokeAny(Collection<? extends Callable<T>> tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException {\n        if (tasks == null)\n            throw new NullPointerException();\n        int ntasks = tasks.size();\n        if (ntasks == 0)\n            throw new IllegalArgumentException();\n        //全部task对应的future集合\n        ArrayList<Future<T>> futures = new ArrayList<Future<T>>(ntasks);\n        //实际执行的实体\n        ExecutorCompletionService<T> ecs = new ExecutorCompletionService<T>(this);\n        try {\n            ExecutionException ee = null;\n            //是否需要超时\n            final long deadline = timed ? System.nanoTime() + nanos : 0L;\n            Iterator<? extends Callable<T>> it = tasks.iterator();\n            //先提交一个任务\n            futures.add(ecs.submit(it.next()));\n            //任务数减一\n            --ntasks;\n            //工作中的线程数为1\n            int active = 1;\n            for (;;) {\n                Future<T> f = ecs.poll();//获取一个执行的任务\n                //判断任务是否完成，为null则还没有执行完成\n                if (f == null) {\n                    //提交的任务是否已经全部由ecs执行，如果还有未提交的，则继续提交。\n                    if (ntasks > 0) {\n                        --ntasks;\n                        futures.add(ecs.submit(it.next()));\n                        ++active;\n                    }\n                    else if (active == 0)//没有存活的任务，说明任务已经完成，但是有异常，导致active=0，则中断循环，然后抛出异常\n                        break;\n                    else if (timed) {//检查是否需要超时\n                        f = ecs.poll(nanos, TimeUnit.NANOSECONDS);\n                        if (f == null)\n                            throw new TimeoutException();\n                        nanos = deadline - System.nanoTime();\n                    }\n                    else\n                        f = ecs.take();//不许要超时，则阻塞获取\n                }\n                if (f != null) {//有任务完成，active数量减一，并返回结果\n                    --active;\n                    try {\n                        return f.get();\n                    } catch (ExecutionException eex) {\n                        ee = eex;\n                    } catch (RuntimeException rex) {\n                        ee = new ExecutionException(rex);\n                    }\n                }\n            }\n            if (ee == null)\n                ee = new ExecutionException();\n            throw ee;\n        } finally {\n            for (int i = 0, size = futures.size(); i < size; i++)\n                futures.get(i).cancel(true);//已经完成或者抛出异常，取消其他正在执行的任务。\n        }\n    }\n    ```\n\n## invokeAny\n- 忽略超时异常的执行方式\n    ```\n    public <T> T invokeAny(Collection<? extends Callable<T>> tasks) throws InterruptedException, ExecutionException {\n        try {\n            return doInvokeAny(tasks, false, 0);\n        } catch (TimeoutException cannotHappen) {//忽略超时异常\n            assert false;\n            return null;\n        }\n    }\n    ```\n\n- 可以设置超时的执行方式\n    ```\n    public <T> T invokeAny(Collection<? extends Callable<T>> tasks,long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n        return doInvokeAny(tasks, true, unit.toNanos(timeout));//会抛出超时异常\n    }\n    ```\n\n## invokeAll\n- 全部执行并等待全部完成\n    ```\n    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks) throws InterruptedException {\n        if (tasks == null)\n            throw new NullPointerException();\n        ArrayList<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());\n        boolean done = false;\n        try {\n            //全部任务提交并执行\n            for (Callable<T> t : tasks) {\n                RunnableFuture<T> f = newTaskFor(t);\n                futures.add(f);\n                execute(f);\n            }\n            //等待全部结果完成\n            for (int i = 0, size = futures.size(); i < size; i++) {\n                Future<T> f = futures.get(i);\n                if (!f.isDone()) {\n                    try {\n                        f.get();\n                    } catch (CancellationException ignore) {\n                    } catch (ExecutionException ignore) {\n                    }\n                }\n            }\n            //全部完成后标示位更新\n            done = true;\n            return futures;\n        } finally {\n            if (!done)//如果没有完成，说明有异常，则取消所有任务\n                for (int i = 0, size = futures.size(); i < size; i++)\n                    futures.get(i).cancel(true);\n        }\n    }\n    ```\n- 全部执行，并带有超时的等待完成\n    ```\n    public <T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,long timeout, TimeUnit unit)\n        throws InterruptedException {\n        if (tasks == null)\n            throw new NullPointerException();\n        long nanos = unit.toNanos(timeout);\n        ArrayList<Future<T>> futures = new ArrayList<Future<T>>(tasks.size());\n        boolean done = false;\n        try {\n            for (Callable<T> t : tasks)\n                futures.add(newTaskFor(t));\n            final long deadline = System.nanoTime() + nanos;\n            final int size = futures.size();\n            //提交任务\n            for (int i = 0; i < size; i++) {\n                execute((Runnable)futures.get(i));\n                //计算超时时间\n                nanos = deadline - System.nanoTime();\n                if (nanos <= 0L)\n                    return futures;\n            }\n            //获取结果\n            for (int i = 0; i < size; i++) {\n                Future<T> f = futures.get(i);\n                if (!f.isDone()) {\n                    if (nanos <= 0L)//已经超时，则直接返回现有的\n                        return futures;\n                    try {\n                        f.get(nanos, TimeUnit.NANOSECONDS);//带有超时的去获取，如果超时，则直接返回结果\n                    } catch (CancellationException ignore) {\n                    } catch (ExecutionException ignore) {\n                    } catch (TimeoutException toe) {\n                        return futures;\n                    }\n                    nanos = deadline - System.nanoTime();\n                }\n            }\n            done = true;//正常完成\n            return futures;\n        } finally {\n            if (!done)//非正常完成，则取消剩余任务\n                for (int i = 0, size = futures.size(); i < size; i++)\n                    futures.get(i).cancel(true);\n        }\n    }\n    ```","tags":["Java","ThreadPool","AbstractExecutorService","多线程"],"categories":["Java"]},{"title":"Java线程池分析-Worker","url":"/2019/07/08/Java线程池分析-Worker/","content":"\n\n# 结构\n\n其实从结构上来看,Worker十分简单。实现了Runnable接口，同时继承了AQS队列。如下图所示:\n![类结构](Java线程池分析-Worker/WorkerClass.png)\n\nWorker的方法也不多，也比较简单，如下图所示:\n![方法](Java线程池分析-Worker/Method.png)\n\n# 分析\n## 内部Field\n- 内部Field不多，如下：\n    - Thread thread 实际的工作线程\n    - Runnable firstTask 初始化的第一个任务\n    - long completedTasks 当前Worker已经完成的任务数\n- 在补充一下父类的state\n    - 0 代表是未锁定状态\n    - 1 代表是锁定状态\n    - -1 代表是不允许被中断，在构造参数中设置\n接下来简单分析一下各个方法:\n\n## 方法\n### public void run()\n- 直接调用线程池的runWorker方法，之后分析\n    ```\n    public void run() {\n        runWorker(this);\n    }\n    ```\n### protected boolean isHeldExclusively()\n- 是否是独占排他的\n    ```\n    protected boolean isHeldExclusively() {\n        return getState() != 0;\n    }\n    ```\n### protected boolean tryAcquire(int unused)\n- 尝试获取锁，参考AQS，这里还是使用CAS进行操作，失败则快速返回\n    ```\n    protected boolean tryAcquire(int unused) {\n        if (compareAndSetState(0, 1)) {\n            setExclusiveOwnerThread(Thread.currentThread());\n            return true;\n        }\n        return false;\n    }\n    ```\n### protected boolean tryRelease(int unused)\n- 尝试释放锁，这个貌似只会成功，不会失败\n    ```\n    protected boolean tryRelease(int unused) {\n        setExclusiveOwnerThread(null);\n        setState(0);\n        return true;\n    }\n    ```\n### public void lock()\n- 加锁，不过这里是阻塞式的\n    ```\n    public void lock()        { acquire(1); }\n    ```\n### public boolean tryLock()\n- 尝试加锁，调用tryAcquire\n    ```\n    public boolean tryLock()  { return tryAcquire(1); }\n    ```\n### public void unlock()\n- 释放锁操作，参考AQS\n    ```\n    public void unlock()      { release(1); }\n    ```\n### public boolean isLocked()\n- 是否处于锁定状态，调用isHeldExclusively方法，也就是看state是否为0\n    ```\n    public boolean isLocked() { return isHeldExclusively(); }\n    ```\n### void interruptIfStarted()\n- 如果处于运行状态，则进行中断。state>=0代表可以进行中断。\n    ```\n    void interruptIfStarted() {\n        Thread t;\n        if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {\n            try {\n                t.interrupt();\n            } catch (SecurityException ignore) {\n            }\n        }\n    }\n    ```\n## 关联方法\n### runWorker\n\n- Worker直接调用线程池的runWorker方法，将自身作为参数，执行任务，具体如下：\n    ```\n    final void runWorker(Worker w) {\n        //当前工作线程\n        Thread wt = Thread.currentThread();\n        //获取待执行的初始任务\n        Runnable task = w.firstTask;\n        //清除firstTask\n        w.firstTask = null;\n        //释放w锁(这个时候可以进行中断操作)\n        w.unlock(); // allow interrupts\n        boolean completedAbruptly = true;\n        try {\n            //开始循环获取任务\n            while (task != null || (task = getTask()) != null) {\n                //获取任务之后先进行加锁\n                w.lock();\n                //检查线程池状态，是否需要中断。\n                //这块逻辑比较绕，整理一下\n                // 首先wt也就是当前线程，不能被中断。\n                // 如果线程池的状态为STOP，TIDYING，TERMINATED 则直接中断\n                // （剩下的就是原文中的注释了）如果线程池正在停止过程中，确保线程是中断的。否则就确保线程不会被中断。\n                if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(),STOP))) && !wt.isInterrupted())\n                    wt.interrupt();\n                try {\n                    beforeExecute(wt, task);//这里实际上是空实现\n                    Throwable thrown = null;\n                    try {\n                        task.run();//实际执行\n                    } catch (RuntimeException x) {\n                        thrown = x; throw x;\n                    } catch (Error x) {\n                        thrown = x; throw x;\n                    } catch (Throwable x) {\n                        thrown = x; throw new Error(x);\n                    } finally {\n                        afterExecute(task, thrown);//这里也是空实现\n                    }\n                } finally {\n                    task = null;\n                    w.completedTasks++;//执行完成后，完成任务+1\n                    w.unlock();//执行完成后释放锁\n                }\n            }\n            completedAbruptly = false;\n        } finally {\n            //清理工作，执行到这里代表Worker已经准备销毁了\n            processWorkerExit(w, completedAbruptly);\n        }\n    }\n    ```\n\n## getTask\n- 获取任务的方法\n    ```\n    private Runnable getTask() {\n        boolean timedOut = false; // Did the last poll() time out?\n        for (;;) {\n            //先检查线程池的状态\n            int c = ctl.get();\n            int rs = runStateOf(c);\n            //如果已经关闭并且队列为空则返回null，并减少一个工作线程\n            //如果已经为STOP，TIDYING，TERMINATED 则减少一个工作线程\n            if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n                decrementWorkerCount();\n                return null;\n            }\n            //获取工作线程数量\n            int wc = workerCountOf(c);\n            //判断是否需要清理Worker\n            // 一种是allowCoreThreadTimeOut=true的情况\n            //一种是工作线程数量已经超过核心线程数量了\n            boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n            //状态检查\n            //满足以下两个条件，则会减少工作线程数量\n            //1.已经超时或者工作线程数量超过最大线程数量的\n            //2.至少有一个工作线程或者任务队列为空\n            if ((wc > maximumPoolSize || (timed && timedOut))\n                && (wc > 1 || workQueue.isEmpty())) {\n                if (compareAndDecrementWorkerCount(c))\n                    return null;\n                continue;\n            }\n            try {\n                //\n                Runnable r = timed ?\n                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) ://带有超时的方式获取，超时之后返回null\n                    workQueue.take();//阻塞方式获取\n                //没有超时则返回结果，否则设置超时状态\n                if (r != null)\n                    return r;\n                timedOut = true;\n            } catch (InterruptedException retry) {\n                timedOut = false;\n            }\n        }\n    }\n    ```\n\n## processWorkerExit\n- 做一些收尾工作\n    ```\n        private void processWorkerExit(Worker w, boolean completedAbruptly) {\n            if (completedAbruptly) // 还记得runWork方法中的completedAbruptly么，就是这个了，为true代表没有执行的改变为false，突然执行到这里了。\n                decrementWorkerCount();//减少工作线程数量\n\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                completedTaskCount += w.completedTasks;//更新一下总共完成的任务\n                workers.remove(w);//从Worker集合中中移除自己\n            } finally {\n                mainLock.unlock();\n            }\n            //尝试设置线程池为TERMINATED，见线程池部分分析\n            //线程池为SHUTDOWN且队列为空或者线程池状态为STOP,则触发设置线程池为TERMINATED\n            tryTerminate();\n\n            int c = ctl.get();//获取当前线程池状态\n            if (runStateLessThan(c, STOP)) {//是否已经停止或者终止\n                //是否突然过来的，如果不是突然过来的，代表正常结束\n                if (!completedAbruptly) {\n                    //根据allowCoreThreadTimeOut获取线程池数量最小值\n                    int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\n                    //队列不为空则最小值不能为0\n                    if (min == 0 && ! workQueue.isEmpty())\n                        min = 1;\n                    //当前工作线程数量大于等于最小值，则代表还不能结束，继续执行\n                    if (workerCountOf(c) >= min)\n                        return; // replacement not needed\n                }\n                //执行到这里说明当前线程数量小于min的值，需要添加一个Worker\n                //或者突然执行过来的，可能有异常，添加一个Worker\n                addWorker(null, false);\n            }\n        }\n    ```","tags":["Java","ThreadPool","多线程","Worker"],"categories":["Java"]},{"title":"Java线程池分析-ThreadPoolExecutor","url":"/2019/07/06/Java线程池分析-ThreadPoolExecutor/","content":"\n# 线程池状态\n## 状态\n- RUNNING\n    - 该状态接受新的任务同时处理队列中的任务\n- SHUTDOWN\n    - 该状态不再接受新的任务，但是队列中的任务继续执行\n- STOP\n    - 不再接受新的任务，也不再处理队列中的任务，并且会中断正在运行的任务\n- TIDYING\n    - 所有任务都已经终止，工作线程数为0。调用terminated()方法状态会变为TIDYING\n- TERMINATED\n    - terminated()方法执行完成\n\n## 状态转移\n- RUNNING -> SHUTDOWN\n    - 执行shutdown()方法（SHUTDOWN状态可能立即结束进入下一状态）\n- (RUNNING or SHUTDOWN) -> STOP\n    - 执行shutdownNow()方法\n- SHUTDOWN -> TIDYING\n    - 当所有任务队列和线程池(pool)都空的了时候\n- STOP -> TIDYING\n    - 当线程池(pool)为空的时候\n- TIDYING -> TERMINATED\n    - terminated()方法完成\nawaitTermination()在状态变为TERMINATED的时候返回\n\n## 状态位表示 \n状态位在线程池中使用一个原子类型的Integer进行存储\n```\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n```\nInteger的长度是32位，用全部32位来表示线程数量，有点浪费。线程池的状态一共就5种，所以大神决定用ctl的高3位（可以表示8种状态了），来表示线程池的状态，低29位用来计数（大约500_000_000），反正就目前机器来说，想同时开启这么多线程。。。机器早就挂了，所以足够了\n\n# 几个底层依赖的方法\n- private static int runStateOf(int c)     { return c & ~CAPACITY; }\n    - 通过位运算，获取当前线程池的状态\n- private static int workerCountOf(int c)  { return c & CAPACITY; }\n    - 通过位运算，获取当前线程池的工作线程数\n- private static int ctlOf(int rs, int wc) { return rs | wc; }\n    - 为了看ctl的状态\n- 然后就是几个关于ctl的cas操作，包括增加一个线程计数，减少一个线程计数\n\n# 几个重要的Field\n- private final BlockingQueue<Runnable> workQueue;\n    - 关键参数，设置线程池corePoolSize满了以后，要将任务放到什么样的阻塞队列中。\n- private final ReentrantLock mainLock = new ReentrantLock();\n    - 内部锁，在很多方法中均有用到，包括添加Worker，中断Worker，shutdown，以及获取各种size都需要锁进行同步保护\n- private final HashSet<Worker> workers = new HashSet<Worker>();\n    - 可以理解为线程的集合，Worker 继承了 AQS 并且实现了 Runnable，也就是线程池中对应的线程的集合。\n- private final Condition termination = mainLock.newCondition();\n    - 在 tryTerminate() 方法中进行通知，awaitTermination(long timeout, TimeUnit unit)方法中进行awaitNanos，也就是说调用awaitTermination方法之后，会一直等待，直到tryTerminate方法执行并且通知，才会结束（这时候线程池应该就变为TERMINATED状态了）\n- private int largestPoolSize;\n    - 记录线程池中线程数量曾经达到过的最大值。\n- private long completedTaskCount;\n    - 这个从字面意思就很好立即了，已经完成的任务数量\n- private volatile ThreadFactory threadFactory;\n    - 又一个核心参数，线程的创建工厂，各种大厂的Java开发规范都需要业务自己实现对应的线程工厂，定义线程的名称之类的，主要是后期排查多线程问题的时候方便定位。\n- private volatile RejectedExecutionHandler handler;\n    - 也是核心参数，当线程池达到饱和状态（队列满了，maximumPoolSize也达到了），如果还在继续提交的任务，就依靠这个进行处理。\n    - 默认有4个实现类，如下：\n        - CallerRunsPolicy，这个就是将任务返回给调用方，由调用方执行。\n        - AbortPolicy，这个比较粗暴，直接抛出异常。也是默认实现，参考defaultHandler\n        - DiscardPolicy，这个应该很少用，直接丢弃提交的任务，Do Nothing\n        - DiscardOldestPolicy，这个也是丢弃，不过是丢弃队列中最早的一个（直接调用peeK）\n- private volatile long keepAliveTime;\n    - 核心参数之一，线程空闲多久后回收（默认如果小于corePoolSize，则不进行回收）\n- private volatile boolean allowCoreThreadTimeOut;\n    - allowCoreThreadTimeOut，core线程是否超时后回收，默认是false\n- private volatile int corePoolSize;\n    - 核心参数，core线程池大小\n- private volatile int maximumPoolSize;\n    - 核心参数，最大线程池大小（超过这个值就会调用RejectedExecutionHandler）\n- private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();\n    - 默认Rejected处理策略，抛出异常\n- private static final RuntimePermission shutdownPerm = new RuntimePermission(\"modifyThread\");\n    - 这个真不太清楚，只知道是在调用shutdown相关方法会调用进行安全检查\n- private final AccessControlContext acc;\n    - 在finalize方法中有调用，看不太明白 = =，貌似也是权限访问层面的（AccessController.doPrivileged(pa, acc);）\n\n# 几个重要的 public 方法\n\n- public void execute(Runnable command)\n    - 提交一个Runnable任务，描述很简单，实现应该是所有方法中最复杂的了，话不多说，直接上源码。\n```\n    public void execute(Runnable command) {\n        if (command == null)\n            throw new NullPointerException();//不允许提交null\n        int c = ctl.get();\n        //检查目前工作线程数量是否超过了corePoolSize，没有超过的话直接添加任务，添加成功就返回，添加失败则更新状态值c然后继续\n        if (workerCountOf(c) < corePoolSize) {\n            if (addWorker(command, true))//参数为true则添加的是core线程\n                return;\n            c = ctl.get();\n        }\n        //执行到这里肯定是添加worker失败或者已经达到了corePoolSize\n        //这时候检查线程状态，确保是Running(因为有可能这期间其他线程调用了shutdown等方法)，就开始往队列中添加任务。\n        if (isRunning(c) && workQueue.offer(command)) {\n            int recheck = ctl.get();\n            //添加到队列之后，再次检查线程池状态，如果状态发生变化，则移除任务并执行拒绝策略\n            //如果状态没有发生改变，此时如果线程池为空，那就添加一个非核心Worker\n            if (! isRunning(recheck) && remove(command))\n                reject(command);\n            else if (workerCountOf(recheck) == 0)\n                addWorker(null, false);\n        }//到这里说明添加队列失败，要么是线程池编程非RUNNING状态，要么队列满了，则添加非核心线程，非核心线程如果添加还是失败了，就只能执行拒绝策略了\n        else if (!addWorker(command, false))\n            reject(command);\n    }\n    //上面的步骤还不算复杂，接下就是最复杂的addWorker方法了。\n    private boolean addWorker(Runnable firstTask, boolean core) {\n        retry:   //标记位，用于循环控制，也就是外层循环\n        for (;;) {\n            int c = ctl.get();\n            int rs = runStateOf(c);//当前线程池状态\n            //如果线程池状态如下，则返回添加失败\n            // 1. 线程池状态为STOP，TIDYING，TERMINATED中的一个\n            // 2. 线程池状态为SHUTDOWN，并且第一个任务不为空\n            // 3. 线程池状态为SHUTDOWN，并且工作队列为空\n            if (rs >= SHUTDOWN &&\n                ! (rs == SHUTDOWN &&\n                   firstTask == null &&\n                   ! workQueue.isEmpty()))\n                return false;\n            //开始内层循环，执行到这里说明不是上述123中的状态。\n            for (;;) {\n                int wc = workerCountOf(c);//获取工作线程数量\n                //检查是否达到上限，并根据添加的线程类别(core或者非core)判断是否超过对应的最大值，超过也返回false\n                if (wc >= CAPACITY ||\n                    wc >= (core ? corePoolSize : maximumPoolSize))\n                    return false;\n                if (compareAndIncrementWorkerCount(c))//上述校验通过以后，CAS方式增加一个工作线程，如果成功了，则跳出外层循环\n                    break retry;\n                //执行到这里说明cas方式增加线程失败，那就重新检查一下线程池状态，然后内层循环继续，直到增加成功。\n                c = ctl.get();  // Re-read ctl\n                if (runStateOf(c) != rs)\n                    continue retry;\n                // else CAS failed due to workerCount change; retry inner loop\n            }\n        }\n        //执行到这里，说明已经成功增加了一个线程计数了。\n        boolean workerStarted = false;\n        boolean workerAdded = false;\n        Worker w = null;\n        try {\n            w = new Worker(firstTask);//使用第一个任务创建一个Worker\n            final Thread t = w.thread;//获取对应worker的线程\n            if (t != null) {\n                final ReentrantLock mainLock = this.mainLock;\n                mainLock.lock();\n                try {\n                    // Recheck while holding lock.\n                    // Back out on ThreadFactory failure or if\n                    // shut down before lock acquired.\n                    int rs = runStateOf(ctl.get());//检查线程池的状态\n                    //线程池状态是运行的或者刚刚关闭，第一个任务尚未赋值\n                    if (rs < SHUTDOWN ||\n                        (rs == SHUTDOWN && firstTask == null)) {\n                        //这里确保线程还没有被其他线程启动\n                        if (t.isAlive()) // precheck that t is startable\n                            throw new IllegalThreadStateException();\n                        //添加worker到workers集合中\n                        workers.add(w);\n                        int s = workers.size();\n                        //对比并更新最大到达数量\n                        if (s > largestPoolSize)\n                            largestPoolSize = s;\n                        workerAdded = true;//表示已经增加了worker\n                    }\n                } finally {\n                    mainLock.unlock();\n                }\n                //如果已经成功增加了worker，就可以启动对应的线程了。\n                if (workerAdded) {\n                    t.start();\n                    workerStarted = true;\n                }\n            }\n        } finally {\n            //这里检查一下worker是否已经启动成功，如果没有启动成功，则执行添加失败操作\n            if (! workerStarted)\n                addWorkerFailed(w);\n        }\n        return workerStarted;//返回工作线程是否启动成功\n    }\n    //简单看一下添加失败的逻辑\n    private void addWorkerFailed(Worker w) {\n        final ReentrantLock mainLock = this.mainLock;\n        mainLock.lock();\n        try {\n            if (w != null)\n                workers.remove(w);//添加失败则移除掉Set集合中对应的worker\n            //并且减少一个工作线程数量计数\n            decrementWorkerCount();\n            //尝试关闭线程池（感觉这里是为了释放空闲线程）\n            tryTerminate();\n        } finally {\n            mainLock.unlock();\n        }\n    }\n```\n- public void shutdown() \n    - 尝试关闭线程池，执行后状态变为SHUTDOWN，继续完成已经提交的任务，但是新的任务不再被接受。\n    ```\n        public void shutdown() {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                checkShutdownAccess();//检查访问权？（这块有点懵）\n                advanceRunState(SHUTDOWN);//检查是否可以设置为SHUTDOWN并通过CAS操作设置为SHUTDOWN\n                interruptIdleWorkers();//中断线程\n                onShutdown(); // hook for ScheduledThreadPoolExecutor ，这里是空实现\n            } finally {\n                mainLock.unlock();\n            }\n            tryTerminate();//检测并尝试终止线程池\n        }\n    ```\n    - 几个内部调用的方法方法\n    ```\n        private void advanceRunState(int targetState) {\n            for (;;) {\n                int c = ctl.get();\n                //传参数为SHUTDOWN，则runStateAtLeast在SHUTDOWN、STOP、TIDYING和TERMINATED状态的时候为true，直接跳出循环。如果线程池状态为RUNNING，则进行CAS操作，更新状态位为SHUTDOWN，成功则结束。\n                if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))\n                    break;\n            }\n        }\n        \n        private void interruptIdleWorkers() {\n            interruptIdleWorkers(false);//中断所有线程，如果参数为true，则仅中断一个线程，具体见下\n        }\n\n        private void interruptIdleWorkers(boolean onlyOne) {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                for (Worker w : workers) {\n                    Thread t = w.thread;\n                    //线程处于非中断状态，并且没有其他线程中断该线程（也就是说只能有一个线程进行中断操作）\n                    if (!t.isInterrupted() && w.tryLock()) {\n                        try {\n                            t.interrupt();//依次中断\n                        } catch (SecurityException ignore) {\n                        } finally {\n                            w.unlock();\n                        }\n                    }\n                    if (onlyOne)//如果为true，则中断一个后跳出循环\n                        break;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n        }\n        //一个空实现\n        void onShutdown() {\n            \n        }\n\n    final void tryTerminate() {\n        for (;;) {\n            int c = ctl.get();\n            if (isRunning(c) ||//正在运行中，不能设置为TIDYING\n                runStateAtLeast(c, TIDYING) ||//线程池为TIDYING或者TERMINATED，其他线程已经开始关闭线程池\n                (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))//队列中尚有需要执行的任务，需要等待执行完成，不能设置为TIDYING\n                return;\n            //上面一坨条件判断说白了就是在等线程池状态为SHUTDOWN并且队列为空或者线程池状态为STOP才会继续，否则放弃终止操作。\n\n            if (workerCountOf(c) != 0) { // Eligible to terminate\n                interruptIdleWorkers(ONLY_ONE);//ONLY_ONE在这里为true，也就是仅仅中断一个空闲的worker。\n                //补充一下：interruptIdleWorkers的作用是因为在getTask方法中执行workQueue.take()时，如果不执行中断会一直阻塞。在shutdown方法中，会中断所有空闲的工作线程，如果在执行shutdown时工作线程没有空闲，然后又去调用了getTask方法，这时如果workQueue中没有任务了，调用workQueue.take()时就会一直阻塞。所以每次在工作线程结束时调用tryTerminate方法来尝试中断一个空闲工作线程，避免在队列为空时取任务一直阻塞的情况。(引用自：https://www.cnblogs.com/liuzhihu/p/8177371.html)\n                return;\n            }\n\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {//CAS操作将线程池设置为TIDYING状态\n                    try {\n                        terminated();//执行一些清理操作\n                    } finally {\n                        ctl.set(ctlOf(TERMINATED, 0));//设置线程池状态为TERMINATED\n                        termination.signalAll();//通知条件变量termination（也就是awaitTermination方法可以继续执行了）\n                    }\n                    return;\n                }\n            } finally {\n                mainLock.unlock();\n            }\n            // else retry on failed CAS\n        }\n    }\n\n    ```\n\n- public List<Runnable> shutdownNow()\n    - 立即关闭线程池，设置状态为STOP，不再接受新的任务，并且中断正在运行的任务，返回队列中未执行的任务。\n    ```\n        public List<Runnable> shutdownNow() {\n            List<Runnable> tasks;\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                checkShutdownAccess();//检查访问权？（这块有点懵）\n                advanceRunState(STOP);//cas方式设置状态为STOP\n                interruptWorkers();//中断正在运行的线程\n                tasks = drainQueue();//将队列中未执行的任务返回\n            } finally {\n                mainLock.unlock();\n            }\n            tryTerminate();//检测并尝试终止线程池\n            return tasks;\n        }\n    ```\n    - 看一下里面具体的方法，checkShutdownAccess、advanceRunState和tryTerminate见上\n    ```\n        private void interruptWorkers() {\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                for (Worker w : workers)//遍历workers集合\n                    w.interruptIfStarted();//依次中断\n            } finally {\n                mainLock.unlock();\n            }\n        }\n        Worker的interruptIfStarted方法如下：\n        void interruptIfStarted() {\n            Thread t;\n            //state小于0是不可中断的标识，只能在大于等于0的时候进行中断\n            if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {\n                try {\n                    t.interrupt();\n                } catch (SecurityException ignore) {\n                }\n            }\n        }\n        //转移队列剩余任务方法\n        private List<Runnable> drainQueue() {\n            BlockingQueue<Runnable> q = workQueue;\n            ArrayList<Runnable> taskList = new ArrayList<Runnable>();\n            q.drainTo(taskList);//将q的所有任务转移到taskList中\n            if (!q.isEmpty()) {//上一步操作可能会失败，再次检查（什么情况会失败？这块我也没太明白）\n                for (Runnable r : q.toArray(new Runnable[0])) {\n                    if (q.remove(r))\n                        taskList.add(r);\n                }\n            }\n            return taskList;\n        }\n    ```\n- public boolean isShutdown()\n    - 通过ctl获取线程池的状态，没啥可说的\n- public boolean isTerminating()\n    - 通过ctl获取线程池的状态，只要不是运行的，不是TERMINATED，就处于这个状态\n- public boolean isTerminated()\n    - 通过ctl获取线程池的状态，并且状态是TERMINATED\n- public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException\n    - 带超时的等待线程池状态变为TERMINATED\n    ```\n        public boolean awaitTermination(long timeout, TimeUnit unit)\n            throws InterruptedException {\n            long nanos = unit.toNanos(timeout);\n            final ReentrantLock mainLock = this.mainLock;\n            mainLock.lock();\n            try {\n                for (;;) {\n                    if (runStateAtLeast(ctl.get(), TERMINATED))//CAS循环判断状态是否为TERMINATED\n                        return true;\n                    if (nanos <= 0)//超时则返回false\n                        return false;\n                    nanos = termination.awaitNanos(nanos);//还记得上面的termination.signalAll()吧，就是这里等待通知\n                }\n            } finally {\n                mainLock.unlock();\n            }\n        }\n    ```\n- public boolean prestartCoreThread()\n    - 调用该方法，则执行启动一个核心线程，源码比较简单，只要不足corePoolSize，就执行增加操作。\n    ```\n        public boolean prestartCoreThread() {\n            return workerCountOf(ctl.get()) < corePoolSize &&\n                addWorker(null, true);\n        }\n    ```\n\n- public int prestartAllCoreThreads()\n    - 一次性启动Core工作线程到corePoolSize，返回启动了几个线程。\n    ```\n        public int prestartAllCoreThreads() {\n            int n = 0;\n            while (addWorker(null, true))\n                ++n;\n            return n;\n        }\n    ```\n- public boolean remove(Runnable task)\n    - 移除一个task，移除操作之后会执行tryTerminate()方法\n    ```\n        public boolean remove(Runnable task) {\n            boolean removed = workQueue.remove(task);\n            //会检查线程池状态，并根据状态决定是否终止线程池（特别针对的场景就是shudown状态+空队列，就可以进入下一个状态）\n            tryTerminate(); // In case SHUTDOWN and now empty\n            return removed;\n        }\n    ```\n- public void purge() \n    - 尝试从队列中移除所有已经取消了的Future任务\n    ```\n        public void purge() {\n            final BlockingQueue<Runnable> q = workQueue;\n            try {\n                Iterator<Runnable> it = q.iterator();\n                while (it.hasNext()) {\n                    Runnable r = it.next();\n                    //移除掉已经取消的Future任务\n                    if (r instanceof Future<?> && ((Future<?>)r).isCancelled())\n                        it.remove();\n                }\n            } catch (ConcurrentModificationException fallThrough) {//遍历过程中发生了其他修改，快速失败采用数组快照方式删除\n                // Take slow path if we encounter interference during traversal.\n                // Make copy for traversal and call remove for cancelled entries.\n                // The slow path is more likely to be O(N*N).\n                for (Object r : q.toArray())\n                    if (r instanceof Future<?> && ((Future<?>)r).isCancelled())\n                        q.remove(r);\n            }\n            //会检查线程池状态，并根据状态决定是否终止线程池（特别针对的场景就是shudown状态+空队列，就可以进入下一个状态）\n            tryTerminate(); // In case SHUTDOWN and now empty \n        }\n    ```\n\n# 待分析内容\n\n## 简单概述\n\n- 上面这一堆只是简单分析了一下ThreadPoolExecutor内部的方法，这个类继承了AbstractExecutorService，之后会在分析一下AbstractExecutorService，此外ThreadPoolExecutor内部还有一个Worker类，它承了AbstractQueuedSynchronizer(AQS)，这两个也是后面要分析的重点。尤其是AQS，后面的各种锁相关都是依赖于它\n\n## TODO项\n\n- AbstractExecutorService\n- Worker\n- AbstractQueuedSynchronizer\n\n\n","tags":["Java","ThreadPool","多线程","ThreadPoolExecutor"],"categories":["Java"]},{"title":"CopyOnWriteArrayList && CopyOnWriteArraySet 总结","url":"/2019/07/02/Cow总结/","content":"\n这两个都是Java提供的原生写时复制的容器(也就是java.util.concurrent包下的)。CopyOnWrite的基本思路是在修改(包括增加和修改)之前，拷贝出一份快照，对快照进行修改，然后替换原引用。读取操作则没有进行加锁，所以适用于读多写少的场景。另外由于使用了快照模式(迭代器，修改等操作)，因此不能保证强一致性，只能保证最终一致性。\n\nCopyOnWriteArraySet是对CopyOnWriteArrayList的包装，所以重点关注一下CopyOnWriteArrayList。\n\n# CopyOnWriteArrayList\n从增删改查4个方面总结下这个容器（相对ConcurrentHashMap，CopyOnWrite的实现实在是简单太多了。。。）\n\n## 增\n增加方法就2个：\n- public boolean add(E e)\n    - 整体思路比较简单，先获取排他锁（同一时刻只能有一个线程进行修改操作），然后拷贝一份新的数组并插入新的元素（此时读取操作读的还是旧的数组），最后替换引用并释放锁。\n    ```\n        public boolean add(E e) {\n            final ReentrantLock lock = this.lock;\n            lock.lock();//获取排他锁\n            try {\n                Object[] elements = getArray();//获取当前引用（可以理解为快照）\n                int len = elements.length;//当前的长度\n                Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝到一个新的数组中\n                newElements[len] = e;//末尾增加新的元素\n                setArray(newElements);//替换引用\n                return true;//返回结果\n            } finally {\n                lock.unlock();//释放排他锁\n            }\n        }\n    ```\n- public void add(int index, E element)\n    - 整体流程和上一个方法基本一致，区别在于进行索引的有效判断，同时检测是不是在数组的最后插入，拷贝的过程是调用System.arraycopy进行分区间拷贝。\n    ```\n        public void add(int index, E element) {\n            final ReentrantLock lock = this.lock;\n            lock.lock();//一样获取独占锁\n            try {\n                Object[] elements = getArray();//获取当前引用\n                int len = elements.length;\n                if (index > len || index < 0)//越界检查\n                    throw new IndexOutOfBoundsException(\"Index: \"+index+\n                                                        \", Size: \"+len);\n                Object[] newElements;\n                int numMoved = len - index;\n                if (numMoved == 0)//判断是不是最后一个元素\n                    newElements = Arrays.copyOf(elements, len + 1);//直接同上一个方法，生成len+1长度的数组\n                else {\n                    newElements = new Object[len + 1];//生成新的空数组\n                    System.arraycopy(elements, 0, newElements, 0, index);//拷贝0~index\n                    System.arraycopy(elements, index, newElements, index + 1,\n                                    numMoved);//拷贝index+1 ~ 最后\n                }\n                newElements[index] = element;//index位置填充\n                setArray(newElements);//替换引用\n            } finally {\n                lock.unlock();//释放锁\n            }\n        }\n    ```\n## 删\n删除操作对外暴露了2个方法，一个是通过索引下标进行删除，一个是找到指定的Object进行删除。\n- public E remove(int index)\n    - 这个方法实现和 add(int index, E element) 基本类似，不做过多解释了。\n```\n    public E remove(int index) {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            E oldValue = get(elements, index);//获取指定下标元素\n            int numMoved = len - index - 1;\n            if (numMoved == 0)//判断是否为最后一个元素\n                setArray(Arrays.copyOf(elements, len - 1));//形成新的0~len-1数组\n            else {\n                Object[] newElements = new Object[len - 1];\n                //跳过要删除的元素                                 \n                System.arraycopy(elements, 0, newElements, 0, index);\n                System.arraycopy(elements, index + 1, newElements, index,\n                                 numMoved);\n                setArray(newElements);//替换引用\n            }\n            return oldValue;\n        } finally {\n            lock.unlock();\n        }\n    }\n```\n- public boolean remove(Object o)\n    - 首先获取数组引用，然后尝试寻找元素，找到了则进入删除操作，找不到则直接返回false\n    ```\n        public boolean remove(Object o) {\n            Object[] snapshot = getArray();//获取引用快照\n            int index = indexOf(o, snapshot, 0, snapshot.length);//尝试寻找（注意，此时并未加锁，如果此时插入了数据或者其他线程插入了数据，是看不到的,需要在删除的时候重新进行查找）\n            return (index < 0) ? false : remove(o, snapshot, index);//找到了则进行删除(index>=0的情况)，找不到则返回false\n        }\n    ```\n    - 看一下具体的删除操作\n    ```\n    private boolean remove(Object o, Object[] snapshot, int index) {\n            final ReentrantLock lock = this.lock;\n            lock.lock();//加锁\n            try {\n                Object[] current = getArray();//重新获取一次快照引用\n                int len = current.length;\n                if (snapshot != current) findIndex: {//判断在上一步中获取到的快照是否发生了改变，如果没有改变，则直接进行删除，如果发生了改变，则需要进一步处理，也就是下面的逻辑。\n                    int prefix = Math.min(index, len);//判断一下以防数组越界\n                    for (int i = 0; i < prefix; i++) {\n                        if (current[i] != snapshot[i] && eq(o, current[i])) {//依次遍历查找，找到则结束if语句块，并更新index\n                            index = i;\n                            break findIndex;\n                        }\n                    }\n                    if (index >= len)//上述条件并未找到，则判断是否已经超过索引长度(其他线程已经删除元素了，可能会执行到这里)\n                        return false;\n                    if (current[index] == o)//这块没想明白什么情况会执行到这里\n                        break findIndex;\n                    index = indexOf(o, current, index, len);//重新查找，因为已经加锁了，所以不会有其他线程进行修改\n                    if (index < 0)\n                        return false;//没有找到\n                }\n                //后面就简单了，还是重新拷贝，更新引用\n                Object[] newElements = new Object[len - 1];\n                System.arraycopy(current, 0, newElements, 0, index);\n                System.arraycopy(current, index + 1,\n                                newElements, index,\n                                len - index - 1);\n                setArray(newElements);\n                return true;\n            } finally {\n                lock.unlock();\n            }\n        }\n    ```\n\n## 改\n修改操作相对比较简单，通过索引下标直接更新即可，方法如下：\n- public E set(int index, E element)\n    - 操作也不复杂，加锁后重新拷贝并替换，唯独注意就是元素没有变化，也要重新更新一下引用（注释说是为了确保volatile写语义）\n    ```\n    public E set(int index, E element) {\n            final ReentrantLock lock = this.lock;\n            lock.lock();\n            try {\n                Object[] elements = getArray();\n                E oldValue = get(elements, index);\n\n                if (oldValue != element) {\n                    int len = elements.length;\n                    Object[] newElements = Arrays.copyOf(elements, len);\n                    newElements[index] = element;\n                    setArray(newElements);\n                } else {\n                    // Not quite a no-op; ensures volatile write semantics\n                    setArray(elements);\n                }\n                return oldValue;\n            } finally {\n                lock.unlock();\n            }\n        }\n    ```\n\n## 查\n查询操作外部暴露了4个方法,其实内部都是委托给对应的私有方法，只是没有index参数的方法委托的时候传值是0。\n- public int indexOf(Object o)\n- public int indexOf(E e, int index)\n- public int lastIndexOf(Object o)\n- public int lastIndexOf(E e, int index)\n前两个方法委托给 private static int indexOf(Object o, Object[] elements, int index, int fence) 执行\n后两个方法委托给 private static int lastIndexOf(Object o, Object[] elements, int index) 执行\n下面整理一下这两个查找方法：\n- indexOf 只是看一下元素是否为空，为空则找null，不为空则直接进行遍历查找\n    ```\n        private static int indexOf(Object o, Object[] elements,\n                                int index, int fence) {\n            if (o == null) {\n                for (int i = index; i < fence; i++)\n                    if (elements[i] == null)\n                        return i;\n            } else {\n                for (int i = index; i < fence; i++)\n                    if (o.equals(elements[i]))\n                        return i;\n            }\n            return -1;\n        }\n    ```\n- lastIndexOf 和 indexOf 几乎相同，只是倒着查找而已。\n    ```\n    private static int lastIndexOf(Object o, Object[] elements, int index) {\n            if (o == null) {\n                for (int i = index; i >= 0; i--)\n                    if (elements[i] == null)\n                        return i;\n            } else {\n                for (int i = index; i >= 0; i--)\n                    if (o.equals(elements[i]))\n                        return i;\n            }\n            return -1;\n        }\n    ```\n## 其他方法\n- contains方法，也是直接调用indexOf方法，判断一下索引位置是不是>=0,就不多说了\n- get方法，直接获取一下数组引用(获取引用之后，其他线程修改，这里也看不到了。。。)，然后取对应下标。\n- addIfAbsent方法，CopyOnWriteArraySet就是基于这个方法实现的。先通过indexOf方法查找，找到直接返回false，找不到则加锁进行添加，添加之前会判断一下引用是否改变，和remove比较相似。代码如下：\n    ```\n    private boolean addIfAbsent(E e, Object[] snapshot) {\n            final ReentrantLock lock = this.lock;\n            lock.lock();\n            try {\n                Object[] current = getArray();\n                int len = current.length;\n                if (snapshot != current) {//引用发生改变，则需要重新查找，如果还是没找到，则继续添加\n                    // Optimize for lost race to another addXXX operation\n                    int common = Math.min(snapshot.length, len);\n                    for (int i = 0; i < common; i++)//遍历查找，并且找到了，则返回false\n                        if (current[i] != snapshot[i] && eq(e, current[i]))\n                            return false;\n                    if (indexOf(e, current, common, len) >= 0)//没太明白为什么又要再次查找。。\n                            return false;\n                }\n                Object[] newElements = Arrays.copyOf(current, len + 1);\n                newElements[len] = e;\n                setArray(newElements);\n                return true;\n            } finally {\n                lock.unlock();\n            }\n        }\n    ```\n- containsAll方法, 实现也比较简单暴力，获取快照后，直接for循环对每一个元素进行判断，就不附代码了。\n- removeAll方法，也不算复杂，加锁之后遍历元素，不在待删除集合中，则加入新数组中，然后重新拷贝一份即可\n    ```\n    public boolean removeAll(Collection<?> c) {\n            if (c == null) throw new NullPointerException();\n            final ReentrantLock lock = this.lock;\n            lock.lock();\n            try {\n                Object[] elements = getArray();\n                int len = elements.length;\n                if (len != 0) {\n                    // temp array holds those elements we know we want to keep\n                    int newlen = 0;\n                    Object[] temp = new Object[len];\n                    for (int i = 0; i < len; ++i) {\n                        Object element = elements[i];\n                        if (!c.contains(element))\n                            temp[newlen++] = element;\n                    }\n                    if (newlen != len) {\n                        setArray(Arrays.copyOf(temp, newlen));\n                        return true;\n                    }\n                }\n                return false;\n            } finally {\n                lock.unlock();\n            }\n        }\n    ```\n- retainAll方法，和removeAll方法类似，对应的是两个集合都包含的\n```\npublic boolean retainAll(Collection<?> c) {\n        if (c == null) throw new NullPointerException();\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            if (len != 0) {\n                // temp array holds those elements we know we want to keep\n                int newlen = 0;\n                Object[] temp = new Object[len];\n                for (int i = 0; i < len; ++i) {\n                    Object element = elements[i];\n                    if (c.contains(element))\n                        temp[newlen++] = element;\n                }\n                if (newlen != len) {\n                    setArray(Arrays.copyOf(temp, newlen));\n                    return true;\n                }\n            }\n            return false;\n        } finally {\n            lock.unlock();\n        }\n    }\n```\n\n- addAllAbsent方法, indexOf(e, cs, 0, added) 采用将遍历过的待添加元素数组进行替换，节省了新开辟数组的空间，这是一个用的很巧的方法。\n```\n    public int addAllAbsent(Collection<? extends E> c) {\n        Object[] cs = c.toArray();\n        if (cs.length == 0)\n            return 0;\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            int added = 0;\n            // uniquify and compact elements in cs\n            for (int i = 0; i < cs.length; ++i) {\n                Object e = cs[i];\n                if (indexOf(e, elements, 0, len) < 0 &&\n                    indexOf(e, cs, 0, added) < 0)\n                    cs[added++] = e;\n            }\n            if (added > 0) {\n                Object[] newElements = Arrays.copyOf(elements, len + added);\n                System.arraycopy(cs, 0, newElements, len, added);\n                setArray(newElements);\n            }\n            return added;\n        } finally {\n            lock.unlock();\n        }\n    }\n```\n- clear方法，就是设置一个空数组，就不附代码了\n- addAll方法，也比较简单，转成数组之后直接合并，带索引位置的，就是跳过一部分后，在插入，最后补充剩余的\n- sort方法，也比较简单，拷贝一份快照后，对快照进行排序，然后替换引用。\n- equals 和 hashCode ，这两个方法都进行了重写，注意一下，都是使用快照进行比较，所以都是弱一致性的。\n- iterator 迭代器是创建一个COWIterator迭代器，不支持删除和修改操作，只能进行读取操作。\n- 其他就不进行分析了\n\n# CopyOnWriteArraySet\n\n其实没啥可分析的，内部就一个CopyOnWriteArrayList，所有方法都是调用 CopyOnWriteArrayList的方法，去重用的是addIfAbsent和addAllAbsent方法，= =感觉这个Set性能有点差。。。远不及HashSet和TreeSet。\n\n# 总结\n\n平时项目中时不时还是会用到CopyOnWriteArrayList，CopyOnWriteArraySet至少我还没用到过，而且看了实现，也不太敢用。。。。\n回归主题：\n- CopyOnWrite相关读取操作都是不加锁的，拷贝一份内部数组的引用，就开始读取了，不用加锁的原因就是所有的数组实际上都不会发生改变，因为所有的修改操作都是生成一份新的数组。\n- 因为读取或者迭代器，乃至hashcode，equals方法都是基于快照进行相关操作，所以可能读到的数据并不是最新的，也就是无法保证实时的一致性(就是所谓的弱一致性)，但是最终数据还是一致的。\n- 因为几乎每次修改，都会生成新的数组，如果写入比较频繁，可能产生大量垃圾，加重GC负担，所以CopyOnWrite最适合的场景就是读多写少。\n- CopyOnWriteArrayList源码上有很多值得学习的小技巧，比如addAllAbsent方法中用替换数组中读过的位置存储待合并字符，省去了开辟新数组的开销。\n","tags":["Java","并发容器","CopyOnWrite"],"categories":["Java"]},{"title":"Java 集合类整理","url":"/2019/06/30/Java集合类/","content":"\n# 起因\n\n好像Java面试必不可少的一个问题就是，Java中集合有哪些？分别有什么特点。照搬各种《XXX从入门到放弃》，集合有2种类型，一个是有序可重复的List，一个是无序不可重复的Set，可是真的用起来的时候好像就不是简单的这样了。  \n\n先来看一下集合的整体关系图(并发包中的集合没有考虑进来，仅看java.util包)\n![Java集合类](Java集合类/Collection.png)  \n\n第一眼看上去我也懵，本来以为自己天天用的那些集合类已经差不多了，然后发现一坨坨的没见过没用过的。\n\n# 那就啃吧。。\n\n## Collection\n- Collection应该是老大哥级别的了，算是集合类的鼻祖（迭代器忽略），定义了一个集合应该有的基本方法，包括增删迭代等，这个就不多说了。\n- 1.8版本开始，增加了流式操作的几个default方法(先不关注了)\n\n## List\nList应该是集合中用的最多最多的了，平时搬砖，基本上几行代码就要加上一个List存储各种元素。忽略抽象方法，整理一下对应的实现类\n\n### ArrayList\nArrayList应该是日常搬砖使用最多的的实现了，特点如下:\n- 底层实现是数组，对应代码:\n```\ntransient Object[] elementData;\n```\n- 实现了动态扩容方法，简单说就是容量不够了，我就新建一个数组，然后将原来的数据拷贝到新数组中。从代码int newCapacity = oldCapacity + (oldCapacity >> 1);中也可以看出来，每次扩容变为原本的1.5倍。\n```\n    private void grow(int minCapacity) {\n        // overflow-conscious code\n        int oldCapacity = elementData.length;\n        int newCapacity = oldCapacity + (oldCapacity >> 1);\n        if (newCapacity - minCapacity < 0)\n            newCapacity = minCapacity;\n        if (newCapacity - MAX_ARRAY_SIZE > 0)\n            newCapacity = hugeCapacity(minCapacity);\n        // minCapacity is usually close to size, so this is a win:\n        elementData = Arrays.copyOf(elementData, newCapacity);\n    }\n```\n- 线程不安全，所有方法没有加锁，多线程存在并发问题\n- 因为底层实现是数组，所以随机读取速度很快，并不是说不适合插入数据，而是不适合在中间或者头部插入数据。因为插入数据之后，当前位置后面的元素都要往后移动，成本相对来说比较大了。代码如下:\n```\n    System.arraycopy(elementData, index, elementData, index + 1, size - index);\n    elementData[index] = element;\n```\n- 删除操作也是同理，在末尾操作其实影响不大，但是在中间和数组起始位置操作成本就有点高了。\n- 更新操作影响很小，直接找到对应数组下标，然后替换就可以了。\n- indexOf和contains以及lastIndexOf方法都是直接进行遍历，因为数组是无序的，也没办法采用二分法之类的进行快速查找。所以尽可能不要直接使用List的查找方法。\n- size方法成本不高，并不是每次都进行统计，而是内部存储了一个size变量，每次增删操作回进行更新。\n- 暂时想到的就这么多，以后想起来再补充。\n\n### Vector\n这个可是个老古董了，从JDK1.0开始就存在了（别问我怎么知道的，那会我也没用过Java，是文档自己写的。。。。），正因为是老古董，所以现在已经不是很推荐使用了，原因就是效率很低下，因为很多方法都暴力的增加了synchronized关键字，性能很低下。做个简单总结吧：\n- 因为很多方法都加上了synchronized关键词，导致整体性能较差，不推荐使用\n- 底层实现也是数组，特性和ArrayList差不多。\n- 注意：Vector没有实现Serializable接口\n- 关于扩容：ArrayList每次扩容是1.5倍，Vector是2倍。代码如下：\n```\n    private void grow(int minCapacity) {\n        // overflow-conscious code\n        int oldCapacity = elementData.length;\n        int newCapacity = oldCapacity + ((capacityIncrement > 0) ?\n                                         capacityIncrement : oldCapacity);//扩充一倍\n        if (newCapacity - minCapacity < 0)\n            newCapacity = minCapacity;\n        if (newCapacity - MAX_ARRAY_SIZE > 0)\n            newCapacity = hugeCapacity(minCapacity);\n        elementData = Arrays.copyOf(elementData, newCapacity);\n    }\n```\ncapacityIncrement是构造方法传进来的，如果不指定，则传0。\n\n### Stack\n这个类已经快被遗忘了，简单概述一下。\n- 1.0时代的远古产物，继承了Vector，所以也是各种synchronized关键字，性能低下\n- 官方注释已经不推荐使用了，同样的功能可以使用Deque实现\n```\nDeque<Integer> stack = new ArrayDeque<Integer>();\n```\n\n### LinkedList\n你以为LinkedList仅仅是一个链表实现的List的么？？那你就是图样图森破了，来看看强大的LinkedList吧。\n- 看一下接口层面：List、deque和Queue，也就是说LinkedList不仅仅是一个list集合，同时也是一个双向队列，当然也可以作为单向队列来使用。所以根据场景，上面的Stack也可以使用LinkedList进行替换\n- 底层的实现是基于链表，基本存储数据的元素是Node，代码如下：\n```\nprivate static class Node<E> {\n        E item;\n        Node<E> next;\n        Node<E> prev;\n\n        Node(Node<E> prev, E element, Node<E> next) {\n            this.item = element;\n            this.next = next;\n            this.prev = prev;\n        }\n    }\n```\n- 正是因为基于链表实现，所以理论上在任意位置进行增删操作都是O(1)的时间复杂度，但是为什么我说是理论上呢？因为实际进行增删的时候，必须要先找到对应的位置吧？这个查找的过程时间复杂度可就是O(n)了。\n- LinkedList同样没有加任何同步措施，因此也是线程不安全的。\n- 说一个坑点：千万不要在for循环中通过索引的方式去获取元素（之前实习生干了这个事。。。），因为链表的**通过索引方式进行随机读取的时间复杂度是O(n)**!\n\n### 简单汇总一下\n\n|列|ArrayList|LinkedList|Vector|Stack|\n|------|------|------|------|------|\n|实现方式|数组|链表|数组|数组|\n|线程安全|否|否|是|是|\n|优势|适合随机读，末尾写|适合随机写，顺序读|线程安全|线程安全|\n|劣势|不适合随机写入|不适合随机读取|性能差|性能差|\n|扩容|1.5|-|2|-|\n\n## Set\n上面简单总结了一下List相关实现，接下来看看狐假虎威的Set。为啥说Set是狐假虎威呢？看看对应的实现类就明白了，基本上都是Map套了个壳（Map稍后总结）\n\n### HashSet\n基于Hash实现的Set，内层实现是HashMap，所有的操作都是HashMap的Key的操作，而Map的实际Value则是一个Object对象。总结一下特点：\n- 判断是否存在速度很快，基于Hash实现如果不出现冲突，基本都是O(1)的操作。\n- 线程不安全，需要自己实现线程同步方式\n- 元素唯一（前提重写HashCode和equals方法,只有两者都相同才被认为是同一个元素）\n- 不保证顺序，因为基于Hash实现，无法保证读取时候的顺序(也就是通过迭代器方式读取无法保证顺序，不过貌似重写HashCode之后，可以在一定程度上控制顺序，但是最好不要这么用。。)\n- 因为底层实现是HashSet，所以也存在初始容量和负载因子，因此使用的时候如果事先知道存储大小，最好指定一下大小和负载因子，减少扩容消耗。\n- 因为HashSet支持null作为key，所以HashSet也可以存储null元素\n\n### LinkedHashSet\nLinkedHashSet也是一个壳，继承了HashSet，注意一下HashSet内部还有一个带有boolean的构造方法，调用这种构造方法，则内部实现不再是HashMap，而是LinkedHashMap。\n- LinkedHashSet和HashSet最大的区别就是能保证元素插入的顺序和通过迭代器读取的顺序是一致的(但是不是经过排序的，是保留插入的顺序)。\n- 除了有序这个之外，其他特点和HashSet一样，因为继承了嘛(写这个类的人，真的是懒到极致的。。向他学习！)\n\n### TreeSet\n看到TreeSet是不是立即想到了TreeMap？对的，TreeSet内部就是一个NavigableMap，NavigableMap又是什么？java.util包下原生的实现且暴露出来的好像只有。。。。TreeMap。。。\n- 内部实现是TreeMap，也就是基于红黑树（啥是红黑树？。。。自行百度。。）,所以整体操作复杂度事O(log(n)),表面上看不如HashSet的O(1)速度快，但是一旦出现大量Hash冲突的时候，HashSet性能将急剧下降，因为冲突导致查询变为链表遍历(好像1.8还是1.7开始，冲突元素个数增加到8就会进行树化，防止链表过长)，而TreeSet不会存在这个问题。\n- TreeSet实现了NavigableSet接口和SortedSet接口，也就是说TreeSet中的元素是有序的，同时是支持范围查询,查找大于或者小于某个元素的元素或者集合(具体看NavigableSet接口)，这些都是HashSet无法提供的。\n- 线程不安全，补充：因为红黑树实现复杂，并发粒度控制困难(应该是这个原因)，官方没有提供TreeSet对应的并发类，而是提供了基于跳表实现的并发类(后面再说)\n- 其他想到了再补充。。\n\n### EnumSet\nEnumSet是一个抽象类，有两个实现：\n- RegularEnumSet\n- JumboEnumSet  \n\n注意一下，这两个类都是不对外暴露的，对外统一暴露的是EnumSet。这两个类有啥区别呢？RegularEnumSet存储的是元素个数小于等于64个，JumboEnumSet则是超过64个。\n为啥要单独出来一个EnumSet呢？HashSet，TreeSet也是可以存储枚举的啊，查了一堆资料(实际上我也没用过这玩意。。)，总结如下：\n- EnumSet的速度很快，原因是底层用了elements进行位运算，也就是说EnumSet并不直接存放枚举对象，而是存储一个对应类和elements，通过位运算来判断Set中有哪些元素，速度自然要快得多。\n- 一旦元素的枚举类型确定那么集合就确定了（因为要通过枚举类型进行位判断，如果更换了枚举类型，会导致结果出错，所以不允许修改）\n- EnumSet只能存放一种枚举类型的元素(原因同上)\n\n## Queue\n一个先入先出的数据结构，util包下实现好像只有下面3个，这个主要在juc包下实现类较多(各种阻塞队列)\n\n### LinkedList\n前面已经说过，不再多说了。\n\n### ArrayDeque\n和LinkedList相比，最大不同就是底层实现是依赖于一个数组,简单汇总一下其特点:\n- 实现依赖于一个循环数组\n- 扩容: 扩容直接将容量翻倍，然后执行数组拷贝\n- 容量：要求必须是2的幂次方(方便进行位移运算)\n- 优势：和LinkedList相比，无需用Node对数据进行包裹，而且数组通过下标访问速度很快\n- 应用场景:额。。。其实我也没怎么用过，感觉常用栈和队列都可以用这个实现(好吧，以前我都是用LinkedList实现栈的操作。。。)\n\n### PriorityQueue\n这个感觉平时用的也很少，是一个带有优先级的队列(并发包中的优先队列貌似使用场景更多一些。。)，这个研究不多，直接当个搬运工吧(参考:https://www.cnblogs.com/mfrank/p/9614520.html)\n- 内部是根据小顶堆的结构进行存储的\n- 构造方法需要传入一个比较器，用于判断优先级\n- 内部实际上也是使用一个数组进行数据存储，同时有一个heapify()方法，用于将数组进行堆化(具体过程就不描述了。。。)\n- 应用场景，基本上就是堆的应用场景，比如寻找topN之类的\n\n# 顺便肯一下另外一组容器\n\n## Map\nMap我的理解就是存储键值对的容器，基本上每一种开发语言都有这种容器，比如Python,C#的字典，golang的map，应该说Map是和数组一个级别的重要容器了。最常用的应该是基于Hash实现的HashMap，当然还有基于红黑树的TreeMap。先看一下Map相关的类图：\n![Java集合类](Java集合类/Map.png)  \n简单总结一下：\n\n### HashMap\n最常用的Map，没有之一(至少我工作这两年看到的Map，九成以上都是HashMap)，应该也是面试必问容器，后面估计要专门整理一篇HashMap的总结了(网上各种总结已经一大把了。。)，简单总结一下特点：\n- 基于hash的方法，能够快速通过key找到对应的value\n- 内部存储数据是基于数组，Node<K,V>[] table;\n- 线程不安全(几乎面试都会问到，然后就自然转到了juc的并发包了)\n- Key建议使用字符串，当然用自定义对象也可以，但是要重写hashcode和equals方法，否则不保证正确性了。\n- hash冲突的解决是通过链表方式，链表长度超过8以后，转为红黑树，当长度减少到6一下，再次转换为链表。(原因是怕链表长度过长，导致查询速度过慢，而冲突变少之后使用链表和树速度差别小，但是复杂度来看，链表要简单。。好吧，也是强行解释)\n- 迭代遍历不保证顺序\n- 允许null作为key和value\n\n### Hashtable\n远古产物，并且类命名还不对，正确命名应该是HashTable，估计是当时开发人员粗心，写成了Hashtable，然后为了兼容性，那就错着把。。。功能上和HashMap基本一样，简单总结一下:\n- 线程安全，但是性能低下，全部基于synchronized关键词实现。\n- 不允许null作为key和value\n\n### LinkedHashMap\n- 与HashMap相比，保留的key的插入顺序性，遍历的时候和插入的顺序一致\n- 原理是内部维护了一条双向链表，记录插入的顺序\n- 额外增加了空间和时间上的开销\n- 应用场景\n    - 保留插入顺序的遍历场景\n    - LRU缓存的实现(可以看一下MyBatis的缓存实现，其中就有基于LinkedHashMap的LRU缓存)\n\n### TreeMap\n这个因为红黑树实现，有点复杂(面试在单独复习红黑树吧。。)，所以就不管内部具体实现了，总结一下特点\n- 线程不安全，即使是在并发包中也没有TreeMap的并发类\n- 实现了SortedMap接口，说明Key是有序的\n- 遍历的时候根据Key的自然顺序进行，或者指定Comparator比较器\n- 实现了NavigableMap接口，也就是说支持区间范围或者比大小操作(基于Key的)\n- 整体操作复杂度均为O(log(n))\n\n### EnumMap\n针对枚举类作为Key的情形进行优化的Map，内部通过数组存储，查找的时候直接通过枚举的ordinal作为index快速查询。\n- 只能支持单一类型枚举\n\n### IdentityHashMap\n陌生么？陌生。。。陌生就对了，因为日常开发中，压根就不会用到这玩意。。这玩意干嘛用的，它实际上是严格版本的HashMap，有多严格？引用必须相等！  \n\nHashMap中判断key相等的依据是key.equals(otherKey),而IdentityHashMap判断key相等的依据是key==otherKey，这种严格的限制，恕我无知。。我实在是找不到应用场景。。关键这个类还是大神Doug Lea写的。。。大神的思维。。不懂。。不懂。。\n\n### WeakHashMap\n这个容器使用之前最好先了解一下Java中的引用(强软弱虚)，WeakHashMap是一种弱key实现的容器，使用场景主要还是缓存吧(反正我没用过。。。)，说一下特点\n- 当key被GC回收后，对应Map中的KeyValue対也会被回收，附代码示例:\n```\n    public static void main(String[] args) throws InterruptedException {\n        WeakHashMap<String, Object> map = new WeakHashMap<>();\n        String k1 = new String(\"k1\"); //注意一定要使用new String(\"xxx\")，形式\n        String k2 = new String(\"k2\");\n        String k3 = new String(\"k3\");\n        map.put(k1,new Object());\n        map.put(k2,new Object());\n        map.put(k3,new Object());\n        System.out.println(map);\n        System.gc();\n        Thread.sleep(500);\n        System.out.println(map);\n        k1 = null;\n        k2 = null;\n        k3 = null;\n        System.out.println(\"Key=null -> \" +map);\n        System.gc();\n        Thread.sleep(500);\n        System.out.println(\"After GC -> \" +map);\n    }\n```\n\n### Properties\n以前我还真不知道Properties竟然也是Map的实现类，内部主要是各种读取配置文件相关逻辑，存储方面由于继承了Hashtable，所以也是线程安全的，关于这个就不分析啥了。。\n\n# 总结\n糊里糊涂整理了一下java.util包下面的集合相关类(容器类也行。。)，发现了几个平时开发中没用过的容器，但是其实是都可以用的。。。比如ArrayDeque，比如Enum相关Set和Map(恕我无知，之前真的都是通过HashSet和HashMap实现的。。。)。等后续有时间了，整理一下并发包下面的容器（好像已经烂大街了。。。）\n","tags":["Java","Collection"],"categories":["Java"]},{"title":"CompletableFuture 学习汇总","url":"/2019/06/23/CompletableFuture学习汇总/","content":"\n### static方法\n#### public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)\n- 提交一个Supplier任务，异步执行，可以获取任务返回结果，使用ForkJoinPool.commonPool()执行任务。\n#### public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier, Executor executor)\n- 提交一个Supplier任务，异步执行，可以获取任务返回结果，使用指定的线程池执行\n#### public static CompletableFuture<Void> runAsync(Runnable runnable)\n- 提交一个Runnable任务，异步执行，无返回结果，使用ForkJoinPool.commonPool()执行任务。\n#### public static CompletableFuture<Void> runAsync(Runnable runnable, Executor executor) \n- 提交一个Supplier任务，异步执行，无返回结果，使用指定的线程池执行\n#### public static <U> CompletableFuture<U> completedFuture(U value)\n- 新建一个完成的CompletableFuture，通常作为计算的起点阶段。\n#### public static CompletableFuture<Void> allOf(CompletableFuture<?>... cfs)\n- 接收一个由CompletableFuture 构成的数组，需要等待多个 CompletableFuture 对象执行完毕，执行join操作可以等待CompletableFuture执行完成。\n#### public static CompletableFuture<Object> anyOf(CompletableFuture<?>... cfs)\n- 接收一个由CompletableFuture 构成的数组，返回由第一个执行完毕的 CompletableFuture 对象的返回值构成的CompletableFuture<Object> 。\n#### 示例代码\n\n```\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class ThreadTest1 {\n    private static SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\");\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(4);\n        //创建一个直接完成的CompletableFuture\n        String now = CompletableFuture.completedFuture(\"Test\")\n                .getNow(\"Fail\");\n        println(\"completedFuture: \" + now);\n        //创建一个带有返回值的CompletableFuture\n        CompletableFuture<String> task = CompletableFuture.supplyAsync(() -> {\n            sleep(100);\n            return \"Test\";\n        }, pool);\n        //延迟100ms，这里获取是default值\n        now = task.getNow(\"Fail\");\n        println(\"supplyAsync: now: \" + now);\n        //等待任务完成后输出\n        println(\"supplyAsync: get: \" + task.get());\n        System.out.println(\"---------------------分割线----------------------\");\n        //耗时100ms的任务\n        CompletableFuture<Void> task100 = CompletableFuture.runAsync(() -> {\n            sleep(100);\n            println(\"runAsync :\" + Thread.currentThread().getName() + \" task100 done\");\n        }, pool);\n        //耗时200ms的任务\n        CompletableFuture<Void> task200 = CompletableFuture.runAsync(() -> {\n            sleep(200);\n            println(\"runAsync :\" + Thread.currentThread().getName() + \" task200 done\");\n        }, pool);\n        //任意一个完成就会继续执行\n        CompletableFuture.anyOf(task100, task200).join();\n        println(\"anyOf Done\");\n        //全部完成才会继续执行\n        CompletableFuture.allOf(task100, task200).join();\n        println(\"allOf Done\");\n        //关闭线程池\n        pool.shutdown();\n    }\n\n    private static void sleep(long time) {\n        try {\n            Thread.sleep(time);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    private static void println(Object object){\n        System.out.println(sdf.format(new Date()) + \": \" + object);\n    }\n}\n\n```\n运行结果\n```\n2019-06-23 18:02:03.552: completedFuture: Test\n2019-06-23 18:02:03.604: supplyAsync: now: Fail\n2019-06-23 18:02:03.710: supplyAsync: get: Test\n-------------------------------------------\n2019-06-23 18:02:03.813: runAsync :pool-1-thread-2 task100 done\n2019-06-23 18:02:03.813: anyOf Done\n2019-06-23 18:02:04.012: runAsync :pool-1-thread-3 task200 done\n2019-06-23 18:02:04.012: allOf Done\n```\n\n### 实例方法\n- 实例方法整体比较规则，一个标准执行方法，一个异步执行方法，一个指定异步线程执行方法\n\n#### thenApply\n-  then是指在当前阶段正常执行完成后（正常执行是指没有抛出异常）进行的操作。Apply是指将一个Function作用于之前阶段得出的结果(即将上一步的结果进行转换)\n-  public <U> CompletableFuture<U> (Function<? super T,? extends U> fn)\n-  public <U> CompletableFuture<U> thenApplyAsync(Function<? super T,? extends U> fn)\n-  public <U> CompletableFuture<U> thenApplyAsync(Function<? super T,? extends U> fn, Executor executor) \n```\n    public static void thenApplyAsyncDemo(){\n        Integer integer = CompletableFuture\n                .completedFuture(\"task 1\")\n                .thenApplyAsync(x -> {\n                    String intString = x.split(\" \")[1];\n                    return Integer.valueOf(intString);\n                })\n                .join();\n        System.out.println(\"thenApplyAsyncDemo: \" + integer);\n    }\n    --------- 输出 -----------\n    thenApplyAsyncDemo: 1    \n```\n#### thenAccept\n- 下一个Stage接收了当前Stage的结果但是在计算中无需返回值(可以简单认为这里就是消费终点，因为没有返回值。当然下一步不依赖当前返回值的情况除外)\n-  public CompletableFuture<Void> thenAccept(Consumer<? super T> action)\n-  public CompletableFuture<Void> thenAcceptAsync(Consumer<? super T> action)\n-  public CompletableFuture<Void> thenAcceptAsync(Consumer<? super T> action,Executor executor)\n```\n    public static void thenAcceptDemo(){\n        CompletableFuture\n                .completedFuture(\"task\")\n                .thenAcceptAsync(s -> {\n                    System.out.println(\"thenAcceptDemo：\" + s);\n                })\n                .join();\n    }\n    --------- 输出 -----------\n    thenAcceptDemo：task\n```\n#### thenRun\n- 不再关心上一步运算的结果，直接进行下一步的运算\n-  public CompletableFuture<Void> thenRun(Runnable action)\n-  public CompletableFuture<Void> thenRunAsync(Runnable action)\n-  public CompletableFuture<Void> thenRunAsync(Runnable action, Executor executor)\n```\n    public static void thenRunDemo() {\n        CompletableFuture.completedFuture(\"Task\")\n                .thenRun(() -> System.out.println(\"我不知道上面的参数，也不会继续往下传递值\"))\n                .join();\n    }\n    --------- 输出 -----------\n    我不知道上面的参数，也不会继续往下传递值\n```\n#### thenCombine\n- 结合前面两个Stage的结果，进行转化\n-  public <U,V> CompletableFuture<V> thenCombine(CompletionStage<? extends U> other, BiFunction<? super T,? super U,? extends V> fn)\n-  public <U,V> CompletableFuture<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn) \n-  public <U,V> CompletableFuture<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn, Executor executor)\n```\n    public static void thenCombineDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> \"task 1\");\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> \"task 2\");\n        String result = task1.thenCombineAsync(task2, (t1, t2) -> t1 + \" - \"+ t2)\n                .join();\n        System.out.println(result);\n    }\n    --------- 输出 -----------\n    task 1 - task 2\n```\n#### thenAcceptBoth\n- 结合两个CompletionStage的结果，进行消耗,和thenCombine相比，只是少了返回值\n-  public <U> CompletableFuture<Void> thenAcceptBoth(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action)\n-  public <U> CompletableFuture<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action) \n-  public <U> CompletableFuture<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action, Executor executor) \n```\n    public static void thenAcceptBothDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> \"task 1\");\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> \"task 2\");\n        task1.thenAcceptBoth(task2, (t1, t2) -> System.out.println(\"thenAcceptBothDemo: \" +t1 + \" - \" + t2))\n                .join();\n    }\n    --------- 输出 -----------\n    thenAcceptBothDemo: task 1 - task 2\n```\n#### runAfterBoth\n- 在两个CompletionStage都运行完执行。\n-  public CompletableFuture<Void> runAfterBoth(CompletionStage<?> other,Runnable action)\n-  public CompletableFuture<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action) \n-  public CompletableFuture<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action,Executor executor) \n```\n    public static void runAfterBothDemo() {\n        CompletableFuture<Void> task1 = CompletableFuture.runAsync(() -> {\n            sleep(100);\n            println(\"task1 Done\");\n        });\n        CompletableFuture<Void> task2 = CompletableFuture.runAsync(() -> {\n            sleep(200);\n            println(\"task2 Done\");\n        });\n        task1.runAfterBoth(task2, () -> println(\"Task 1 And Task 2 Both Done\"))\n                .join();\n    }\n    --------- 输出 -----------\n    2019-06-23 19:22:08.498: task1 Done\n    2019-06-23 19:22:08.595: task2 Done\n    2019-06-23 19:22:08.596: Task 1 And Task 2 Both Done\n```\n#### applyToEither\n- 在两个CompletionStage中选择计算快的，将其结果进行下一步的转化操作。\n-  public <U> CompletableFuture<U> applyToEither(CompletionStage<? extends T> other, Function<? super T, U> fn)\n-  public <U> CompletableFuture<U> applyToEitherAsync(CompletionStage<? extends T> other, Function<? super T, U> fn) \n-  public <U> CompletableFuture<U> applyToEitherAsync(CompletionStage<? extends T> other, Function<? super T, U> fn,Executor executor) \n```\n    public static void applyToEitherDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> {\n            sleep(10);\n            return \"task 1\";\n        });\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> {\n            sleep(20);\n            return \"task 2\";\n        });\n        Integer result = task1.applyToEither(task2, t -> Integer.valueOf(t.split(\" \")[1]))\n                .join();\n        System.out.println(\"applyToEitherDemo:\" + result);\n    }\n    --------- 输出 -----------\n    applyToEitherDemo:1\n```\n#### acceptEither\n- 在两个CompletionStage中选择计算快的，作为下一步计算的结果。\n-  public CompletableFuture<Void> acceptEither(CompletionStage<? extends T> other, Consumer<? super T> action) \n-  public CompletableFuture<Void> acceptEitherAsync(CompletionStage<? extends T> other, Consumer<? super T> action)\n-  public CompletableFuture<Void> acceptEitherAsync(CompletionStage<? extends T> other, Consumer<? super T> action,Executor executor)\n```\n    public static void acceptEitherDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> {\n            sleep(10);\n            return \"task 1\";\n        });\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> {\n            sleep(20);\n            return \"task 2\";\n        });\n        task1.acceptEitherAsync(task2, t -> System.out.println(\"acceptEitherDemo:\" +Integer.valueOf(t.split(\" \")[1])))\n                .join();\n    }\n    --------- 输出 -----------\n    acceptEitherDemo:1\n```\n#### runAfterEither\n- 两个CompletionStage，任何一个完成了都会执行下一步的操作。\n-  public CompletableFuture<Void> runAfterEither(CompletionStage<?> other,Runnable action) \n-  public CompletableFuture<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action) \n-  public CompletableFuture<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action,Executor executor) \n```\n    public static void runAfterEitherDemo() {\n        CompletableFuture<Void> task1 = CompletableFuture.runAsync(() -> {\n            sleep(100);\n            println(\"task1 Done\");\n        });\n        CompletableFuture<Void> task2 = CompletableFuture.runAsync(() -> {\n            sleep(200);\n            println(\"task2 Done\");\n        });\n        task1.runAfterEither(task2, () -> println(\"Task 1 Or Task 2 Done\"))\n                .join();\n        sleep(100);\n    }\n    --------- 输出 -----------\n    2019-06-23 19:24:27.644: task1 Done\n    2019-06-23 19:24:27.645: Task 1 Or Task 2 Done\n    2019-06-23 19:24:27.749: task2 Done\n```\n#### thenCompose\n- 连接两个CompletableFuture，返回值是新的CompletableFuture\n-  public <U> CompletableFuture<U> thenCompose(Function<? super T, ? extends CompletionStage<U>> fn) \n-  public <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn) \n-  public <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn,Executor executor)\n```\n    public static void thenComposeDemo() {\n        String result = CompletableFuture.completedFuture(\"Start\")\n                .thenCompose(x -> CompletableFuture.supplyAsync(() -> {\n                    sleep(20);\n                    return x + \" task 2\";\n                }))\n                .thenCompose(x -> CompletableFuture.supplyAsync(() -> {\n                    sleep(10);\n                    return x + \" task 1\";\n                }))\n                .join();\n        System.out.println(\"thenComposeDemo:\" +result);\n    }\n    --------- 输出 -----------\n    thenComposeDemo:Start task 2 task 1\n```\n#### whenComplete\n- 当运行完成时，对结果的记录。\n    - 正常执行，返回值。\n    - 异常抛出造成程序的中断\n- 注意，内部线程出现异常会抛到外层，导致外层线程产生异常。\n-  public CompletableFuture<T> whenComplete(BiConsumer<? super T, ? super Throwable> action) \n-  public CompletableFuture<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action)\n-  public CompletableFuture<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action, Executor executor) \n```\n    public static void whenCompleteDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> {\n            sleep(10);\n            return \"task 1\";\n        });\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> {\n            sleep(20);\n            throw new RuntimeException(\"task2 RuntimeException\");\n        });\n        String task1res = task1.whenComplete((res, exp) -> {\n            println(\"task1 res:\" + res);\n            println(\"task1 exp:\" + exp);\n        }).join();\n        println(task1res);\n        String task2res = task2.whenComplete((res, exp) -> {\n            println(\"task2 res:\" + res);\n            println(\"task2 exp:\" + exp.getMessage());\n        }).join();\n        println(task2res);\n    }\n    --------- 输出 -----------\n    2019-06-23 19:50:03.429 ForkJoinPool.commonPool-worker-1: task1 res:task 1\n    2019-06-23 19:50:03.430 ForkJoinPool.commonPool-worker-1: task1 exp:null\n    2019-06-23 19:50:03.430 main: task 1\n    2019-06-23 19:50:03.439 ForkJoinPool.commonPool-worker-2: task2 res:null\n    2019-06-23 19:50:03.439 ForkJoinPool.commonPool-worker-2: task2 exp:java.lang.RuntimeException: task2 RuntimeException\n    Exception in thread \"main\" java.util.concurrent.CompletionException: java.lang.RuntimeException: task2 RuntimeException\n        at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:273)\n        at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:280)\n        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1592)\n        at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582)\n        at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n        at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\n    Caused by: java.lang.RuntimeException: task2 RuntimeException\n        at com.example.demo.ThreadTest.lambda$whenCompleteDemo$5(ThreadTest.java:44)\n        at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1590)\n        ... 5 more\n\n```\n#### handle\n- 运行完成时，对结果的处理。这里的完成时有两种情况，\n    - 正常执行，返回值\n    - 遇到异常抛出造成程序的中断。\n- 异常不会被抛到外层，不会造成外部线程因为异常中断\n-  public <U> CompletableFuture<U> handle(BiFunction<? super T, Throwable, ? extends U> fn) \n-  public <U> CompletableFuture<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn) \n-  public <U> CompletableFuture<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn, Executor executor) \n```\n    public static void handleDemo() {\n        CompletableFuture<String> task1 = CompletableFuture.supplyAsync(() -> {\n            sleep(10);\n            return \"task 1\";\n        });\n        CompletableFuture<String> task2 = CompletableFuture.supplyAsync(() -> {\n            sleep(20);\n            throw new RuntimeException(\"task2 RuntimeException\");\n        });\n        String task1res = task1.handle((res, exp) -> {\n            println(\"task1 res:\" + res);\n            println(\"task1 exp:\" + exp);\n            return res;\n        }).join();\n        println(task1res);\n        String task2res = task2.handle((res, exp) -> {\n            println(\"task2 res:\" + res);\n            println(\"task2 exp:\" + exp.getMessage());\n            return res;\n        }).join();\n        println(task2res);\n    }\n    --------- 输出 -----------\n    2019-06-23 19:50:53.542 ForkJoinPool.commonPool-worker-1: task1 res:task 1\n    2019-06-23 19:50:53.543 ForkJoinPool.commonPool-worker-1: task1 exp:null\n    2019-06-23 19:50:53.543 main: task 1\n    2019-06-23 19:50:53.552 ForkJoinPool.commonPool-worker-2: task2 res:null\n    2019-06-23 19:50:53.552 ForkJoinPool.commonPool-worker-2: task2 exp:java.lang.RuntimeException: task2 RuntimeException\n    2019-06-23 19:50:53.552 main: null\n\n```\n#### exceptionally\n- 异常处理逻辑，可以设置异常情况下的返回值\n- public CompletionStage<T> exceptionally(Function<Throwable, ? extends T> fn)\n```\n    public static void exceptionallyDemo() {\n        Object result = CompletableFuture.supplyAsync(() -> {\n            sleep(20);\n            throw new RuntimeException(\"task2 RuntimeException\");\n        }).exceptionally(e->{\n            System.out.println(\"exceptionally: \" +e);\n            return e.getMessage();\n        }).join();\n        System.out.println(\"exceptionallyDemo: \" +result);\n    }\n    --------- 输出 -----------\n    exceptionally: java.util.concurrent.CompletionException: java.lang.RuntimeException: task2 RuntimeException\n    exceptionallyDemo: java.lang.RuntimeException: task2 RuntimeException\n```\n### 其他方法\n- public boolean isDone()\n    - 是否已经完成（包括正常完成，异常完成，取消完成）\n- public T get() throws InterruptedException, ExecutionException\n    - 阻塞方式获取结果\n- public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException\n    - 带超时方式的阻塞方式获取结果\n- public T join() \n    - 阻塞至任务完成。会抛出CompletionException(unchecked类型)\n- public T getNow(T valueIfAbsent) \n    - 立即获取结果，如果任务没有执行完成，则返回valueIfAbsent\n- public boolean complete(T value)\n    - 如果任务还没有执行完成，则用当前值去替换完成值，否则继续使用原始值。\n    ```\n    private static void completeDemo() {\n        println(\"complete start\");\n        CompletableFuture<String> task = CompletableFuture.supplyAsync(() -> {\n            println(\"runAsync start\");\n            sleep(2000);\n            println(\"runAsync end\");\n            return \"task run finish\";\n        });\n        boolean complete = task.complete(\"finish\");\n        System.out.println(\"complete:\"+complete);\n        System.out.println(\"task:\"+task.join());\n        println(\"complete end\");\n    }\n    --------- 输出 -----------\n    2019-06-23 20:55:19.491 main: complete start\n    complete:true\n    task:finish\n    2019-06-23 20:55:19.547 main: complete end\n    ------------------------------------------------------------------------\n    private static void completeDemo() {\n        println(\"complete start\");\n        CompletableFuture<String> task = CompletableFuture.supplyAsync(() -> {\n            println(\"runAsync start\");\n            sleep(1);\n            println(\"runAsync end\");\n            return \"task run finish\";\n        });\n        sleep(10);\n        boolean complete = task.complete(\"finish\");\n        System.out.println(\"complete:\"+complete);\n        System.out.println(\"task:\"+task.join());\n        println(\"complete end\");\n    }\n    --------- 输出 -----------\n    2019-06-23 20:59:32.375 main: complete start\n    2019-06-23 20:59:32.426 ForkJoinPool.commonPool-worker-1: runAsync start\n    2019-06-23 20:59:32.428 ForkJoinPool.commonPool-worker-1: runAsync end\n    complete:false\n    task:task run finish\n    2019-06-23 20:59:32.437 main: complete end\n    ```\n- public boolean completeExceptionally(Throwable ex)\n    - 如果任务还没有执行完成，则以异常的方式中断执行（调用join方法会抛出该异常），如果执行完成,则返回false，并正常执行\n    ```\n        private static void completeExceptionallyDemo() {\n        println(\"completeExceptionally start\");\n        CompletableFuture<String> task = CompletableFuture.supplyAsync(() -> {\n            println(\"supplyAsync start\");\n            sleep(1);\n            println(\"supplyAsync end\");\n            return \"task run finish\";\n        });\n        sleep(10);\n        boolean complete = task.completeExceptionally(new NullPointerException(\"Test Null\"));\n        System.out.println(\"complete:\"+complete);\n        System.out.println(\"task:\"+task.join());\n        println(\"complete 1 end\");\n\n        task = CompletableFuture.supplyAsync(() -> {\n            println(\"supplyAsync start\");\n            sleep(1);\n            println(\"supplyAsync end\");\n            return \"task run finish\";\n        });\n        complete = task.completeExceptionally(new NullPointerException(\"Test Null\"));\n        System.out.println(\"complete:\"+complete);\n        System.out.println(\"task:\"+task.join());\n    }\n    --------- 输出 -----------\n    2019-06-23 21:11:48.276 main: completeExceptionally start\n    2019-06-23 21:11:48.330 ForkJoinPool.commonPool-worker-1: supplyAsync start\n    2019-06-23 21:11:48.331 ForkJoinPool.commonPool-worker-1: supplyAsync end\n    complete:false\n    task:task run finish\n    2019-06-23 21:11:48.340 main: complete 1 end\n    complete:true\n    Exception in thread \"main\" java.util.concurrent.CompletionException: java.lang.NullPointerException: Test Null\n        at java.util.concurrent.CompletableFuture.reportJoin(CompletableFuture.java:375)\n        at java.util.concurrent.CompletableFuture.join(CompletableFuture.java:1934)\n        at com.example.demo.ThreadTest.completeExceptionallyDemo(ThreadTest.java:35)\n        at com.example.demo.ThreadTest.main(ThreadTest.java:9)\n    Caused by: java.lang.NullPointerException: Test Null\n        at com.example.demo.ThreadTest.completeExceptionallyDemo(ThreadTest.java:33)\n        ... 1 more\n    ```\n- public CompletableFuture<T> toCompletableFuture()\n    - 返回CompletableFuture对象，实际代码中返回this\n- public boolean cancel(boolean mayInterruptIfRunning)\n    - 取消任务，mayInterruptIfRunning在当前实现没有任何作用。。（醉了）\n    - 任务取消后如果执行join方法会抛出CancellationException异常。\n    ```\n    private static void cancelDemo() {\n        CompletableFuture<Void> future = CompletableFuture.runAsync(new Runnable() {\n            @Override\n            public void run() {\n                println(\"Start\");\n                sleep(1000);\n                println(\"End\");\n\n            }\n        });\n        sleep(10);\n        boolean cancel = future.cancel(true);\n        println(cancel);\n        System.out.println(\"----------------------------------\");\n        future = CompletableFuture.runAsync(new Runnable() {\n            @Override\n            public void run() {\n                println(\"Start\");\n                sleep(10);\n                println(\"End\");\n\n            }\n        });\n        sleep(100);\n        cancel = future.cancel(true);\n        println(cancel);\n    }\n    --------- 输出 -----------\n    2019-06-23 21:56:33.060 ForkJoinPool.commonPool-worker-1: Start\n    2019-06-23 21:56:33.072 main: true\n    ----------------------------------\n    2019-06-23 21:56:33.075 ForkJoinPool.commonPool-worker-2: Start\n    2019-06-23 21:56:33.086 ForkJoinPool.commonPool-worker-2: End\n    2019-06-23 21:56:33.176 main: false\n    ```\n- public boolean isCancelled()\n    - 返回当前任务是否已经被取消\n- public boolean isCompletedExceptionally()\n    - 返回当前任务是否异常方式中断\n- public void obtrudeValue(T value)\n    - 将future的结果强制更改为value，无论是否发生异常\n- public void obtrudeException(Throwable ex)\n    - 将future的结果强制更改为异常，只要调用get或者join均会抛出该异常,同时会修改isCompletedExceptionally的结果\n- public int getNumberOfDependents()\n    - 返回有多少个后续stage依赖当前stage\n    ```\n    private static void getNumberOfDependentsDemo() {\n        CompletableFuture<String> t1 = CompletableFuture.supplyAsync(() -> {\n            sleep(1000);\n            return \"1\";\n        });\n        CompletableFuture<String> t2 = CompletableFuture.supplyAsync(() -> {\n            sleep(1000);\n            return \"2\";\n        });\n        sleep(10);\n        println(t1.getNumberOfDependents());\n        println(t2.getNumberOfDependents());\n        CompletableFuture<Void> all = CompletableFuture.allOf(t1, t2);\n        println(all.isDone());\n        println(t1.getNumberOfDependents());\n        println(t2.getNumberOfDependents());\n        all.join();\n        println(t1.getNumberOfDependents());\n        println(t2.getNumberOfDependents());\n    }\n    --------- 输出 -----------\n    2019-06-23 22:26:45.132 main: 0\n    2019-06-23 22:26:45.133 main: 0\n    2019-06-23 22:26:45.133 main: false\n    2019-06-23 22:26:45.133 main: 1\n    2019-06-23 22:26:45.133 main: 1\n    2019-06-23 22:26:46.122 main: 0\n    2019-06-23 22:26:46.122 main: 0\n    ```\n\n    ### 参考\n    - https://www.jianshu.com/p/6bac52527ca4\n    - https://www.jianshu.com/p/558b090ae4bb\n    - https://www.jb51.net/article/51163.htm\n    - https://www.cnblogs.com/dennyzhangdd/p/7010972.html\n    - https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html?is-external=true","tags":["Java","异步","CompletableFuture"],"categories":["Java"]},{"title":"I/O 多路复用之select、poll、epoll详解","url":"/2019/06/13/IO多路复用详解/","content":"\n-------------------------\n\nselect，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。\n\n-------------\n\n## 详解\n\n### select\n- 基本原理：\n    - select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。\n    - 调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。\n    - 当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。\n- select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。\n- select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。\n    - 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.\n- 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。\n    - 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。\n- 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。\n- 简述：1024\n\n### poll\n- 基本原理：\n    - poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态。\n    - 如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。\n    - 这个过程经历了多次无谓的遍历。\n- pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。\n- 同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。\n- 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\n- poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。\n- 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。\n- 事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\n- 简述：鸡肋\n\n### epoll\n- epoll是在2.6内核中提出的，是之前的select和poll的增强版本。\n- 相对于select和poll来说，epoll更加灵活，没有描述符限制。\n- epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。\n- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。\n- 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。\n    - 只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。\n- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。\n- 简述：杀手锏\n\n#### epoll工作模式\n- epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：\n    - LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\n    - ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\n##### LT模式\n- LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\n##### ET模式\n- ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\n- ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n\n#### epoll总结\n- 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而*epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。*(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。)\n- epoll的优点主要是一下几个方面：\n    - 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。\n    - IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。\n    - 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。\n## select、poll、epoll区别\n1、支持一个进程所能打开的最大连接数\n![最大连接数](IO多路复用详解/1.png)\n2、FD剧增后带来的IO效率问题\n![IO效率问题](IO多路复用详解/2.png)\n3、消息传递方式\n![消息传递方式](IO多路复用详解/3.png)","tags":["IO","select","poll","epoll"],"categories":["IO"]},{"title":"用户空间与内核空间","url":"/2019/06/12/用户空间与内核空间/","content":"\n-------------------------\n\n- 我们知道现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。\n- 操心系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。\n- 针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。\n- 每个进程可以通过系统调用进入内核，因此，Linux内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。\n- 空间分配如下图所示：\n![空间分配图](用户空间与内核空间/1.png)\n- 有了用户空间和内核空间，整个linux内部结构可以分为三部分，从最底层到最上层依次是：硬件-->内核空间-->用户空间。如下图所示：\n![linux内部结构图](用户空间与内核空间/2.png)\n\n- 需要注意的细节问题：\n    - 内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中。 \n    - Linux使用两级保护机制：0级供内核使用，3级供用户程序使用。\n- 内核态与用户态：\n    - 当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。\n    - 当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。\n- 参考资料：\n    - 用户空间与内核空间，进程上下文与中断上下文[总结][https://www.cnblogs.com/Anker/p/3269106.html]","tags":["Linux","操作系统"],"categories":["Linux"]},{"title":"Java NIO学习笔记","url":"/2019/06/02/Java NIO学习/","content":"\n\n- 内容基本来源:\n    - http://www.iocoder.cn/\n    - http://ifeve.com\n\n## 核心组件\n### Channel\n- Nio Channel类似于Java Stream，但又有几点不同\n    - Channel是双向的，Stream是单向的\n    - Channel可以非阻塞的进行读写操作，而Stream需要等待io操作完成，也就是阻塞的。\n    - Channel的读操作或者写操作都是依赖Buffer的，Stream没有依赖\n#### ServerSocketChannel\n- Java NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。\n- ServerSocketChannel类在 java.nio.channels包中。\n#### SocketChannel\n- Java NIO中的SocketChannel是一个连接到TCP网络套接字的通道。\n- 可以通过以下2种方式创建SocketChannel：\n    - 打开一个SocketChannel并连接到互联网上的某台服务器。\n    - 一个新连接到达ServerSocketChannel时，会创建一个SocketChannel。\n- 非阻塞模式与选择器搭配会工作的更好，通过将一或多个SocketChannel注册到Selector，可以询问选择器哪个通道已经准备好了读取，写入等。\n#### DatagramChannel\n- Java NIO中的DatagramChannel是一个能收发UDP包的通道。\n- 因为UDP是无连接的网络协议，所以不能像其它通道那样读取和写入。\n- 它发送和接收的是数据包。\n#### FileChannel\n- Java NIO中的FileChannel是一个连接到文件的通道。可以通过文件通道读写文件。\n- FileChannel无法设置为非阻塞模式，它总是运行在阻塞模式下。\n### Buffer\n- 一个 Buffer，本质上是内存中的一块，我们可以将数据写入这块内存，之后从这块内存获取数据。通过将这块内存封装成 NIO Buffer 对象，并提供了一组常用的方法，方便我们对该块内存的读写。\n- 基本属性\n    - capacity\n        - 属性，容量，Buffer 能容纳的数据元素的最大值。这一容量在 Buffer 创建时被赋值，并且永远不能被修改。\n    - limit\n        - 属性，上限。\n        - 写模式下，代表最大能写入的数据上限位置，这个时候 limit 等于 capacity 。\n        - 读模式下，在 Buffer 完成所有数据写入后，通过调用 #flip() 方法，切换到读模式。此时，limit 等于 Buffer 中实际的数据大小。因为 Buffer 不一定被写满，所以不能使用 capacity 作为实际的数据大小。\n    - position\n        - position 属性，位置，初始值为 0 。\n        - 写模式下，每往 Buffer 中写入一个值，position 就自动加 1 ，代表下一次的写入位置。\n        - 读模式下，每从 Buffer 中读取一个值，position 就自动加 1 ，代表下一次的读取位置。( 和写模式类似 )\n    - mark \n        - 属性，标记，通过 #mark() 方法，记录当前 position ；通过 reset() 方法，恢复 position 为标记。\n        - 写模式下，标记上一次写位置。\n        - 读模式下，标记上一次读位置。\n    - 关系\n        - mark <= position <= limit <= capacity\n- 创建Buffer\n    - 每个 Buffer 实现类，都提供了 #allocate(int capacity) 静态方法，帮助我们快速实例化一个 Buffer 对象。\n        - ByteBuffer 实际是个抽象类，返回的是它的基于堆内( Non-Direct )内存的实现类 HeapByteBuffer 的对象。\n    - 每个 Buffer 实现类，都提供了 #wrap(array) 静态方法，帮助我们将其对应的数组包装成一个 Buffer 对象。\n        - 和 #allocate(int capacity) 静态方法一样，返回的也是 HeapByteBuffer 的对象。\n    - 每个 Buffer 实现类，都提供了 #allocateDirect(int capacity) 静态方法，帮助我们快速实例化一个 Buffer 对象。\n        - 和 #allocate(int capacity) 静态方法不一样，返回的是它的基于堆外( Direct )内存的实现类 DirectByteBuffer 的对象。\n- 向 Buffer 写入数据\n    - 每个 Buffer 实现类，都提供了 #put(...) 方法，向 Buffer 写入数据。\n    - 对于 Buffer 来说，有一个非常重要的操作就是，我们要讲来自 Channel 的数据写入到 Buffer 中。\n    - 在系统层面上，这个操作我们称为读操作，因为数据是从外部( 文件或者网络等 )读取到内存中。\n    - 通常在说 NIO 的读操作的时候，我们说的是从 Channel 中读数据到 Buffer 中，对应的是对 Buffer 的写入操作\n- 从 Buffer 读取数据\n    - 每个 Buffer 实现类，都提供了 #get(...) 方法，从 Buffer 读取数据。\n    - 对于 Buffer 来说，还有一个非常重要的操作就是，我们要讲来向 Channel 的写入 Buffer 中的数据。\n    - 在系统层面上，这个操作我们称为写操作，因为数据是从内存中写入到外部( 文件或者网络等 )。\n- rewind()  flip()   clear()\n    - flip  \n        - 如果要读取 Buffer 中的数据，需要切换模式，从写模式切换到读模式。\n    - rewind\n        - 可以重置 position 的值为 0 。因此，我们可以重新读取和写入 Buffer 了。\n        - 该方法主要针对于读模式，所以可以翻译为“倒带”。\n    - clear\n        - 可以“重置” Buffer 的数据。因此，我们可以重新读取和写入 Buffer 了。\n        - 该方法主要针对于写模式。\n        - Buffer 的数据实际并未清理掉\n- mark() 搭配 reset()\n    - mark\n        - 保存当前的 position 到 mark 中。\n    - reset\n        - 恢复当前的 postion 为 mark 。\n\n#### 关于 Direct Buffer 和 Non-Direct Buffer 的区别\n- Direct Buffer:\n    - 所分配的内存不在 JVM 堆上, 不受 GC 的管理.(但是 Direct Buffer 的 Java 对象是由 GC 管理的, 因此当发生 GC, 对象被回收时, Direct Buffer 也会被释放)\n    - 因为 Direct Buffer 不在 JVM 堆上分配, 因此 Direct Buffer 对应用程序的内存占用的影响就不那么明显(实际上还是占用了这么多内存, 但是 JVM 不好统计到非 JVM 管理的内存.)\n    - 申请和释放 Direct Buffer 的开销比较大. 因此正确的使用 Direct Buffer 的方式是在初始化时申请一个 Buffer, 然后不断复用此 buffer, 在程序结束后才释放此 buffer.\n    - 使用 Direct Buffer 时, 当进行一些底层的系统 IO 操作时, 效率会比较高, 因为此时 JVM 不需要拷贝 buffer 中的内存到中间临时缓冲区中.\n- Non-Direct Buffer:\n    - 直接在 JVM 堆上进行内存的分配, 本质上是 byte[] 数组的封装.\n    - 因为 Non-Direct Buffer 在 JVM 堆中, 因此当进行操作系统底层 IO 操作中时, 会将此 buffer 的内存复制到中间临时缓冲区中. 因此 Non-Direct Buffer 的效率就较低.\n### Selector\n- Selector ， 一般称为选择器。它是 Java NIO 核心组件中的一个，用于轮询一个或多个 NIO Channel 的状态是否处于可读、可写。如此，一个线程就可以管理多个 Channel ，也就说可以管理多个网络连接。也因此，Selector 也被称为多路复用器。\n- 那么 Selector 是如何轮询的呢？\n    - 首先，需要将 Channel 注册到 Selector 中，这样 Selector 才知道哪些 Channel 是它需要管理的。\n    - 之后，Selector 会不断地轮询注册在其上的 Channel 。如果某个 Channel 上面发生了读或者写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作。\n- 优缺点\n    - 优点\n        - 使用一个线程能够处理多个 Channel 的优点是，只需要更少的线程来处理 Channel 。\n        - 事实上，可以使用一个线程处理所有的 Channel 。\n        - 对于操作系统来说，线程之间上下文切换的开销很大，而且每个线程都要占用系统的一些资源( 例如 CPU、内存 )。因此，使用的线程越少越好。\n    - 缺点\n        - 因为在一个线程中使用了多个 Channel ，因此会造成每个 Channel 处理效率的降低。\n- 创建 Selector\n    - 通过 #open() 方法，我们可以创建一个 Selector 对象。代码如下：\n- 注册 Chanel 到 Selector 中\n    - 为了让 Selector 能够管理 Channel ，我们需要将 Channel 注册到 Selector 中。\n    - 如果一个 Channel 要注册到 Selector 中，那么该 Channel 必须是非阻塞。\n    - FileChannel 是不能够注册到 Channel 中的，因为它是阻塞的。\n    - 监听四种不同类型的事件：\n        - Connect ：连接完成事件( TCP 连接 )，仅适用于客户端，对应 SelectionKey.OP_CONNECT 。\n        - Accept ：接受新连接事件，仅适用于服务端，对应 SelectionKey.OP_ACCEPT 。\n        - Read ：读事件，适用于两端，对应 SelectionKey.OP_READ ，表示 Buffer 可读。\n        - Write ：写时间，适用于两端，对应 SelectionKey.OP_WRITE ，表示 Buffer 可写。\n    - Channel 触发了一个事件，意思是该事件已经就绪：\n        - 一个 Client Channel Channel 成功连接到另一个服务器，称为“连接就绪”。\n        - 一个 Server Socket Channel 准备好接收新进入的连接，称为“接收就绪”。\n        - 一个有数据可读的 Channel ，可以说是“读就绪”。\n        - 一个等待写数据的 Channel ，可以说是“写就绪”。\n- SelectionKey 类\n    - 调用 Channel 的 #register(...) 方法，向 Selector 注册一个 Channel 后，会返回一个 SelectionKey 对象。\n    - SelectionKey 在 java.nio.channels 包下，被定义成一个抽象类，表示一个 Channel 和一个 Selector 的注册关系。\n    - 注册关系，包含如下内容：\n        - interest set: 感兴趣的事件集合。\n        - ready set ：就绪的事件集合。\n        - Channel\n        - Selector\n        - attachment ：可选的附加对象。可以向 SelectionKey 添加附加对象。\n- 通过 Selector 选择 Channel\n    - 在 Selector 中，提供三种类型的选择( select )方法，返回当前有感兴趣事件准备就绪的 Channel 数量。\n        - select() 阻塞到至少有一个 Channel 在你注册的事件上就绪了。\n        - select(long timeout) 在 `#select()` 方法的基础上，增加超时机制。\n        - selectNow() 和 `#select()` 方法不同，立即返回数量，而不阻塞。\n    - select 方法返回的 int 值，表示有多少 Channel 已经就绪。也就是自上次调用 select 方法后有多少 Channel 变成就绪状态。\n- 获取可操作的 Channel\n    - 一旦调用了 select 方法，并且返回值表明有一个或更多个 Channel 就绪了，然后可以通过调用Selector 的 #selectedKeys() 方法，访问“已选择键集( selected key set )”中的就绪 Channel 。\n    - 注意，当有新增就绪的 Channel ，需要先调用 select 方法，才会添加到“已选择键集( selected key set )”中。否则，我们直接调用 #selectedKeys() 方法，是无法获得它们对应的 SelectionKey 们。\n- 唤醒 Selector 选择\n    - 某个线程调用 #select() 方法后，发生阻塞了，即使没有通道已经就绪，也有办法让其从 #select() 方法返回。\n    - 只要让其它线程在第一个线程调用 select() 方法的那个 Selector 对象上，调用该 Selector 的 #wakeup() 方法，进行唤醒该 Selector 即可。\n    - 注意，如果有其它线程调用了 #wakeup() 方法，但当前没有线程阻塞在 #select() 方法上，下个调用 #select() 方法的线程会立即被唤醒。\n- 关闭 Selector\n    - 当我们不再使用 Selector 时，可以调用 Selector 的 #close() 方法，将它进行关闭。\n        - Selector 相关的所有 SelectionKey 都会失效。\n        - Selector 相关的所有 Channel 并不会关闭。\n    - 此时若有线程阻塞在 #select() 方法上，也会被唤醒返回。\n\n\n## NIO与BIO相比\n\n### NIO\n\n- 基于缓冲区\n    - 基于Buffer读取，将数据从Channel中读取到Buffer中，或者从buffer中将数据写回到channel中。因为数据已经读取到缓冲区当中，所以操作不需要顺序执行，增加其灵活性。\n- 非阻塞IO\n    - 一个线程从channel中执行io操作的时候，无论是读取还是写入，都无需等待完成，都会直接返回，不会阻塞当前正在执行的线程。\n- 有选择器\n    - 一个线程可以通过一个Selector管理多个Channel，选择器是实现非阻塞io的核心。\n    - Selector内部自动为我们实现了轮训select操作，判断channel是否有已经就绪的io事件（连接，读，写等）\n\n### BIO\n- 基于流(Stream)\n    - 以流式方式进行处理，顺序的从一个stream中读取一个或者多个字节，直到读取完成。由于没有缓存区，不能随意更改读取指针的位置。\n- 阻塞IO\n    - 一个线程操作io的时候，该线程会被阻塞，直到数据被读取或者写入完成。\n","tags":["Java","NIO"],"categories":["Java"]},{"title":"MySQL学习总结(4)","url":"/2019/05/08/MySQL学习总结(4)/","content":"锁\n---------\n根据加锁的范围，MySQL里面的锁大致可以分为全局锁，表级锁和行级锁。\n\n# 全局锁\n- MySql提供了一个加全局锁的方法，Flush tables with read lock(FTWRL)\n- 适用场景：全库逻辑备份\n- 阻塞: 数据更新语句，数据定义语句，更新类事务提交语句\n\n# 表级锁\n- MySql中表级锁有两种：表锁 和 元数据锁\n## 表锁\n- 表锁语法是: lock tables ... read/write\n- 对于InnoDB这种支持行锁的引擎，一般不使用lock tables方式控制并发\n## 元数据锁（matedata lock，MDL）\n- MDL不需要显示使用，在访问一个表的时候会被自动加上。\n- 作用：保证读写的正确性。\n- 增删改查操作自动加MDL读锁，修改表结构的时候加MDL写锁\n\n# 幻读\n\n- 问题: 即使把所有的记录都加上锁，也还是阻止不了新插入的记录。\n\n## 如何解决幻读问题\n\n- 产生幻读的原因是：行锁只能锁住行，新插入记录这个动作，要更新的是记录之间的间隙。\n- 解决办法： InnoDB引入了新的锁，间隙锁(Gap Lock)\n- 与间隙锁冲突的操作:往这个间隙中插入一条记录\n- 间隙锁和行锁合称：next-key lock\n\n\n# 加锁总结\n\n- 原则1：加锁的基本单位是next-key lock，是前开后闭区间。\n- 原则2：查找过程中访问到的对象才会加锁。\n- 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n- 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。\n- Bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n\n- 锁是加在索引上的\n- 用lock in share mode来给行加读锁避免数据被更新的话，必须要绕过覆盖索引优化，查询字段中加入索引中不存在的字段。\n- 分析加锁规则的时候可以用next-key lock来进行分析，但是具体执行的时候，是要分成间隙锁和行锁两阶段来执行的。\n\n\n-----\n- 源：<极客时间> MySQL实战45讲教程","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL学习总结(3)","url":"/2019/05/07/MySQL学习总结(3)/","content":"索引\n--------------\n\n# 索引常见模型\n- 哈希表\n- 适用于只有等值查询的场景\n- 有序数组\n- 适用于等值查询，范围查询\n- 更新成本高，适用于静态存储引擎\n- 搜索树\n- 查询复杂度O(log(N))\n- 更新操作复杂度O(log(N))\n- 为了适配磁盘，往往使用N叉树\n\n# InnoDB索引模型\n\n- 表都是根据主键顺序以索引形式存放。\n- 使用了B+树索引模型，数据存储在B+树中。\n\n- 根据叶子节点内容，索引类型分主键索引和非主键索引\n- 主键索引叶子节点存放的是整行的数据，也成为聚簇索引。\n- 非主键索引叶子节点存放的是主键的值，非主键索引也成为二级索引\n- 区别：基于非主键索引的查询需要多扫描一颗索引树。\n\n# 索引维护\n\n- 一个数据页满了，按照B+Tree算法，会新增加一个数据页，这个过程称为页分裂，会导致性能下降，空间利用率降低大概一半。\n- 两个相邻的数据页利用率如果都很低，会做数据合并，也就是页分裂逆过程\n- B+树的插入可能会引起数据页的分裂，删除可能会引起数据页的合并，二者都是比较重的IO消耗，所以比较好的方式是顺序插入数据，这也是我们一般使用自增主键的原因之一\n- 在Key-Value的场景下，只有一个索引且是唯一索引，则适合直接使用业务字段作为主键索引\n- 非主键索引的叶子结点存储的是主键的值，所以主键字段占用空间不宜过大。同时，其查找数据的过程称为“回表”，需要先查找自己得到主键值，再在主键索引上边查找数据内容。\n- 索引的实现由存储引擎来决定，InnoDB使用B+树（N叉树，比如1200叉树），把整颗树的高度维持在很小的范围内，同时在内存里缓存前面若干层的节点，可以极大地降低访问磁盘的次数，提高读的效率。\n\n# 覆盖索引\n- 回到主键索引树搜索的过程，我们称为回表\n- 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n# 最左前缀原则\n- B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n- 在建立联合索引的时候，如何安排索引内的字段顺序\n- 第一原则，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是最需要有限考虑的。\n- 再次考虑空间\n\n# 索引下推\n- MySQL 5.6 引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n# 小结\n- 满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。\n- 设计表结构时，也要以减少资源消耗作为目标。\n\n\n-----\n- 源：<极客时间> MySQL实战45讲教程","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL学习总结(2)","url":"/2019/05/06/MySQL学习总结(2)/","content":"事务隔离级别\n-------------------\n\n## 问题\n- 脏读\n- 可重复读\n- 幻读\n\n## 隔离级别\n- 读未提交\n- 一个事务还没提交的时候，其所作的变更可以被其他事务看到。\n- 读提交\n- 一个事务提交后，他做的变更才会被其他事务看到。\n- 可重复读\n- 一个事务执行的过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。\n- 串行化\n- 对于同一行记录，写会加写锁，读会加读锁，一旦出现读写锁冲突的时候，后访问的事务必须等前一个事务完成才能继续执行。\n\n## 隔离级别实现\n- 数据库里面会创建一个视图，访问的时候以这个视图的逻辑结果为准。\n- 可重复读，视图在事务启动时创建，这个事务存在期间都在用这个视图。\n- 读提交，视图实在每个sql语句开始执行的时候创建\n- 读未提交，直接返回记录最新值，没有视图概念\n- 串行化，直接用加锁的方式避免并行访问\n- 隔离的实现\n- 每条记录在更新的时候都会同事记录一条回滚操作。记录上的最新值，通过回滚操作都可以得到前一个状态的值。\n- 系统会在没有实物需要使用到这些回滚日志的时候，删除回滚日志。\n- 不要使用长事务\n- 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面会存储他可能用到的所有回滚记录，导致占用大量的存储空\n\n-----\n- 源：<极客时间> MySQL实战45讲教程","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL学习总结(1)","url":"/2019/05/05/MySQL学习总结(1)/","content":"\n# SQL执行过程\n\n- 客户端 -> 连接器 -> 分析器 -> 优化器 -> 执行器\n- 连接器\n- 管理连接，权限验证，维持管理连接\n- 分析器\n- 词法分析，语法分析\n- 优化器\n- 执行计划生成，索引选择\n- 执行器\n- 操作引擎，返回结果\n- 存储引擎\n- 存储数据，提供读写接口\n- 连接器会优先查询缓存，如果命中则直接返回结果\n\n### 连接器\n- 连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n\n### 查询缓存\n- 大多数情况下不要使用查询缓存\n- 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。\n\n### 分析器\n- 分析器先会做“词法分析”。\n\n### 优化器\n- 优化器是在表里面有多个索引的时候，决定使用哪个索引\n- 在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n\n### 执行器\n- 执行之前会进行权限校验\n- 根据表的引擎定义，使用引擎提供的接口\n- 获取记录集作为结果返回给客户端。\n\n# MySQL日志模块\n\n### redo log （重做日志）\n- WAL （Write-Ahead Logging）\n- 核心先写日志，在写磁盘\n- 保证及时数据库发生异常重启，之前提交的记录不会丢失（crash-safe）\n- InnoDB特有\n\n### binlog （归档日志）\n\n\n### 对比\n- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\n- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。\n- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n### 两阶段提交\n\n- 引擎讲更新操作记录到redo log中，此时redo log处于prepare状态，同时告知执行器执行完成，可以提交事务。\n- 执行器生成该操作的binlog并写入磁盘。\n- 执行器调用引擎提交事务接口，引擎讲刚刚写入的redo log改为提交commit状态。\n- redo log的写入拆成了2个步骤prepare和commit，即两阶段提交。\n\n#### 先写rodo log 后写binlog问题\n- 写完rodo log 后，binlog未写完，重启后，主库可以通过redo log恢复，但是通过binlog恢复临时库会丢失该次更新。\n\n#### 先写binlog 后写redo log问题\n- 写完binlog后未写redo log，重启后由于redo log没写，即该次事务无效，而binlog中已经包含，则用binlog恢复会多出来一个事务。\n\n-----\n- 源：<极客时间> MySQL实战45讲教程","tags":["MySQL"],"categories":["MySQL"]},{"title":"记一次线上ES Down机事故","url":"/2018/12/20/记一次线上ES Down机事故/","content":"\n**背景**\n\n- 前两天的某个上午，正在开会ing。。突然收到了报警Es服务不可用，同时几个其他业务部门的人也都过来反馈说ES挂了。\n- 二话不说先启动ES恢复业务再说。然后就开始分析日志找问题了。\n\n**排查过程**\n\n- 先是怀疑系统资源被用满了，看了一下zabbix，系统负载不太高，8C 16G机器load维持在5-10左右波动，应该不是这个问题。\n- 看了一下网络读取带宽，也没有达到什么高峰(时间是上午10点半左右)，感觉系统方面应该不至于出问题。\n- 又怀疑是出现OOM内存不足，可是也没发现dump文件，然后就开始找ES日志看问题了\n- 看ES日志在down机之前有一个java.lang.StackOverflowError，应该就是这个原因了，之前还真没碰到过这个问题，将错误信息在google上面一查，有一些说是使用前缀或者正则查询导致的，感觉应该是这个问题，便开始抓取down机前1分钟的日志。\n- 运气不坏，很快就找到了一个高度怀疑的参数，是在搜索建议词中出现的，搜索建议词使用的es原生suggest + prefix，传过来的关键词是一个json数组去除了双引号和冒号(应该是api做的过滤)，但是里面还有1600+字符，同时包含了“{}[]”符号，在测试机上面进行一下测试，把这个Query放进去，ES果然直接Down掉了，问题排查就算是完成了。\n\n**修复过程**\n\n- 紧急发布了Hotfix（就是加入参数长度限制，特殊字符限制）\n- 后续准备考虑使用Ngram来解决这个问题\n- 吸取教训：\n\t- 能不用就尽可能不用通配符查询，无论是前缀还是模糊\n\t- 大不了空间换时间，暴力使用ngram解决问题\n\t- 参数一定要加入校验机制\n\n**原因分析(转)**\n\n- 问题出现时，ES服务端日志有如下报错:\n```\njava.lang.StackOverflowError: null\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n        at org.apache.lucene.util.automaton.Operations.isFinite(Operations.java:1053) ~[lucene-core-6.2.1.jar:6.2.1 43ab70147eb494324a1410f7a9f16a896a59bc6f - shalin - 2016-09-15 05:15:20]\n```\n\n- Prefix/Regex/Fuzzy一类的Query，是直接构造的deterministic automaton，如果查询字符串过长，或者pattern本身过于复杂，构造出来的状态过多，之后一个isFinite的Lucene方法调用可能产生堆栈溢出。\n\n\n- PrefixQuery继承自Lucene的AutomatonQuery，在实例化的时候，maxDeterminizedStates传的是Integer.MAX_VALUE, 并且生成automaton之前，prefix的长度也没有做限制。\n\n- 附参考链接：\n\t- https://elasticsearch.cn/article/186\n\t- https://elasticsearch.cn/article/171\n\t- https://github.com/elastic/elasticsearch/issues/24553","tags":["ElasticSearch","通配符","前缀查询"],"categories":["ElasticSearch"]},{"title":"一次Es排序优化记录","url":"/2018/12/13/一次Es排序优化记录/","content":"\n\n**背景**\n\n- 13号有一个大上线，其中一个功能就是排序功能，说复杂也不复杂，说难吧也不难，但是麻烦的就是加上Sort之后速度奇慢无比。\n- 排序实现也不太复杂，基本都是基于function score + sort 实现，对应不同的商品品类，有不同的排序规则(Hmm，目前还没有上个性化排序。。)，实现方式就是定位品类之后，用function score进行提升部分商品的score，在这之后用sort进行【score + field1 +field2】的排序，看着也不复杂对吧。\n- ES机器配置不太高(qiong.....)4C 8G * 3，索引中在售商品也不太多几，万的样子，分布到200多个城市站，总共合起来大概千万出头的数据(有部分非在售商品)。\n\n**问题**\n\n- 每次定位到品类之后，使用了品类排序【score + field1 +field2】，速度奇慢无比，平时几十毫秒的查询能变成5-6秒甚至更多，有点让人无法忍受\n\n**尝试过程**\n\n- 最开始打算用缓存解决问题，但是更新频率实在有点高的不行。。这个有点扛不住。\n- 后来打算按照城市站分索引，这样一个索引数据量就很小了，排序应该就不是什么大问题了，但是查询有点麻烦。\n- 先reindex一个小的索引，试了试排序速度，果然恢复到了几十毫秒的数量级了。\n突然想到了也许多加一些分片也可以解决这个问题，毕竟我们是有城市站routing的啊。\n- 不过城市站反正是查询的必须条件已经加上了routing，吧shard从默认的5个先加到了50个，试了一下果然速度提升到100ms左右，再往上加shard的时候发现了另外一个问题，大批量的出现ESReject问题，可能是一次bulk或者index数据的量略大，ES又需要进行routing的原因吧，最终上线的时候，保守一点使用了40 Shard，目前速度尚在可接受范围(线上最起码是8c 16G的。。)，如果想在提升速度，估计要加机器了(还是那句话。。。qiong。。。)\n\n\n**加速原理**\n\n- 没看源码，纯属自己猜测：\n\t- 感觉shard和分索引应该差不多，Es Query需要找到对应的shard，拽出来符合条件的数据进行排序，然后输出出去。拽出来数据应该是在shard内部进行过排序，如果shard内部文档过多，速度应该会比较慢。\n\t- 我们这边业务场景是城市站必须有，而且文档按照城市站分开后相对来说很平均了(当然还是有部分shard很小。。)，将shard数量提高以后，shard内部排序的文档数量少了很多，速度自然就上去了。\n\t- shard过多，在ES进行bulk插入数据时候，routing到对应分片，这步骤应该会花较多时间，如果机器配置不太给力的话（囧。。比如说我们），shard数量还是不要太多，否则机器负载会很高很高(前两天看到负载破20了 - -！还好只是瞬时)\n","tags":["ElasticSearch","Sort","routing","shard"],"categories":["ElasticSearch"]},{"title":"MySQL实现Rank排名","url":"/2018/11/25/MySQL Rank/","content":"\n\n\n- Hmm..就是在leetcode上面做题碰到了一个题目，让用SQL实现根据分值排序，原题描述如下：\n```\n编写一个 SQL 查询来实现分数排名。如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。\n\n+----+-------+\n| Id | Score |\n+----+-------+\n| 1  | 3.50  |\n| 2  | 3.65  |\n| 3  | 4.00  |\n| 4  | 3.85  |\n| 5  | 4.00  |\n| 6  | 3.65  |\n+----+-------+\n例如，根据上述给定的 Scores 表，你的查询应该返回（按分数从高到低排列）：\n\n+-------+------+\n| Score | Rank |\n+-------+------+\n| 4.00  | 1    |\n| 4.00  | 1    |\n| 3.85  | 2    |\n| 3.65  | 3    |\n| 3.65  | 3    |\n| 3.50  | 4    |\n+-------+------+\n```\n\n- 生产中应该不会遇到这种问题吧。。有的话应该也是新出表之类的解决，不过想了想，这个题还真么啥解决思路（自己引用自己还是内外层的。。在这之前真不会TAT）\n- 结合别人的答案，总算是弄明白了这个SQL是怎么写了\n\n```\nSELECT\n\tScore,\n\t(\n\tSELECT\n\t\tcount( DISTINCT score ) \n\tFROM\n\t\tScores \n\tWHERE\n\t\tscore >= s.score \n\t) AS Rank \nFROM\n\tScores s \nORDER BY\n\tScore DESC;\n```\n\n- 外层其实很好理解，查询score表中Score和Rank，倒序一下。\n- 内层就是把外层每条的Score拿到(语句中的s.score)，然后统计一下不小于s.score的值(去重)，这个结果也就是对应的RanK了。\n\n- 换个条件。。如果两个分数相同，则两个分数排名（Rank）相同，名次之间“间隔”，也可以用这个思路来解决。\n\n```\nSELECT\n\tScore,\n\t(\n\tSELECT\n\t\tcount( score ) + 1 \n\tFROM\n\t\tScores \n\tWHERE\n\t\tscore > s.score \n\t) AS Rank \nFROM\n\tScores s \nORDER BY\n\tScore DESC;\n```","tags":["MySQL"],"categories":["MySQL"]},{"title":"Linux ssh 远程执行命令环境切换问题","url":"/2018/11/19/Linux ssh 远程执行命令环境切换问题/","content":"\n-------------------------\n\n- 今天将公司之前的shell脚本处理一下，放到Jenkins中执行，方便大家部署，结果出现了一个奇怪的问题，通过ssh 远程执行命令的时候发现找不到java命令。\n- 直接用ssh切换到那台机器是没有问题的，java命令存在。远程执行 ssh -t user@host 'java -version' 提示java命令找不到。\n- 查了一堆资料，定位了问题： \n    - 使用这种方式执行命令，不会执行/etc/profile文件，而我的java_home，java path都是在/etc/profile文件中配置的\n- 解决也不太复杂：\n    - 方法1：ssh -t user@host 'source /etc/profile && java -version' 久违的jdk1.8终于出来了(嗯。。我就用这个解决的)\n    - 方法2: 修改 ~/.bashrc 加入java_home，java path (这个没敢动。。因为机器是公用的。。。)\n- 补充知识点：\n\n 1. 通过SSH登录后再执行命令和脚本\n    这种方式会使用Bash的interactive + login shell模式，这里面有两个概念需要解释：interactive和login。\n    - login故名思义，即登陆，login shell是指用户以非图形化界面或者以ssh登陆到机器上时获得的第一个shell，简单些说就是需要输入用户名和密码的shell。因此通常不管以何种方式登陆机器后用户获得的第一个shell就是login shell。\n    - interactive意为交互式，这也很好理解，interactive shell会有一个输入提示符，并且它的标准输入、输出和错误输出都会显示在控制台上。所以一般来说只要是需要用户交互的，即一个命令一个命令的输入的shell都是interactive shell。而如果无需用户交互，它便是non-interactive shell。通常来说如bash script.sh此类执行脚本的命令就会启动一个non-interactive shell，它不需要与用户进行交互，执行完后它便会退出创建的Shell。\n    - 在interactive + login shell模式中，Shell首先会加载/etc/profile文件，然后再尝试依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找：\n    \n    ```\n    ~/.bash_profile\n    ~/.bash_login\n    ~/.profile\n    ```\n\n 2. 通过SSH直接执行远程命令和脚本\n    这种方式会使用Bash的non-interactive + non-login shell模式，它会创建一个shell，执行完脚本之后便退出，不再需要与用户交互。\n    - no-login shell，顾名思义就是不是在登录Linux系统时启动的（比如你在命令行提示符上输入bash启动）。它不会去执行/etc/profile文件，而会去用户的HOME目录检查.bashrc并加载。\n    - 系统执行Shell脚本的时候，就是属于这种non-interactive shell。Bash通过BASH_ENV环境变量来记录要加载的文件，默认情况下这个环境变量并没有设置。如果有指定文件，那么Shell会先去加载这个文件里面的内容，然后再开始执行Shell脚本。\n\n\n\n\n引用: https://www.cnblogs.com/zhenyuyaodidiao/p/9287497.html","tags":["Linux","ssh"],"categories":["Linux"]},{"title":"Linux crontab 执行Python脚本执行一半问题解决","url":"/2018/10/29/Linux crontab 执行Python脚本执行一半问题解决/","content":"\n-------------------------\n\n- 上周五用python2实现了一个简易的canal监控报警脚本(主要就是检测时间戳，超时就进行邮件通知)，脚本不太复杂，上传到线上服务器之后，直接运行一切正常，模拟了一下错误数据，也正常发出了邮件通知。然后就配置了一下crontab定时任务，每5分钟执行一次检测，本来以为万事大吉，谁知道部署之后，日志什么的都正常更新了，唯独就是邮件没有发送出去。\n- 问题排查：\n    - 本地运行正常，服务器直接通过python monitor.py 执行，也正常。唯独就是通过crontab执行不正常，只是记录了日志，没有进行邮件通知。\n    - 开始怀疑是程序中引用路径有问题，crontab执行命令不是在monitor脚本目录执行，获取sys.args[0]路径可能有问题，全都替换成绝对路径，问题依旧。\n    - 无解，谷歌百度一番之后，有人说执行shell脚本，要使用/bin/bash /path/shell.sh，这样才能正常运行，那我这个估计也是这个原因。修改crontab命令使用： /usr/bin/python /data/monitor.py 重于收到了久违的邮件，至此问题解决。\n- 原因：\n    - 初步怀疑直接运行python /data/monitor.py 可能会使用其他版本的python（python3），我的脚本使用python2写的(已知账户均有python2，没有python3环境，懒得找运维-0-)，其中用到了print xxx的语法，由于我没有root权限，这个暂时不进行验证了。\n- 总结：\n    - 使用crontab所有命令，执行器都要使用绝对路径，免得引起不必要的麻烦-0-！\n","tags":["Linux","crontab","Python"],"categories":["Linux"]},{"title":"Swagger使用简介","url":"/2018/10/09/Swagger使用简介/","content":"\n# Swagger使用简介\n\n## Swagger简介\n\n没有API文档工具之前，大家都是手写API文档的，在什么地方书写的都有，有在confluence上写的，有在对应的项目目录下readme.md上写的。这种方式不是说不好，大家都有一个通病，就是懒得更新文档，隔了一段时间，接口变动了什么没人清楚了。另外还有就是开始写文档的时候特别痛苦，每个字段，一行行注释解释。\n其实大多数开发都还是写注释的（为了防止自己看不懂吧。。），如果稍加修改，可以从注释中自动生成文档就好了。Hmm..Swagger可以完成这个功能，尤其是针对Java，C#这样的项目，而且是前后端分离的，更加合适了。\nSwagger能做什么呢？可以自动根据Controller自动生成对应的文档，并且提供测试接口。如果你能容忍一定程度的代码侵入（也不是太多。。就是在需要暴露的Model和Controller上加点注解，一个配置文件类），Swagger还是很方便的。\n\n\n## Swagger 和 Spring 项目整合\n\n其实很简单，加个依赖，加个配置类，嗯。。这个应该是最低工作保证了。。\n\n先说依赖\n\n```\n    <!-- swagger2 生成对应的Json文档，这个应该可以说是核心依赖了 -->\n    <dependency>\n        <groupId>io.springfox</groupId>\n        <artifactId>springfox-swagger2</artifactId>\n        <version>2.6.1</version>\n    </dependency>\n    <!-- swagger-ui 为项目提供api展示及测试的界面 -->\n    <dependency>\n        <groupId>io.springfox</groupId>\n        <artifactId>springfox-swagger-ui</artifactId>\n        <version>2.6.1</version>\n    </dependency>\n    <!-- 集成 swagger 的时候，缺少这个 jar包是不OK的-->\n    <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-databind</artifactId>\n        <version>2.8.6</version>\n    </dependency>\n```\n\n说真的，依赖包不是太多springfox-swagger2是生成接口访问JSON和核心，同时依赖jackson。界面展示依赖的是swagger-ui。嗯。。引入的时候注意下Jar包冲突。。尤其是Spring的版本不同exclusion一下。。\n\n依赖包这样基本就已经满足了，剩下就是加一个配置类就好了。如下：\n\n```\n\n \nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport springfox.documentation.builders.ApiInfoBuilder;\nimport springfox.documentation.builders.ParameterBuilder;\nimport springfox.documentation.builders.RequestHandlerSelectors;\nimport springfox.documentation.schema.ModelRef;\nimport springfox.documentation.service.ApiInfo;\nimport springfox.documentation.service.Parameter;\nimport springfox.documentation.spi.DocumentationType;\nimport springfox.documentation.spring.web.plugins.Docket;\nimport springfox.documentation.swagger2.annotations.EnableSwagger2;\nimport java.util.ArrayList;\nimport java.util.List;\n\n\n@Configuration\n@EnableSwagger2\npublic class ApiConfig {\n    @Bean(name = \"docket\")\n    public Docket api() {\n        ParameterBuilder ticketPar = new ParameterBuilder();\n        List<Parameter> pars = new ArrayList<>();\n        ticketPar.name(\"login-token\").description(\"登录Token\")\n                .modelRef(new ModelRef(\"string\")).parameterType(\"header\")\n                //header中的ticket参数非必填，传空也可以\n                .required(false).build(); \n        //根据每个方法名也知道当前方法在设置什么参数\n        pars.add(ticketPar.build());\n        Docket docket = new Docket(DocumentationType.SWAGGER_2)\n                .select()\n                .apis(RequestHandlerSelectors.any())\n                .build().globalOperationParameters(pars);\n                docket.apiInfo(apiInfo());\n        return docket;\n    }\n    private ApiInfo apiInfo() {\n        return new ApiInfoBuilder()\n                .title(\"后台接口\")\n                .description(\"后台接口\")\n                .version(\"1.0.0\")\n                .build();\n    }\n}\n\n```\n\n如果项目使用Spring是XML方式，就在配置文件加上如下几行：\n```\n\t<mvc:default-servlet-handler/>\n\t<mvc:resources mapping=\"/webjars/**\" location=\"classpath:/META-INF/resources/webjars/\" />\n\t<mvc:resources mapping=\"swagger-ui.html\" location=\"classpath:/META-INF/resources/\" />\n```\n\n如果是SpringBoot的就更简单了。。直接拷贝配置类，加上依赖包就可以运行了。\nHmm。。简单来说这样就足够了。。。\n访问地址是默认地址+/swagger-ui.html，我这里是http://localhost:8080/swagger-ui.html\n效果如图所示：\n![](pic/base.png)\n\n## 稍微复杂一些\n\n上面的只是提供了基础功能，Hmm...还是没有注释说明什么的，只是有一些基础的序列化参数（Json字段还是可以自动识别的，而且能提供默认值）\n如果要加入一些注释，就需要对原有项目加入一些侵入代码了(一些swagger特有注解)\n\n首先是Model实体上面的\n\n```\nimport io.swagger.annotations.ApiModel;\nimport io.swagger.annotations.ApiModelProperty;\n@ApiModel\npublic class AddKeywordRequestVo extends BaseVo {\n    /**\n     * 关键词名称\n     */\n    @ApiModelProperty(value = \"关键词名称\",example = \"汽车\")\n    private String keywordName;\n    /**\n     *关键词品类,多个用逗号分隔，0全部，1灯泡,2火花塞,3轮胎,4蓄电池,5油品,6雨刮,7全车件。默认为0\n     */\n    @ApiModelProperty(value = \"关键词品类,多个用逗号分隔，0全部，1灯泡,2火花塞,3轮胎,4蓄电池,5油品,6雨刮,7全车件。默认为0\",example = \"1\")\n    private String keywordCategory;\n    /**\n     * 关键词拼音\n     */\n    @ApiModelProperty(value = \"关键词拼音\",example = \"qiche\")\n    private String keywordPinyin;\n    /**\n     * 关键词同义词\n     */\n    @ApiModelProperty(value = \"关键词同义词\",example = \"卡车\")\n    private String keywordSynonym;\n    /**\n     * 词频\n     */\n    @ApiModelProperty(value = \"词频\",example = \"1\")\n    private Integer wordFrequency;\n    /**\n     * 词性，0通用，1专属\n     */\n    @ApiModelProperty(value = \"词性，0通用，1专属\",example = \"1\")\n    private Integer wordType;\n    /**\n     * 备注\n     */\n    @ApiModelProperty(\"备注\")\n    private String remark;\n    public String getKeywordName() {\n        return keywordName;\n    }\n\n    public void setKeywordName(String keywordName) {\n        this.keywordName = keywordName;\n    }\n\n    public String getKeywordCategory() {\n        return keywordCategory;\n    }\n\n    public void setKeywordCategory(String keywordCategory) {\n        this.keywordCategory = keywordCategory;\n    }\n\n    public String getKeywordPinyin() {\n        return keywordPinyin;\n    }\n\n    public void setKeywordPinyin(String keywordPinyin) {\n        this.keywordPinyin = keywordPinyin;\n    }\n\n    public String getKeywordSynonym() {\n        return keywordSynonym;\n    }\n\n    public void setKeywordSynonym(String keywordSynonym) {\n        this.keywordSynonym = keywordSynonym;\n    }\n\n    public Integer getWordFrequency() {\n        return wordFrequency;\n    }\n\n    public void setWordFrequency(Integer wordFrequency) {\n        this.wordFrequency = wordFrequency;\n    }\n\n    public Integer getWordType() {\n        return  wordType;\n    }\n\n    public void setWordType(Integer wordType) {\n        this.wordType = wordType;\n    }\n\n    public String getRemark() {\n        return remark;\n    }\n\n    public void setRemark(String remark) {\n        this.remark = remark;\n    }\n\n    public AddKeywordRequestVo() {}\n\n    public AddKeywordRequestVo(Integer wordFrequency, Integer wordType, String keywordName, String keywordCategory) {\n        this.wordFrequency = wordFrequency;\n        this.wordType = wordType;\n        this.keywordName = keywordName;\n        this.keywordCategory = keywordCategory;\n    }\n}\n```\n其实也不是太多，一个ApiModelProperty，一个ApiModel就够用了，加上上面的注解有什么效果呢？看图吧。。\n\nmodel的：\n![](pic/RequestModel.png)\n参数示例的：\n![](pic/RequestExample.png)\n\n\n其实Response也是可以的，但是需要为泛型或者具体的，Object类型的就。。。。参考我这边的。。。\n如果是泛型的话，参考下图：\nmodel的：\n![](pic/ResponseModel.png)\n参数示例的：\n![](pic/ResponseExample.png)\n\nController上面也可以加一些的：\n\n```\n\n/**\n * 关键词Controller\n */\n@RestController\n@Api(\"关键词Controller\")\npublic class KeywordsController {\n    @Autowired\n    private AddKeyWordService addKeyWordService;\n    @Autowired\n    private DelKeyWordService delKeyWordService;\n    @Autowired\n    private BatchDelKeyWordService batchDelKeyWordService;\n\n    private static Logger logger = LoggerFactory.getLogger(KeyWordController.class);\n\n    /**\n     * 添加关键词\n     * @param vo 添加关键词请求参数\n     * @return  添加关键词结果\n     */\n    @RequestMapping(value = \"/add/keyword\",method = RequestMethod.POST)\n    @ResponseBody\n    @ApiOperation(\"添加关键词\")\n    public Result addKeyword(@RequestBody AddKeywordRequestVo vo){\n        LogModel lm = LogModel.newLogModel(\"addKeyword\");\n        logger.info(lm.addMetaData(vo).toJson());\n        Result res = new Result();\n        if (!addKeyWordService.checkParam(vo,res)){\n            return res;\n        }\n        try{\n            addKeyWordService.addKeyword(vo,res);\n        }catch(Exception e){\n            res.setStatus(ReturnStatusEnum.SERVICE_ERROR.getValue());\n            res.setMessage(ReturnStatusEnum.SERVICE_ERROR.getDesc());\n        }\n        logger.info(lm.getMeta(\"status\", res.getStatus()).getMeta(\"meg\", res.getMessage()).toJson());\n        return res;\n    }\n\n    /**\n     * 删除关键词\n     * @return  删除关键词结果\n     */\n    @RequestMapping(value = \"/del/keyword\",method = RequestMethod.DELETE)\n    @ResponseBody\n    @ApiOperation(\"删除关键词\")\n    public Result delKeyword(@RequestBody DelKeywordRequestVo vo){\n        LogModel lm = LogModel.newLogModel(\"delKeyword\");\n        logger.info(lm.addMetaData(vo).toJson());\n        Result res = new Result();\n        if (!delKeyWordService.checkParam(vo,res)){\n            return res;\n        }\n        try {\n            delKeyWordService.delKeyword(vo,res);\n        } catch (Exception e) {\n            res.setStatus(ReturnStatusEnum.SERVICE_ERROR.getValue());\n            res.setMessage(ReturnStatusEnum.SERVICE_ERROR.getDesc());\n        }\n        logger.info(lm.getMeta(\"status\", res.getStatus()).getMeta(\"meg\", res.getMessage()).toJson());\n        return res;\n    }\n\n    /**\n     * 批量删除关键词接口\n     * @param vo 批量删除关键词请求\n     * @return  批量删除结果\n     */\n    @ApiOperation(\"批量删除关键词接口\")\n    @RequestMapping(value = \"/batchdel/keyword\",method = RequestMethod.DELETE)\n    @ResponseBody\n    public Result delKeywords(@RequestBody DelKeywordsRequestVo vo){\n        LogModel lm = LogModel.newLogModel(\"delKeywords\");\n        logger.info(lm.addMetaData(vo).toJson());\n        Result res = new Result();\n        if (!batchDelKeyWordService.checkParam(vo,res)){\n            return res;\n        }\n        try {\n            batchDelKeyWordService.delKeywords(vo,res);\n        } catch (Exception e) {\n            res.setStatus(ReturnStatusEnum.SERVICE_ERROR.getValue());\n            res.setMessage(ReturnStatusEnum.SERVICE_ERROR.getDesc());\n        }\n        logger.info(lm.getMeta(\"status\", res.getStatus()).getMeta(\"meg\", res.getMessage()).toJson());\n        return res;\n    }\n}\n```\n\n效果如图所示：\n![](pic/Controller.png)\n\n\n## 还有更强大的\n\n你以为这就是全部？ nonono swagger还可以直接访问接口，Hmm。。这应该是最方便的吧\n\n直接输入对应的参数，点击Try it out! 如图所示：\n![](pic/Result.png)\n\n是不是有了这个连Postman都不用了=-=~\n\n## 总结\n\n### 好处\n\n- 文档跟随项目接口实时改变，不用担心文档和接口不同步\n- 一大批懒开发(比如我)还是写一些注释的，加入注释同时加个注解，也不算太麻烦。\n- 对接流畅多了，前端调用也方便多了。\n- 自己测试也方便\n\n### 坏处\n\n- 有一定代码侵入（加入注解，依赖，配置文件等）\n- 放到线上一定一定要屏蔽掉/swagger相关路径（通过Nginx屏蔽掉）\n- 变动更频繁了。。\n- 人更懒了。。","tags":["Java","Swagger","Spring"],"categories":["Java"]},{"title":"Redis学习汇总","url":"/2018/10/05/Redis 学习汇总/","content":"\n\n# Redis 学习汇总\n\n- 近期看书看博客看视频，相对较为系统的学习了一下Redis，不过版本还是比较老，主要还是3.X系列的。虽然目前最新的已经是4.X，不过老版本的基本都还兼容。\n\n# Redis 编译安装\n\n- Redis安装有很多种方式，Centos可以快捷的使用yum安装，Ubuntu也可以找到apt源进行安装，我这为了尝鲜，用的的是编译安装，其实蛮简单的，我这里直接在mac下进行编译安装，步骤如下：\n- 首先下载redis源码包 ：wget http://download.redis.io/releases/redis-4.0.11.tar.gz\n- 解压 tar -zxvf redis-4.0.11.tar.gz\n- 进入redis-4.0.11目录 cd redis-4.0.11\n- 执行make命令编译(好像需要command tools，之前安装过，没太注意)\n- 然后执行make install  进行安装\n- 然后就可以运行了（mac下直接发送到bin目录下面了，不需要额外配置= =！），执行redis-server 就可以看到熟悉的姐妹了\n\n# Redis 简易配置\n\n- 开始还是单机运行吧，创建一个conf文件，我这里叫做 redis-6379.conf ，内容如下:\n\n```\nbind 127.0.0.1 #绑定Ip\nport 6379   #暴露端口\ndaemonize yes #后台启动\npidfile /Users/eviltuzki/Public/redis/redis_6379.pid\nlogfile \"/Users/eviltuzki/Public/redis/6379.log\"\ndatabases 16\ndbfilename dump.rdb\ndir /Users/eviltuzki/Public/redis #工作目录\n```\n\n- 配置都比较简单，就不过多解释了，主要就是一些工作目录之类的内容\n- 配置完成后通过 redis-server redis-6379.conf  启动redis，可以通过redis-cli检查是否启动成功\n\n# Redis 基本数据类型\n\n- 新版本增加了若干新的数据类型，我暂时没有使用需求，没做过多研究，主要还是针对常用的5中数据结构\n\n## Strings\n\n- 这应该是Redis中使用最多最多的数据结构了，使用起来也很简单，直接set key value 进行赋值，get key进行取值\n- 常用的应用场景（好吧，我只是说一下我经常用的场景吧，在使用Token进行登录验证的时候，token存储于Redis中，使用的就是这种结构，设置好过期时间，定期刷新，可以理解为模拟Session吧）\n- 列举一些常用API\n\n|API|解释|使用示例|\n| ------- |--|--|\n|set| 设置指定 key 的值|set key value|\n|mset| 同时设置一个或多个 key-value 对|mset key value [key1 value1 ...]|\n|get| 获取指定 key 的值|get key|\n|mget| 获取所有(一个或多个)给定 key 的值|mget key1 [key2 ...]|\n|strlen| 返回 key 所储存的字符串值的长度|strlen key|\n|incr| 将 key 中储存的数字值增一。|incr key|\n|incrby| 将 key 所储存的值加上给定的增量值（increment）|incrby key increment|\n|decr| 将 key 中储存的数字值减一|decr key|\n|decrby| key 所储存的值减去给定的减量值（decrement）|decrby key increment|\n|append| 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾|append key value|\n|getset| 将给定 key 的值设为 value ，并返回 key 的旧值(old value)|getset key value|\n|expire| 设置指定key的过期时间（time）|expire key time|\n- 这里当然不太全面，具体参考官方文档：https://redis.io/commands\n\n## Hash\n\n- Hash结构可以认为是一个微型Redis（如果把Redis简单认为是Strings类型），换成Java语言来说，Hash结构就是 Map<String,Map<String,String>> \n- 应用场景。。。。Hmm。。项目中没有用到，不过觉得如果加入用户角色权限等信息。。。。是不是session可以用这个来处理呢？或者是application。。。。Hmm。。。暂时没有想法\n- 还是列举一些常用API\n\n|API|解释|使用示例|\n| ------- |--|--|\n|hget| 获取存储在哈希表中指定字段的值。| HGET key field |\n|hset| 将哈希表 key 中的字段 field 的值设为 value 。|\tHSET key field value |\n|hmget| 获取所有给定字段的值 \t|HMGET key field1 [field2] |\n|hmset| 同时将多个 field-value (域-值)对设置到哈希表 key 中。| HMSET key field1 value1 [field2 value2 ] |\n|hgetall| 获取在哈希表中指定 key 的所有字段和值 |HGETALL key |\n|hscan| 迭代哈希表中的键值对。| HSCAN key cursor [MATCH pattern] [COUNT count] ``|\n|hexist| 查看哈希表 key 中，指定的字段是否存在。 |HEXISTS key field |\n|hdel| 删除一个或多个哈希表字段| HDEL key field1 [field2] |\n|hincrby| 为哈希表 key 中的指定字段的整数值加上增量 increment 。 |HINCRBY key field increment |\n|hkeys| 获取所有哈希表中的字段 |HKEYS key |\n|hlen| 获取哈希表中字段的数量 |HLEN key |\n|hvals| 获取哈希表中所有值 |HVALS key |\n- 具体参考官方文档：https://redis.io/commands\n\n## List\n\n- 列表虽然最近项目中没有使用，不过之前的项目中大规模使用，场景是。。。把list当做消息队列了。。\n- 应用场景。。。除了消息队列。。Hmm。。我也想不到什么了。。。如果有其他场景，烦请告诉我，谢谢。。\n- 老规矩，列举一些常用API\n\n|API|解释|使用示例|\n| ------- |--|--|\n|blpop| 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。| BLPOP key1 [key2] timeout |\n|brpop| 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。|BRPOP key1 [key2] timeout |\n|brpoplpush| 从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。| BRPOPLPUSH source destination timeout |\n|lindex| 通过索引获取列表中的元素 |LINDEX key index |\n|linsert| 在列表的元素前或者后插入元素 |LINSERT key BEFORE\\AFTER pivot value |\n|llen| 获取列表长度 |LLEN key |\n|lpop| 移出并获取列表的第一个元素| LPOP key |\n|lpush| 将一个或多个值插入到列表头部 |LPUSH key value1 [value2] |\n|lpushx| 将一个值插入到已存在的列表头部 |LPUSHX key value |\n|lrange| 获取列表指定范围内的元素 |LRANGE key start stop |\n|lrem| 移除列表元素 | LREM key count value |\n|lset| 通过索引设置列表元素的值  |LSET key index value |\n|ltrim| 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。  |LTRIM key start stop |\n|rpop| 移除并获取列表最后一个元素 |RPOP key |\n|rpoplpush| 移除列表的最后一个元素，并将该元素添加到另一个列表并返回   |RPOPLPUSH source destination |\n|rpush| 在列表中添加一个或多个值  |RPUSH key value1 [value2] |\n|rpushx|  为已存在的列表添加值   |RPUSHX key value|\n- 具体参考官方文档：https://redis.io/commands\n\n## Set\n\n- Set集合，就知道这个是一个集合，无序，不可以重复（Hmm和java中的Set很相似）\n- 应用场景。。。没想到。。。Hmm。。待补充\n- 常用API\n\n|API|解释|使用示例|\n| ------- |--|--|\n|sadd|向集合添加一个或多个成员|SADD key member1 [member2] |\n|scard|获取集合的成员数|SCARD key |\n|sdiff|返回给定所有集合的差集|SDIFF key1 [key2] |\n|sdiffstore|返回给定所有集合的差集并存储在 destination 中|SDIFFSTORE destination key1 [key2] |\n|sinter|返回给定所有集合的交集|SINTER key1 [key2] |\n|sinterstore|返回给定所有集合的交集并存储在 destination 中|SINTERSTORE destination key1 [key2] |\n|sismember|判断 member 元素是否是集合 key 的成员|SISMEMBER key member |\n|smembers|返回集合中的所有成员|SMEMBERS key |\n|smove|将 member 元素从 source 集合移动到 destination 集合|SMOVE source destination member |\n|spop|移除并返回集合中的一个随机元素|SPOP key |\n|srandmember|返回集合中一个或多个随机数|SRANDMEMBER key [count] |\n|srem|移除集合中一个或多个成员|SREM key member1 [member2] |\n|sunion|返回所有给定集合的并集|SUNION key1 [key2] |\n|sunionstore|所有给定集合的并集存储在 destination 集合中|SUNIONSTORE destination key1 [key2] |\n|sscan|迭代集合中的元素|SSCAN key cursor [MATCH pattern] [COUNT count] |\n- 具体参考官方文档：https://redis.io/commands\n\n## Zset\n\n- Hmm Zset 也叫做Sorted Set 就是一个排序的集合，简单的说就是Set的有序版本（不过这个和Java的SortedSet不太一样。。），区别是什么呢，区别就是每个元素都有一个Score，排序的依据呢就是这个Score了。。\n- 应用场景，项目中倒是用到了，不过感觉用到并不是太对。。。所以不说了。老项目使用这个实现了一个排行榜，Hmm还是可以的，定期刷入到MySQL中持久化，也不怕数据丢失什么的。。。挺好\n- 说一下常用API吧\n\n|API|解释|使用示例|\n| ------- |--|--|\n|zadd|向有序集合添加一个或多个成员，或者更新已存在成员的分数|ZADD key score1 member1 [score2 member2] |\n|zcard|获取有序集合的成员数|ZCARD key |\n|zcount|计算在有序集合中指定区间分数的成员数|ZCOUNT key min max |\n|zincrby|有序集合中对指定成员的分数加上增量 increment|ZINCRBY key increment member |\n|zinterstore|计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中|ZINTERSTORE destination numkeys key [key ...] |\n|zlexcount|在有序集合中计算指定字典区间内成员数量|ZLEXCOUNT key min max |\n|zrange|通过索引区间返回有序集合成指定区间内的成员|ZRANGE key start stop [WITHSCORES] |\n|zrangebylex|通过字典区间返回有序集合的成员|ZRANGEBYLEX key min max [LIMIT offset count] |\n|zrangebyscore|通过分数返回有序集合指定区间内的成员|ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] |\n|zrank|返回有序集合中指定成员的索引|ZRANK key member |\n|zrem|移除有序集合中的一个或多个成员|ZREM key member [member ...] |\n|zremrangebylex|移除有序集合中给定的字典区间的所有成员|ZREMRANGEBYLEX key min max |\n|zremrangebyrank|移除有序集合中给定的排名区间的所有成员|ZREMRANGEBYRANK key start stop |\n|zremrangebyscore|移除有序集合中给定的分数区间的所有成员|ZREMRANGEBYSCORE key min max |\n|zrevrange|返回有序集中指定区间内的成员，通过索引，分数从高到底|ZREVRANGE key start stop [WITHSCORES] |\n|zrevrangebyscore|返回有序集中指定分数区间内的成员，分数从高到低排序|ZREVRANGEBYSCORE key max min [WITHSCORES] |\n|zrevrank|返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序|ZREVRANK key member |\n|zscore|返回有序集中，成员的分数值|ZSCORE key member |\n|zunionstore|计算给定的一个或多个有序集的并集，并存储在新的 key 中|ZUNIONSTORE destination numkeys key [key ...] |\n|zscan|迭代有序集合中的元素（包括元素成员和元素分值）|ZSCAN key cursor [MATCH pattern] [COUNT count] |\n- 具体参考官方文档：https://redis.io/commands\n\n# Redis 读写分离结构\n\n- 读写分离其实不是太复杂，简单来说就是多个Redis组成小\"集群\"，注意我这里的集群是带有引号的哈，\b这并不是一个真正意义上的集群，而是主从结构(Master&Slave)，可以是一主多从，也可以是一主一从，甚至可以使只有一个Master(这个就退化成了。。。单机模式了。。)\n- 说一下怎么配置吧\n    - 先参考 Redis 简易配置，并启动6379节点\n    - 拷贝一份配置文件，将所有的6379替换为6380 （Hmm，我比较懒。。就单机先这么搞了。。）\n    - 启动6380这个实例 redis-server redis-6380.conf\n    - 查看是否都启动成功了，执行 \bps -ef |grep redis-server|grep -v 'grep'  我这里显示如下，表示两个实例已经启动成功\n```\n501 42485     1   0 12:29下午 ??         0:07.18 redis-server 127.0.0.1:6379\n501 43688     1   0 10:20下午 ??         0:00.33 redis-server 127.0.0.1:6380\n```\n\n    - 执行 redis-cli -p 6380 info replication 看到6380实例目前是以Master角色运行\n```\n# Replication\nrole:master\nconnected_slaves:0\nmaster_replid:13f6fcea2807ec7a78d52ecf76c382c0ba7d9c55\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:0\nsecond_repl_offset:-1\nrepl_backlog_active:0\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:0\nrepl_backlog_histlen:0\n```\n\n    - 给6380分配角色slave，跟从Master 执行 redis-cli -p 6380  slaveof 127.0.0.1 6379\n    - 执行 redis-cli -p 6380 info replication 看到6380实例目前是以Slave角色运行\n```\n# Replication\nrole:slave\nmaster_host:127.0.0.1\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:8\nmaster_sync_in_progress:0\nslave_repl_offset:154\nslave_priority:100\nslave_read_only:1\nconnected_slaves:0\nmaster_replid:7a2c11e996810f76bdc72765130dcf47b5af4ab8\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:154\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:71\nrepl_backlog_histlen:84\n```\n\n    - \b这种是通过Redis Client\b来分配角色，还可以在配置文件中进行配置，修改redis-6380.conf如下，并重启：\n```\nbind 127.0.0.1\nport 6380\ndaemonize yes\npidfile /Users/eviltuzki/Public/redis/redis_6380.pid\nlogfile \"/Users/eviltuzki/Public/redis/6380.log\"\ndatabases 16\ndbfilename dump.rdb\ndir /Users/eviltuzki/Public/redis\nslaveof 127.0.0.1 6379\n```\n    \n   - 实际生产环境通常使用配置文件的方式配置主从结构\n   - 完成了配置简单尝试一下：\n       - 在Master set value -> redis-cli -p 6379 set hello world  -> OK\n       - 在Slave get value -> redis-cli -p 6380 get hello -> \"world\"\n       - 在Slave set value -> redis-cli -p 6380 set test test -> (error) READONLY You can't write against a read only slave.\n   - \b基本测试完成，主节点可读可写，从节点同步主节点，只能读取，不能写入，Hmm。。。如果要多加入几个Slave节点。。Copy一下配置文件就好了。。。 \n\n# Redis HA 之 sentinel\n\n## 说一下背景\n- Hmm 上文说道了集群，\b其实主从结构并不是一个可靠的集群，\b比如某天一大波僵尸来袭。。。跑题了，一大波流量来袭。。。Master挂了。。。然后。。。Hmm。。。没有节点可以写入了，咋办呢？\n- 解决方法也不是太复杂，举个场景：3台机器，1Master 2Slave，然后某天。。。Master突然挂了。。剩下2个Slave，这个时候咋办？切换一下，让其中一个Slave变成Master，另外一个跟随这个\b新的Master，这样就\u001b1主1从1挂机（鄙视挂机党。。。）。好赖可以正常提供服务了，等挂机服务器启动起来了，将它设置为新Master的Slave节点，这样就完成了Master Slave的转换了，然后就可以正常提供服务了。\n- 听起来上面的方案还不错，其实服务端执行起来也不太复杂。\b如下：\n    - Master挂了，剩下2个Slave，记为Slave1 Slave2\n    - 对Slave 1 执行 slaveof no one，将Slave 1 升级为新Master\n    - 对Slave 2 执行 slaveof Slave1，将Slave 2设置跟从新的Master\n    - 等原Master启动，执行slaveof Slave1，将原Master设置为Slave并且跟从\b新的Master\n- 为啥说服务端简单呢？Client连接服务器也得跟着切换啊。。\bClient写入只能写入到Master节点，服务端经过这么一折腾，Client也要跟着切换IP\b，才能正常访问。\n- 所以呢，官方提供了sentinel 一种HA方案，服务端的切换可以自动执行，sentinel 节点负责监控Master Slave状态，如果切换了，\b同时通知Client进行切换，达到\b可服务状态。\n\n## 怎么配置？\n\n- 首先要额外准备机器作为sentinel节点，我这里偷懒，继续单机运行。。。（Hmm，穷人。。没有太多机器。。也不想搞虚拟机）\n- 先启动一个Maste 6379，2个Slave 6380 8381，执行ps -ef |grep redis|grep -v grep 如下：\n```\n  501 42485     1   0 12:29下午 ??         0:10.87 redis-server 127.0.0.1:6379\n  501 43910     1   0 10:47下午 ??         0:02.45 redis-server 127.0.0.1:6380\n  501 44117     1   0 11:17下午 ??         0:00.53 redis-server 127.0.0.1:6381\n```\n\n- 查看Master状态 redis-cli -p 6379 info replication\n```\n# Replication\nrole:master\nconnected_slaves:2\nslave0:ip=127.0.0.1,port=6380,state=online,offset=3796,lag=0\nslave1:ip=127.0.0.1,port=6381,state=online,offset=3796,lag=0\nmaster_replid:7a2c11e996810f76bdc72765130dcf47b5af4ab8\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:3796\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:3796\n```\n- 全部启动成功，然后开始配置sentinel节点\n- 从Redis解压文件中可以看到一个sentinel.conf文件，Hmm。。。懒人。。直接Copy这个开始改造，sentinel-26379.conf 如下：\n```\nport 26379\ndir /Users/eviltuzki/Public/redis/\nsentinel monitor mymaster 127.0.0.1 6379 2  # 监控mymaster集群，Master地址为127.0.0.1 6379，当2个sentinel认为Master有问题，则进行Master转换\nsentinel down-after-milliseconds mymaster 30000 #\b下线Master时间30s\nsentinel parallel-syncs mymaster 1\nsentinel failover-timeout mymaster 180000\nsentinel deny-scripts-reconfig yes\ndaemonize yes #守护进程方式启动\n```\n\n- \b生成对应的3份，分别是sentinel-26379.conf、sentinel-26380.conf、sentinel-26381.conf，然后通过redis-sentinel sentinel-263xx.conf启动sentinel节点\n- 查看进程，是否启动成功：ps -ef |grep sent|grep -v grep\n```\n  501 44288     1   0 11:36下午 ??         0:00.64 redis-sentinel *:26379 [sentinel]\n  501 44291     1   0 11:36下午 ??         0:00.61 redis-sentinel *:26380 [sentinel]\n  501 44293     1   0 11:36下午 ??         0:00.63 redis-sentinel *:26381 [sentinel]\n```\n\n- 查看redis-sentinel状态：redis-cli -p 26379 info sentinel\n```\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=2,sentinels=3\n```\n\n- 可以看到master0状态OK，2个Slave，3个sentinels，一切正常。接下来就可以使用对应的Client进行连接了。\b\n- Hmm 这块内容有点太多了。。。后面单开Java Client\u001b连接。。\n\n- 接下来模拟一下事故吧：\n    - 查看一下刚刚配置的sentinel-26379.conf文件，多了一些内容：\n```\nport 26379\ndir \"/Users/zhaojian/Public/redis\"\nsentinel myid bca8111060bbda4a42ec3744391d1f40ca1fda00\nsentinel deny-scripts-reconfig yes\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel config-epoch mymaster 0\nsentinel leader-epoch mymaster 0\n# Generated by CONFIG REWRITE\nsentinel known-slave mymaster 127.0.0.1 6381\nsentinel known-slave mymaster 127.0.0.1 6380\nsentinel known-sentinel mymaster 127.0.0.1 26380 ba913a9c10e46fd4df76bf0289721136031926ef\ndaemonize yes\nsentinel known-sentinel mymaster 127.0.0.1 26381 7c387d9b2e95ac2338655fb8f5011f277635dade\nsentinel current-epoch 0\n```\n\n    - 主节点和从节点信息都能看到，现在我准备下线Master节点，看看会有什么反应（Hmm怎么下线呢？直接kill掉吧）\n    - 等待一小会儿，Hmm，大概30S左右吧，再次查看sentinel-26379.conf文件，发现有些变化了\n```\nport 26379\ndir \"/Users/zhaojian/Public/redis\"\nsentinel myid bca8111060bbda4a42ec3744391d1f40ca1fda00\nsentinel deny-scripts-reconfig yes\nsentinel monitor mymaster 127.0.0.1 6380 2\nsentinel config-epoch mymaster 1\nsentinel leader-epoch mymaster 1\n# Generated by CONFIG REWRITE\nsentinel known-slave mymaster 127.0.0.1 6379\nsentinel known-slave mymaster 127.0.0.1 6381\nsentinel known-sentinel mymaster 127.0.0.1 26380 ba913a9c10e46fd4df76bf0289721136031926ef\ndaemonize yes\nsentinel known-sentinel mymaster 127.0.0.1 26381 7c387d9b2e95ac2338655fb8f5011f277635dade\nsentinel current-epoch 1\n```\n    - Hmm，首先Master已经切换了，不再是6379了，而是6380，而6379变成了known-slave，也就是Slave节点，无妨。。。反正现在也不工作。。。\n    - 那我现在恢复一下6379\b节点(重新执行redis-server redis-6379.conf)，注意，这里的配置6379可是Master哦~\n    - 执行 redis-cli -p 6379 info replication ,信息如下：\n```\n# Replication\nrole:slave\nmaster_host:127.0.0.1\nmaster_port:6380\nmaster_link_status:up\nmaster_last_io_seconds_ago:0\nmaster_sync_in_progress:0\nslave_repl_offset:162525\nslave_priority:100\nslave_read_only:1\nconnected_slaves:0\nmaster_replid:a6939796e0faba3555a74719ec18498e7b247756\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:162525\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:155146\nrepl_backlog_histlen:7380\n```\n    - Hmm，说明sentinel还是蛮智能的，尽管6379之前是Master，但是选举出新的Master之后，旧的Master会被 降级到Slave节点，避免\b出现多个Master。\n    - 附带看一下6381和6380\b的日志：\n    - 首先是6380的：\n```\n43910:S 06 Oct 23:45:51.903 * MASTER <-> SLAVE sync started\n43910:S 06 Oct 23:45:51.904 # Error condition on socket for SYNC: Connection refused\n43910:S 06 Oct 23:45:52.914 * Connecting to MASTER 127.0.0.1:6379\n\n...\n43910:S 06 Oct 23:46:21.205 * MASTER <-> SLAVE sync started\n43910:S 06 Oct 23:46:21.206 # Error condition on socket for SYNC: Connection refused\n43910:M 06 Oct 23:46:21.960 # Setting secondary replication ID to 7a2c11e996810f76bdc72765130dcf47b5af4ab8, valid up to offset: 111989. New replication ID is a6939796e0faba3555a74719ec18498e7b247756\n43910:M 06 Oct 23:46:21.960 * Discarding previously cached master state.\n43910:M 06 Oct 23:46:21.962 * MASTER MODE enabled (user request from 'id=13 addr=127.0.0.1:51348 fd=12 name=sentinel-7c387d9b-cmd age=568 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')\n43910:M 06 Oct 23:46:21.963 # CONFIG REWRITE executed with success.\n43910:M 06 Oct 23:46:23.354 * Slave 127.0.0.1:6381 asks for synchronization\n43910:M 06 Oct 23:46:23.354 * Partial resynchronization request from 127.0.0.1:6381 accepted. Sending 422 bytes of backlog starting from offset 111989.\n43910:M 06 Oct 23:49:59.772 * Slave 127.0.0.1:6379 asks for synchronization\n43910:M 06 Oct 23:49:59.772 * Partial resynchronization not accepted: Replication ID mismatch (Slave asked for '4a931cc983685e6f1b029225185120eee25f03b4', my replication IDs are 'a6939796e0faba3555a74719ec18498e7b247756' and '7a2c11e996810f76bdc72765130dcf47b5af4ab8')\n43910:M 06 Oct 23:49:59.773 * Starting BGSAVE for SYNC with target: disk\n43910:M 06 Oct 23:49:59.773 * Background saving started by pid 44404\n44404:C 06 Oct 23:49:59.775 * DB saved on disk\n43910:M 06 Oct 23:49:59.855 * Background saving terminated with success\n43910:M 06 Oct 23:49:59.856 * Synchronization with slave 127.0.0.1:6379 succeeded\n```\n\n    - 然后看一下6381的：\n```\n...\n44117:S 06 Oct 23:46:22.338 * Connecting to MASTER 127.0.0.1:6379\n44117:S 06 Oct 23:46:22.339 * MASTER <-> SLAVE sync started\n44117:S 06 Oct 23:46:22.340 # Error condition on socket for SYNC: Connection refused\n44117:S 06 Oct 23:46:22.866 * SLAVE OF 127.0.0.1:6380 enabled (user request from 'id=11 addr=127.0.0.1:51346 fd=12 name=sentinel-7c387d9b-cmd age=569 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=133 qbuf-free=32635 obl=36 oll=0 omem=0 events=r cmd=exec')\n44117:S 06 Oct 23:46:22.867 # CONFIG REWRITE executed with success.\n44117:S 06 Oct 23:46:23.351 * Connecting to MASTER 127.0.0.1:6380\n44117:S 06 Oct 23:46:23.351 * MASTER <-> SLAVE sync started\n44117:S 06 Oct 23:46:23.352 * Non blocking connect for SYNC fired the event.\n44117:S 06 Oct 23:46:23.353 * Master replied to PING, replication can continue...\n44117:S 06 Oct 23:46:23.353 * Trying a partial resynchronization (request 7a2c11e996810f76bdc72765130dcf47b5af4ab8:111989).\n44117:S 06 Oct 23:46:23.354 * Successful partial resynchronization with master.\n44117:S 06 Oct 23:46:23.355 # Master replication ID changed to a6939796e0faba3555a74719ec18498e7b247756\n44117:S 06 Oct 23:46:23.355 * MASTER <-> SLAVE sync: Master accepted a Partial Resynchronization.\n```\n\n    - 额，刚想起来6379重启后的日志也看一下：\n```\n42485:M 06 Oct 23:45:51.599 # User requested shutdown...\n42485:M 06 Oct 23:45:51.600 * Saving the final RDB snapshot before exiting.\n42485:M 06 Oct 23:45:51.601 * DB saved on disk\n42485:M 06 Oct 23:45:51.601 * Removing the pid file.\n42485:M 06 Oct 23:45:51.602 # Redis is now ready to exit, bye bye...\n44398:C 06 Oct 23:49:48.652 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n44398:C 06 Oct 23:49:48.653 # Redis version=4.0.11, bits=64, commit=00000000, modified=0, pid=44398, just started\n44398:C 06 Oct 23:49:48.654 # Configuration loaded\n44399:M 06 Oct 23:49:48.656 * Increased maximum number of open files to 10032 (it was originally set to 4864).\n44399:M 06 Oct 23:49:48.657 * Running mode=standalone, port=6379.\n44399:M 06 Oct 23:49:48.657 # Server initialized\n44399:M 06 Oct 23:49:48.657 * DB loaded from disk: 0.000 seconds\n44399:M 06 Oct 23:49:48.658 * Ready to accept connections\n44399:S 06 Oct 23:49:58.958 * Before turning into a slave, using my master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.\n44399:S 06 Oct 23:49:58.958 * SLAVE OF 127.0.0.1:6380 enabled (user request from 'id=3 addr=127.0.0.1:52967 fd=7 name=sentinel-ba913a9c-cmd age=10 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')\n44399:S 06 Oct 23:49:58.960 # CONFIG REWRITE executed with success.\n44399:S 06 Oct 23:49:59.769 * Connecting to MASTER 127.0.0.1:6380\n44399:S 06 Oct 23:49:59.769 * MASTER <-> SLAVE sync started\n44399:S 06 Oct 23:49:59.770 * Non blocking connect for SYNC fired the event.\n44399:S 06 Oct 23:49:59.771 * Master replied to PING, replication can continue...\n44399:S 06 Oct 23:49:59.771 * Trying a partial resynchronization (request 4a931cc983685e6f1b029225185120eee25f03b4:1).\n44399:S 06 Oct 23:49:59.774 * Full resync from master: a6939796e0faba3555a74719ec18498e7b247756:155145\n44399:S 06 Oct 23:49:59.774 * Discarding previously cached master state.\n44399:S 06 Oct 23:49:59.856 * MASTER <-> SLAVE sync: receiving 202 bytes from master\n44399:S 06 Oct 23:49:59.857 * MASTER <-> SLAVE sync: Flushing old data\n44399:S 06 Oct 23:49:59.857 * MASTER <-> SLAVE sync: Loading DB in memory\n44399:S 06 Oct 23:49:59.858 * MASTER <-> SLAVE sync: Finished with success\n```\n\n    - 从日志中可以看到，6379下线以后，6380和6381经历了一段时间（约30s）的找不到Master，之后6380收到了sentinel-7c387d9b-cmd发送的请求，转换角色为Master。6381收到sentinel-7c387d9b-cmd发送的请求，变更为跟随6380而不是6379。等6379重新启动后收到了sentinel-ba913a9c-cmd的请求，降级为Slave并且跟随6380。\n\n- 补充说明一下sentinel一定要集群部署，不能单点！否则网络等因素会导致集群来回切换角色，另外sentinel本身单点也有风险！\n\n# Redis HA 之 Clusterv","tags":["Redis"],"categories":["Redis"]},{"title":"ElasticSearch 查询优化 之 inner_hits","url":"/2018/09/24/ElasticSearch 查询优化 之 inner_hits/","content":"\n**背景及问题**\n\n- 说一下背景\n    - Doc数量约20W+\n    - 机器配置 4C 8G * 3 \n    - ElasticSearch 5.6.3\n    - 每个Doc中的Nested字段(价格列表，不同城市价格不同)中包含约100-200个嵌套文档\n\n- 查询需求：\n    - 每个查询均需要从嵌套文档中进行查询（根据城市Id）\n    - 最终只需要返回一个嵌套文档(城市Id符合需求的)\n\n- 开始没有想太复杂，直接使用nested Query + inner_hits取出来文档，觉得很方便，但是后来进行测试，发现只要条件中加入了城市Id，查询就很慢(平均120+ms)，而不带城市id基本在40ms+，于是开始了查询问题定位。\n\n**问题定位**\n\n- 根据条件定位问题肯定是出在了城市Id查询，观察了一下mapping，估计问题是出在了nested上，对Query DSL语句进行注意尝试，发现如果不带inner_hits，只是进行城市Id查询，速度可以稳定在45ms左右，一旦加上innder_hits速度就在120ms左右，看来问题是在这里了。\n- 查了官方文档，说inner_hits是父子文档的优化版本，附带了一句nested对检索性能有较大影响，也没有其他相关资料了。\n- 论坛，Google 一下也没有这方面资料，有点没有头绪。\n\n\n**问题解决**\n\n- 本地使用Query DSL 尝试了一下将整个整个价格列表返回，不再使用\binner_hits,发现速度竟然提升了(数据返回话费了4s+，但是EsQuery仅用了50ms)那说明可以**删掉inner_hits，直接返回价格列表，然后在内存中进行筛选**。\n- 按照这个思路改了一下项目代码，发现速度确实有提升，之前平均响应时间在130+ ms（Query+处理），现在基本不过70ms。\n\n\n**继续优化**\n\n- 官方的那句**nested对检索性能有较大影响**还是得重视起来，后来进行了一个尝试，将价格列表和Doc组合起来，不再使用嵌套文档，直接进行\b平铺，这样就相当于取消了nested查询，发现速度再一次提高了，查询的平均检索时间降低到40ms+，针对城市Id又加上了_routing，速度最终稳定在20ms+。好了，在测试环境的优化最终就这样了，等节后花时间测试一下，放到线上估计速度能提高不少~\n\n**总结**\n\n- 其实还是最初的索引结构设计不是很合理，尤其是城市价格这块，最开始没有加入_routing，这算是一个败笔了，每次查询都需要查询城市id，还没加上，这个确实是失误了。。。\n- nested+inner_hits对检索性能确实有很大影响（最起码我这种场景影响很大了）\n- 官方提示了，nested一定程度影响\b性能，如果可以的话，还是要注意一下，避免这种结构，现在将nested字段\u001c平铺开后虽然\bdoc数量激增，但是检索速度大幅度提升，这样代价也值了~\n","tags":["ElasticSearch"],"categories":["ElasticSearch"]},{"title":"MySQL大翻页查询优化","url":"/2018/09/16/MySQL大翻页查询优化/","content":"\n\n**背景**\n\n- 前两天做项目需要讲数据从MySQL 同步到ES中，由于索引结构经常发生变化，需要时不时就跑一个全量的索引。\n- 数据库MySQL5.7\n- 开始方案没有选好，图省事，用的select * from table limit x,10000进行全量读取(现在已经改成用id扫描方式了。。)，开始速度还可以，越到后面越慢。\n\n**自己测试**\n\n- 在自己的电脑上面做了一个一个测试，主要是优化一下limit查询，有一定提升，但是这个尽量还是别用的好，全量还是用id扫描最快。\n- 配置如下：\n\t- 16款MacPro，16G内存 4Core i7 2.2G，SSD硬盘\n\t- MySQL 5.7.22\n\t- 表很简单一列主键id，一列guid,guid没有加索引，InnoDB引擎\n\t- 数据量24589792（自己select insert 进去的）\n\t- 没有做任何特殊优化，只是标准安装(- -自己水平有限)\n- 测试结果如下：\n\t- 语句1：```SELECT * FROM token  LIMIT 24589790,1``` \n\t- 结果：\n\t\t- OK, Time: 5.920000s\n\t\t- OK, Time: 5.872000s\n\t\t- OK, Time: 5.821000s\n\t\t- OK, Time: 5.819000s\n\t\t- OK, Time: 5.880000s\n\t- 语句2：```SELECT * FROM token INNER JOIN (SELECT id FROM token LIMIT 24589790,1) t USING (id)``` \n\t- 结果：\n\t\t- OK, Time: 4.897000s\n\t\t- OK, Time: 4.962000s\n\t\t- OK, Time: 4.897000s\n\t\t- OK, Time: 4.889000s\n\t\t- OK, Time: 4.910000s\n\n- 其实还是挺明显的，接近1秒的差别\n\n**原理**\n\n- 从《高性能MySQL》中看到的，摘抄一下\n- LIMIT和OFFSET，尤其是OFFSET 会导致MySQL扫描大量的不需要的行，然后抛弃掉，这个也是查询慢的根本原因。\n- 语句2提升查询效率是因为他可以让MySQL扫描尽可能少的页面，获取到需要访问的记录后再根据关联列去原表找到所需要的列。\n\n\n**高效的最终方案**\n\n- 就是上面提到的通过Id扫描的方式进行查询，速度杠杠的\n- SELECT * FROM token WHERE id>4589790 LIMIT 1\n- 花费时间(hmmm......显示是OK, Time: 0.000000s)","tags":["MySQL","Limit"],"categories":["MySQL"]},{"title":"ElasticSearch使用painless脚本小记","url":"/2018/08/26/ElasticSearch使用painless脚本小记/","content":"\n\nElasticSearch使用painless脚本小记\n-------\n\n\n- 前几天项目中碰到了一个麻烦的问题，统计Doc中一个List中符合筛选条件的项的值的和(简单说就是Doc是商店为主体，统计该商店的某个时间段下单记录)，开始用的是二次查询，但是后来数据量大了以后，第二次查询用的IDs查询传了几千个值，超过了ES的限制，最后只好拿出脚本进行解决。\n- 先说一下Doc的结构,不相干的字段就删掉了\n\n```\n{\n    \"shopid\": 11,\n    \"orderList\": [\n        {\n            \"orderTime\":\"2015-06-06\",\n            \"orderAmount\":2254\n        },\n        {\n            \"orderTime\":\"2016-06-06\",\n            \"orderAmount\":7575.66\n        },\n        {\n            \"orderTime\":\"2017-06-06\",\n            \"orderAmount\":6533.99\n        },\n        {\n            \"orderTime\":\"2018-06-06\",\n            \"orderAmount\":7870.20\n        }\n    ]\n}\n```\n\n- 业务的查询需求是筛选2016-2018年，下单金额累计超过13000的商店(当然还有其他附加条件的查询)，orderList还是Nested字段，最开始是进行二次查询，也就是首先将其他条件查询出来，然后对结果进行过滤，在这个日期下的符合条件的取出来ID，进行二次查询(这个条件改成Ids查询)，最开始还能正常工作，后来不加上这个条件一下查出来一千条数据的时候就麻烦了，es默认Bool查询条件不能超过1024，硬着头皮改了ES配置，调成了1W，总算是正常工作了，但是不是长久之计，随着订单越来越多，迟早还会有问题，而且查询的时间越来越长了(查出来7000多条数据的时候已经超过10s了。。)，跟业务部门沟通了，他们暂时可以接受，但是让我们尽快优化。\n- 网上查找了很多资料，也想使用innerHits解决，但是innerHits结果无法参与aggs，实在没有其他办法，只好决定用脚本来解决。在上家公司用的是ES2.X，脚本groovy默认是关闭的，开启还有重启ES修改配置，觉得麻烦，而且据说有安全隐患，对这个一比较抵触，当下用的是ES5.6，看了一下脚本用的是painless，这个从来没有接触过，看了一下语法，好像也不太复杂，和Java差不太多，那就硬着头皮上。\n- painless什么时候开始支持的没太关注，不过看文档说好像已经是容器内运行，相对比较安全了，而且ES5.6默认已经开启了，尝试过程中发现Nested类型取值只能取到一个内部文档的，list其他对象找不到。冗余出来一个非nested字段，发现日期和金额都是分别排序的，这就很尴尬了。。。最后决定吧订单金额和下单时间拼接成字符串，存到一个数组中去，这样取值的时候，金额和日期就是一一对应的。\n- 修改后的Doc结构如下：\n\n```\n{\n    \"shopid\": 11,\n    \"orderListStr\":[\n        \"2015-06-06@2254\",\n        \"2016-06-06@7575.66\",\n        \"2017-06-06@6533.99\",\n        \"2018-06-06@7870.20\"\n    ],\n    \"orderList\": [\n        {\n            \"orderTime\":\"2015-06-06\",\n            \"orderAmount\":2254\n        },\n        {\n            \"orderTime\":\"2016-06-06\",\n            \"orderAmount\":7575.66\n        },\n        {\n            \"orderTime\":\"2017-06-06\",\n            \"orderAmount\":6533.99\n        },\n        {\n            \"orderTime\":\"2018-06-06\",\n            \"orderAmount\":7870.20\n        }\n    ]\n}\n```\n- 然后就是对照着文档写painless脚本了，个人水平有限，写的脚本也很低效，不过好赖问题是解决了，附上脚本：\n\n```\nString fotmat = 'yyyy-MM-dd';\nString field = 'orderListStr';\ndouble saleNum = 0.0;\nfor (int i = 0; i < doc[field].length; ++i) {\n    def docStr=doc[field][i];\n    def date = docStr.substring(0,docStr.indexOf('@'));\n    double value =Double.parseDouble(docStr.substring(docStr.indexOf('@')+1));\n    SimpleDateFormat sdf = new SimpleDateFormat(fotmat);\n    if (params.from != null && params.from != '' && params.to != null && params.to != '' ){\n        if (sdf.parse(params.from).getTime()<=sdf.parse(date).getTime() && sdf.parse(params.to).getTime()>=sdf.parse(date).getTime())\n            saleNum+=value;\n    }\n    else if (params.from != null && params.from != ''){\n        if( sdf.parse(params.from).getTime()<=sdf.parse(date).getTime())\n            saleNum+=value;\n    }\n    else if (params.to != null && params.to != ''){\n        if( sdf.parse(params.to).getTime()>=sdf.parse(date).getTime())\n            saleNum+=value;\n    }else {\n        saleNum+=value;\n    }\n}\nif (params.inputFrom != null && params.inputTo != null){\n    return params.inputFrom<=saleNum && saleNum<=params.inputTo;\n} else if(params.inputFrom !=null){\n    return params.inputFrom<=saleNum;\n} else if(params.inputTo != null){\n    return saleNum<=params.inputTo;\n}else{\n    return true;\n}\n```\n\n\n- 使用脚本解决了时间段下单次数统计和时间段金额统计的查询，时间也从原来的接近10s下降到1s左右(感觉脚本没办法走索引，应该都是全表扫描)，这个肯定不是最优方法，但是 现在也想不出来什么其他高效的方法，就先上这个了，最起码目前查询最近5年的订单也是1秒左右，而且不用担心出现bool数量超过限制的问题了。","tags":["ElasticSearch","Painless"],"categories":["ElasticSearch"]},{"title":"Linux curl命令报错 bad range specification","url":"/2018/08/25/Linux curl命令报错 bad range specification/","content":"\n-------------------------\n\n- 加个-g或--globoff选项就ok了\n\n```\ncurl -g  'http://10.200.200.11/interface/task?q=1&value=[]'  \n```\n","tags":["Linux","curl"],"categories":["Linux"]},{"title":"ElasticSearch 查询出现maxClauseCount is set to 1024","url":"/2018/08/24/ElasticSearch 查询出现maxClauseCount is set to 1024/","content":"\n- 如果bool查询的查询条件过多会导致TooManyClauses问题：\n```\n\"caused_by\":{\"type\":\"too_many_clauses\",\"reason\":\"maxClauseCount is set to 1024\"}}}],\n\"caused_by\":{\"type\":\"query_shard_exception\",\"reason\":\"failed to create query:\n```\n\n- 解决方式在配置文件 Elasticsearch.yml中配置:\n    - index.query.bool.max_clause_count: 10240 \n- 设置最大限制bool查询的条数,过多会导致性能比较慢。\n\n- 在ElasticSearch 5之后参数有所改动，提示如下:\n- The setting index.query.bool.max_clause_count has been removed. In order to set the maximum number of boolean clauses indices.query.bool.max_clause_count should be used instead.","tags":["Linux","ElasticSearch"],"categories":["ElasticSearch"]},{"title":"SQL优化","url":"/2018/06/26/sql优化/","content":"\n\n\n# SQL 优化\n\n### 负向查询不能使用索引\n\n```sql\nselect name from user where id not in (1,3,4);\n```\n应该修改为:\n\n```\nselect name from user where id in (2,5,6);\n```\n\n### 前导模糊查询不能使用索引\n如:\n\n```sql\nselect name from user where name like '%zhangsan'\n```\n\n非前导则可以:\n```sql\nselect name from user where name like 'zhangsan%'\n```\n建议可以考虑使用 `Lucene` 等全文索引工具来代替频繁的模糊查询。\n\n### 数据区分不明显的不建议创建索引\n\n如 user 表中的性别字段，可以明显区分的才建议创建索引，如身份证等字段。\n\n### 字段的默认值不要为 null\n这样会带来和预期不一致的查询结果。\n\n### 在字段上进行计算不能命中索引\n\n```sql\nselect name from user where FROM_UNIXTIME(create_time) < CURDATE();\n```\n\n应该修改为:\n\n```sql\nselect name from user where create_time < FROM_UNIXTIME(CURDATE());\n```\n\n### 最左前缀问题\n\n如果给 user 表中的 username pwd 字段创建了复合索引那么使用以下SQL 都是可以命中索引:\n\n```sql\nselect username from user where username='zhangsan' and pwd ='axsedf1sd'\n\nselect username from user where pwd ='axsedf1sd' and username='zhangsan'\n\nselect username from user where username='zhangsan'\n```\n\n但是使用\n\n```sql\nselect username from user where pwd ='axsedf1sd'\n```\n是不能命中索引的。\n\n### 如果明确知道只有一条记录返回\n\n```sql\nselect name from user where username='zhangsan' limit 1\n```\n可以提高效率，可以让数据库停止游标移动。\n\n### 不要让数据库帮我们做强制类型转换\n\n```sql\nselect name from user where telno=18722222222\n```\n这样虽然可以查出数据，但是会导致全表扫描。\n\n需要修改为\n```\nselect name from user where telno='18722222222'\n```\n\n### 如果需要进行 join 的字段两表的字段类型要相同\n\n不然也不会命中索引。","tags":["MySQL"],"categories":["MySQL"]},{"title":"SpringBoot 拦截 response 记录日志","url":"/2018/06/15/SpringBoot 拦截 response 记录日志/","content":"\n直接使用AOP的拦截器，调用AfterReturning即可。\n废话不多说直接上代码\n\n```\npackage com.gs.techpub.filter;\n \nimport com.gridsum.techpub.utils.JsonUtil;\nimport org.aspectj.lang.annotation.AfterReturning;\nimport org.aspectj.lang.annotation.Aspect;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.stereotype.Component;\n@Component\n@Aspect\npublic class ResponseFilter  {\n \n    private Logger logger = LoggerFactory.getLogger(this.getClass());\n    @AfterReturning(returning = \"ret\", pointcut = \"execution( * com.gs.techpub.controller.*.*(..))\")\n    public void doAfterReturning(Object ret) {\n        logger.info(\"返回值 : \" + JsonUtil.getInstance().toJson(ret));\n    }\n}\n```\n\n记得加上依赖\n\n```\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-aop</artifactId>\n</dependency>\n```","tags":["Java","SpringBoot","Response"],"categories":["Java"]},{"title":"解决HttpServletRequest InputStream只能读取一次问题","url":"/2018/06/15/解决HttpServletRequest InputStream只能读取一次问题/","content":"\n在Filter中读取inputSeream读取一次之后就无法再次读取，解决办法如下：\n\n```\npublic class LoggerHttpServletRequestWrapper extends HttpServletRequestWrapper {\n    \n   private final byte[] body;\n \n   public LoggerHttpServletRequestWrapper(HttpServletRequest request) throws IOException {\n      super(request);\n      body = StreamUtils.readBytes(request.getInputStream());\n   }\n    \n   @Override\n   public BufferedReader getReader() {\n      return new BufferedReader(new InputStreamReader(getInputStream()));\n   }\n    \n   @Override\n   public ServletInputStream getInputStream() {\n      final ByteArrayInputStream bais = new ByteArrayInputStream(body);\n      return new ServletInputStream() {\n \n         @Override\n         public boolean isFinished() {\n            return false;\n         }\n \n         @Override\n         public boolean isReady() {\n            return false;\n         }\n \n         @Override\n         public void setReadListener(ReadListener readListener) {\n \n         }\n \n         @Override\n         public int read() {\n            return bais.read();\n         }\n      };\n   }\n \n}\n```\n\n调用如下\n\n```\n@Override\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n    ServletRequest requestWrapper = null;\n    if(request instanceof HttpServletRequest) {\n        requestWrapper = new LoggerHttpServletRequestWrapper((HttpServletRequest) request);\n        if (((HttpServletRequest) request).getMethod().equals(\"POST\")){\n            String path = ((HttpServletRequest) request).getServletPath();\n            String param = StreamUtils.streamToString(requestWrapper.getInputStream());\n            LoggerFactory.getLogger(\"filter.\"+path).info(param);\n        }else if (((HttpServletRequest) request).getMethod().equals(\"GET\")){\n            String path = ((HttpServletRequest) request).getServletPath();\n            String queryString = ((HttpServletRequest) request).getQueryString();\n            LoggerFactory.getLogger(\"filter.\"+path).info(queryString);\n        }\n\n\n    }\n    if(requestWrapper == null) {\n        chain.doFilter(request, response);\n    } else {\n        chain.doFilter(requestWrapper, response);\n    }\n}\n```\n\n工具类如下\n```\npublic class StreamUtils {\n\n    /**\n     * @param inputStream inputStream\n     * @return 字符串转换之后的\n     */\n    public static String streamToString(InputStream inputStream) {\n        try(BufferedReader br =new BufferedReader(new InputStreamReader(inputStream, \"UTF-8\"))) {\n            StringBuilder builder = new StringBuilder();\n            String output;\n            while((output = br.readLine())!=null){\n                builder.append(output);\n            }\n            return builder.toString();\n        }  catch (IOException e) {\n           throw new RuntimeException(\"Http 服务调用失败\",e);\n        }\n    }\n\n    \n\n    public static byte[] readBytes(ServletInputStream inputStream) {\n        return streamToString(inputStream).getBytes(Charset.forName(\"UTF-8\"));\n    }\n}\n```","tags":["Java","Filter","HttpServletRequest"],"categories":["Java"]},{"title":"jenkins构建基于gradle的springboot项目CI采坑(采用jar方式部署)","url":"/2018/02/14/jenkins构建基于gradle的springboot项目CI采坑-采用jar方式部署/","content":"\n试了一堆插件，最后用的还是 publish over SSH\n\njenkins基本配置不多说了，就是配置一下git仓储，配置一下gradle执行命令\n\n```\nclean\nbootRepackage\n```\n之后执行Send build artifacts over SSH\n\n提前配置好对应的服务器\n\nSend build artifacts over SSH\n\n![配置图](jenkins构建基于gradle的springboot项目CI采坑-采用jar方式部署/config.png)\n\n麻烦的是执行restart.sh脚本，总是各种奇葩问题，最终结果如下：\n```\n#/bin/bash\npid=`ps -ef | grep spp.jar | grep -v grep | awk '{print $2}'`\nif [ -n \"$pid\" ]\nthen\n   kill -9 $pid\nfi\njava -jar /data1/javaApp/smartPushPlatform/spp.jar --server.port=30001 > console.log &\n```\n\n这样基本就可以完成启动了，而且可以正常推出\n\n编译日志如下：\n\n```\n[Gradle] - Launching build.\n[SmartPushPlatform] $ /usr/share/gradle/bin/gradle clean bootRepackage\nStarting a Gradle Daemon (subsequent builds will be faster)\n:clean\n:compileJavaNote: /var/lib/jenkins/workspace/SmartPushPlatform/src/main/java/com/gridsum/techpub/legal/smartpush/service/TagService.java uses unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\n \n:processResources\n:classes\n:findMainClass\n:jar\n:bootRepackage\n \nBUILD SUCCESSFUL in 7s\n6 actionable tasks: 6 executed\nBuild step 'Invoke Gradle script' changed build result to SUCCESS\nSSH: Connecting from host [gs-server-3602]\nSSH: Connecting with configuration [10.202.81.26] ...\nSSH: EXEC: STDOUT/STDERR from command [cd /data1/javaApp/smartPushPlatform\nmv SmartPushPlatform-1.1.jar spp.jar\nsh restart.sh] ...\nSSH: EXEC: completed after 200 ms\nSSH: Disconnecting configuration [10.202.81.26] ...\nSSH: Transferred 1 file(s)\nFinished: SUCCESS\n```","tags":["SpringBoot","gradle","Jenkins"],"categories":["Jenkins"]},{"title":"ElasticSearch Index 速度优化 （官方翻译）","url":"/2018/02/10/ElasticSearch Index 速度优化 （官方翻译）/","content":"\n### 使用Bulk请求进行Index\nBulk请求将产生比单文档index请求有更好的性能。至于Bulk请求中文档数量的大小，建议使用单一节点单一分片进行测试，先试试看100个，然后200个，然后400这样，每次进行翻倍测试，只要速度稳定了，也就是最合适的大小了。但是要注意一下，并不是速度最合适了就OK，因为每次请求总的大小要进行一下控制。并发发送的时候，ES内存压力会很大，一定要避免每次请求超过几十兆，即便是这样插入的性能更好（这个我踩过坑，我这测试超过10M，ES就不接受请求，直接拒绝了）。\n### 使用多个节点或者多线程进行Index\n一般来说一个线程，即便是使用了Bulk方式进行Index，也无法达到ES集群的瓶颈，所以为了最大限度的利用集群资源，使用多线程或者多进程的方式进行Index是一个很好的选择。这样不仅最大程度利用了集群资源，还帮助减少了fsync的成本。（这个fsync是什么 意思我暂时也没弄明白，后续补充）。\n要注意一下TOO_MANY_REQUESTS (429) 相应（对应Java Client 则是EsRejectedExecutionException）, 这说明ES集群已经跟不上你Index的速度了，使用一些适当的方式限制一下速度吧。（官方文档说暂停Index一会或者使用随机指数函数Backoff）。\n类似Bulk Index 数量，多线程多进程Index也需要进行人工测试，直到找到一个合适线程数或者进程数。\n### 增加refresh interval\n默认的 index.refresh_interval 是1s，在index的时候如果没有实时性检索需求，建议可以设置大一些，比如30S，如果不需要检索，等index完成才进行检索的话，可以设置为-1，也就是禁用，等完成index之后在调整回来。\n### 禁用refresh，降低分片副本数\n如果需要一次index大量数据，最好禁用refresh，也就是将refresh_interval设置为-1，同时index.number_of_replicas 设置为0，也就是不需要副本。尽管这样会增加一些风险（真的很小很小），也就是在索引的时候可能导致数据丢失，但是这样可以大幅度增加索引速度，等完成索引后在增加副本，这样也可以保证数据的可靠性。\n### 禁用Swapping\n一定确保操作系统禁用了swapping，这对ES性能有很大的提升。\n### 给足够的内存文件系统缓存\n你应该分配机器的一半内存给ES使用，用于文件系统的缓存。文件系统缓存用于缓冲I/O操作。\n### 使用系统自动生成id\n当你index一个document使用特定的id，ES需要去检查是否在同一个shard存在相同的ID的文档，这是一个相当昂贵的操作，并且随着文档数量的增加，花费呈指数增长。如果使用自动生成id，ES会跳过这个检查，使得Index速度更快。\n### 使用更快的硬件\n如果I/O是瓶颈，那么最好考虑为文件系统提供更多内存或者购买更好的服务器。使用SSD硬盘能比一般的硬盘有更好的性能。另外尽量使用本地存储，不要考虑远程存储。也尽可能不要考虑Amazon等虚拟化存储，尽管比较简单的使用，但是性能比本地存储差很多。\n还有要尽可能冗余副本，以避免节点故障导致数据丢失。也可以用快照备份还原进一步降低数据出事的风险。\n### Indexing 缓冲大小\n如果节点仅仅是大量Index，确保每个分片 indices.memory.index_buffer_size 大于512M，（尽管大于512M没有什么性能改善）。举个例子，默认值是10%，也是说如果你设置的jvm大小是10G，那么Index缓冲大小是1G，足以支撑2个shard的大量索引。\n### 禁用 _field_names\n简单来说，如果你不需要运行exists查询，那么你就可以禁用_field_names。","tags":["ElasticSearch","Index"],"categories":["ElasticSearch"]},{"title":"gradle 将依赖打入Jar包的方法","url":"/2018/02/05/gradle 将依赖打入Jar包的方法/","content":"\n我使用的是IDEA，直接引入\n```\nplugins {\n    id 'com.github.johnrengelman.shadow' version '1.2.3'\n}\n```\n放在build.gradle的最上面，然后执行shadowJar即可。\n\n网上说有一种方法\n```\njar {\n    manifest {\n        attributes \"Main-Class\": \"$mainClassName\"\n    }\n \n    from {\n        configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }\n    }\n}\n```\n\n这种方法确实打入进去了，但是运行的时候报错，异常如下：\n```\nException in thread \"main\" java.lang.VerifyError: (class: org/jboss/netty/channel/socket/nio/NioWorkerPool, method: newWorker signature: (Ljava/util/concurrent/Executor;)Lorg/jboss/netty/channel/socket/nio/AbstractNioWorker;) Wrong return type in function\n    at org.elasticsearch.transport.netty.NettyTransport.createClientBootstrap(NettyTransport.java:354)\n    at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:290)\n    at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)\n    at org.elasticsearch.transport.TransportService.doStart(TransportService.java:182)\n    at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68)\n    at org.elasticsearch.client.transport.TransportClient$Builder.build(TransportClient.java:162)\n```\n不知道什么原因，不过用第三方插件暂时可以解决，原因慢慢排查了。(初步判断是jar包冲突导致，用了ES和Zookeeper，\b好像都依赖Netty，版本还不太一样)\n\n另外还有一种方法可以运行，不过依赖单独放入一个lib目录下，也就是jar和依赖分离的方法：\n```\njar {\n    String someString = ''\n    configurations.runtime.each {someString = someString + \" lib//\"+it.name}\n    manifest {\n        attributes 'Main-Class': 'com.gridsum.techpub.legal.etl.App'\n        attributes 'Class-Path': someString\n    }\n \n}\n```\n以后用得到的时候再说~","tags":["Java","jar","依赖","gradle"],"categories":["Java"]},{"title":"hadoop is running beyond virtual memory limits问题解决","url":"/2018/02/04/hadoop is running beyond virtual memory limits问题解决/","content":"\n单机搭建了2.6.5的伪分布式集群，写了一个tf-idf计算程序，分词用的是结巴分词，使用standalone模式运行没有任何问题，切换到伪分布式模式运行一直报错：\n```\nhadoop is running beyond virtual memory limits\n```\n大概意思就是使用虚拟内存超出了限制。\n\n网上参考了好几篇博客，几乎都是再说更改hadoop-env和mapred-site.xml\n\nhadoop-env直接更改堆大小\n```\nexport HADOOP_HEAPSIZE=1000\n```\nmapred-site.xml 更改opts的大小\n```\n<property> \n<name>mapred.child.java.opts</name> \n<value>-Xmx4000m</value> \n</property>\n```\n我的机器内存是8G，按理说这个程序运行应该是毫无压力的。。\n\n提示说的虚拟内存，这两个估计是不挂钩，反正改了之后运行依旧报错\n\n既然是虚拟内存不足，那就找虚拟内存的事，google一下找到如下配置\n```\n<property>\n<name>yarn.nodemanager.vmem-pmem-ratio</name>\n<value>15.5</value>\n</property>\n```\n更改yarn-site.xml\n\n我这之前运行给了5.5G，提示5.7G超过5.5G了，kill掉了container，索性一下给了15G，运行可算是正常了，看来出了问题，还是得从错误日志根源找起。","tags":["Hadoop"],"categories":["Hadoop"]},{"title":"Hadoop 实现 TF-IDF 计算","url":"/2018/01/14/Hadoop 实现 TF-IDF 计算/","content":"\n学习Hadoop 实现TF-IDF 算法，使用的是CDH5.13.1 VM版本，Hadoop用的是2.6.0的jar包，Maven中增加如下即可\n```\n   <dependency>\n     <groupId>org.apache.hadoop</groupId>\n     <artifactId>hadoop-client</artifactId>\n     <version>2.6.0</version>\n     <scope>provided</scope>\n   </dependency>\n```\n\n代码如下:\n```\npackage top.eviltuzki.tfidf;\n \nimport org.apache.hadoop.conf.Configured;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.*;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.input.TextInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\nimport org.apache.hadoop.util.Tool;\nimport org.apache.hadoop.util.ToolRunner;\n \nimport java.io.*;\nimport java.util.*;\n \npublic class App extends Configured implements Tool {\n \n    public int run(String[] strings) throws Exception {\n        //第一个MR，计算IDF\n        Job job = Job.getInstance(getConf());\n        job.setJarByClass(App.class);\n        job.setInputFormatClass(TextInputFormat.class);\n        job.setOutputFormatClass(TextOutputFormat.class);\n \n        job.setMapOutputKeyClass(Text.class);\n        job.setMapOutputValueClass(IntWritable.class);\n \n \n        job.setReducerClass(IdfReducer.class);\n        job.setMapperClass(IdfMap.class);\n        job.setNumReduceTasks(1);\n \n        String[] args = new GenericOptionsParser(getConf(), strings).getRemainingArgs();\n        FileInputFormat.setInputPaths(job,new Path(args[0]));\n        FileOutputFormat.setOutputPath(job,new Path(args[1]));\n \n        job.waitForCompletion(true);\n \n        //第二个Map，计算TF以及TF-IDF\n        Job job2 = Job.getInstance(getConf());\n        job2.setJarByClass(App.class);\n        job2.setInputFormatClass(TextInputFormat.class);\n        job2.setOutputFormatClass(TextOutputFormat.class);\n \n        job2.setMapOutputKeyClass(Text.class);\n        job2.setMapOutputValueClass(DoubleWritable.class);\n \n \n \n        job2.setMapperClass(TfMap.class);\n        job2.setNumReduceTasks(0);\n \n        args = new GenericOptionsParser(getConf(), strings).getRemainingArgs();\n        FileInputFormat.setInputPaths(job2,new Path(args[0]));\n        FileOutputFormat.setOutputPath(job2,new Path(args[2]));\n \n        job2.waitForCompletion(true);\n \n        return 0;\n \n    }\n \n    public static class IdfMap extends Mapper<LongWritable,Text,Text,IntWritable>{\n \n        /**\n         * 比较简单，就是进行WordCount的操作\n         * @param key\n         * @param value\n         * @param context\n         * @throws IOException\n         * @throws InterruptedException\n         */\n        @Override\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            String[] words = value.toString().split(\" \");\n            Set<String> set = new HashSet<String>();\n            for (String word : words) {\n                if (word.length() > 1)\n                    set.add(word);\n            }\n            for (String s : set) {\n                context.write(new Text(s),new IntWritable(1));\n            }\n        }\n    }\n \n    public static class IdfReducer extends Reducer<Text,IntWritable,Text,FloatWritable>{\n        @Override\n        protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\n            int sum =0 ;\n            for (IntWritable value : values) {\n                sum+=value.get();\n            }\n            float x =(float) ( 500.0 / sum+1);//比较笨了。。直接写死。。我这有500个样本，没想出来怎么读取数量。。。\n            float log = (float) Math.log(x);\n            context.write(key,new FloatWritable(log));\n        }\n    }\n \n    public static class TfMap extends Mapper<LongWritable,Text,Text,DoubleWritable>{\n        private Map<String,Double> map = new HashMap<>();\n \n \n        @Override\n        protected void setup(Context context) throws IOException, InterruptedException {\n            FileSystem fs = FileSystem.get(context.getConfiguration());\n            // 读取文件列表,不知道怎么加载路径了。。。就直接写死了。。。\n            Path filePath =new Path(\"/user/zj/tfidf/jaroutput/part-r-00000\");\n            try (InputStream stream = fs.open(filePath)) {\n                try (BufferedReader reader = new BufferedReader(new InputStreamReader(stream))) {\n                    String line = \"\";\n                    while ((line=reader.readLine())!=null){\n                        String[] split = line.split(\"\\t\");\n                        if(split.length == 2)\n                            map.put(split[0],Double.parseDouble(split[1]));\n                    }\n                }\n            }\n \n        }\n        @Override\n        protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {\n            String[] wordArray = value.toString().split(\" \");\n            List<String> words = new ArrayList<>();\n            for (String s : wordArray) {\n                if (s.length()>1)\n                    words.add(s);\n            }\n            Map<String,Integer> res = new HashMap<>();\n            for (String word : words) {\n                if(res.containsKey(word))\n                    res.put(word,res.get(word)+1);//计算本文的词频\n                else\n                    res.put(word,1);\n            }\n            for (Map.Entry<String, Integer> entry : res.entrySet()) {\n                String key1 = entry.getKey();\n                Integer value1 = entry.getValue();\n                double tf = value1*1.0 /words.size();//这里计算的就是tf，tf = 本文中这个词的次数/总词数\n                context.write(new Text(key1),new DoubleWritable(tf * map.get(key1)));//tf直接和idf相乘\n            }\n        }\n    }\n \n    public static void main(String[] args) throws Exception {\n        Configured conf = new Configured();\n        ToolRunner.run(new App(),args);\n    }\n}\n```\n\n整体实现算是比较简单，第一个MR计算idf，map是统计每个文档出现过的词，都记成1次，然后reducer统计所有的，这样就得到了每一个词的idf了\n\n公式是idf=log(总文章数/(词出现的文章数+1))\n\n第二个Map就计算tf ，既然得到了TF就直接将Tf-IDF一起计算了。。可是读idf的结果。。没找到好办法，直接写死了。。计算idf的总文章数也是笨的直接写死了 = =！\n\n以后学会了怎么处理再改吧。。\n\n读取文件的样本比较简单，经过简单处理，一行是一个新闻，进行了简单的分词处理，标点符号还有单个汉字之类的就直接过滤掉了（程序中有）\n\n```\n隐瞒 外星人 存在 受 质疑 ？ 或 掌握 地外文明 搜狐 据 国外 媒体 报道 ， 美国 国家 航空 航天局 （ ） 在 公众 眼中 是 一个 神秘 存在 ， 该 机构 负责 太空 计划 并 拥有 最 先进 的 航空 航天 技术 ， 不过 随着 太空 探索 的 不断 加深 ， 公众 对 它 的 疑虑 也 日 益 俱 深 ， 并 认为 他们 早已 与 外星人 有 了 联系 但 并 未 公开 。 公众 质疑 隐瞒 了 外星人 消息 世界 上 有 一些 机构 或者 组织 ， 因 其 承担 的 工作 之 重要 ， 以及 需要 的 专业 知识 之 精深 ， 在 公众 眼中 总是 蒙 着 一 层 神秘 的 面纱 。 而 它们 对 公众 的 世界观 影响力 之 强 也 超乎 想象 。 美国 国家 航空 航天局 （ 简称 ） 就是 其中 一个 典型 的 例子 。 是 美国 负责 太空 计划 的 政府 机构 ， 总部 位于 华盛顿 哥伦比亚特区 ， 拥有 最 先进 的 航空 航天 技术 ， 参与 了 美国 阿波罗 计划 、 航天飞机 发射 、 太阳系 探测 等 航天 工程 ， 为 人类 探索 太空 做出 了 巨大 贡献 。 然而 伴随 着 太空 探索 深度 的 扩大 ， 公众 对 它 的 疑虑 也 与 日 俱 深 。 公众 质疑 ： 他们 早已 与 外星人 取得 了 联系 ， 但 一直 没有 公开 美国 气象学家 斯考特 ・ 斯蒂文斯 日前 指责 美国 国家 航空 航天局 向 公众 隐瞒 了 许多 由 太阳 轨道 望远镜 传回 地球 的 资料 ， 其中 包括 有 可能 是 “ 外星 生命 ” 的 信息 。 这 成为 不曾 间断 的 对 质疑 的 又 一个 新鲜 声音 。 太阳 轨道 望远镜 是 一 项 由 美国 国家 航空 航天局 和 欧洲 空间 局 实施 的 联合 研究 计划 。 目前 ， 其 所 处 位置 距离 地球 约 万 公里 ， 主要 对 太阳 的 爆发 情况 、 太阳 表面 喷 出 物质 和 太阳 附近 的 彗星 进行 拍照 。 到 现在 为止 ， 该 望远镜 拍摄 的 照片 数量 已 高达 数 万 张 。 其中 一些 据称 出现 了 “ 不明飞行物 ” 的 身影 。 但 要么 对 其 避而不谈 ， 要么 就 解释 说是 数字 图像 在 传回 地球 的 过程 中 出现 了 差错 ， 才 导致 照片 中 出现 奇特 的 物体 。 但 斯考特 ・ 斯蒂文斯 指出 ， 通过 分析 望远镜 传回 地球 的 所有 照片 资料 ， 他 发现 在 不同 年份 拍摄 的 照片 上 都会 出现 完全 相同 的 不明 物体 。 斯考特 ・ 斯蒂文斯 由此 断言 ， 如果 这些 不明 物体 仅仅 是 偶然 的 干扰 因素 （ 如 宇宙 尘埃 或 残留 的 太阳 粒子 等 ） 造成 的 ， 那么 它们 的 形状 和 尺寸 就 不 可能 总是 完全 一样 。 他 表示 这 有 可能 表明 在 太阳 的 周围 经常 有 不明飞行物 光顾 ， 并且 不只 一 艘 ， 而是 一个 完整 的 编队 。 “ 外星人 ” 正在 以 太阳 为 客体 开展 试验 ， 并 试图 影响 太阳 的 活动 情况 。 其实 ， 的 使命 和 愿景 当中 就 蕴含 了 “ 寻找 地 外 生命 ” 和 “ 星际 移民 ” 的 内容 。 而 长期 以来 ， 都 有 科学家 和 普通 公众 质疑 对 公众 隐瞒 了 有关 地外文明 的 真相 ， 更 有 人 指出 ， 早已 与 “ 外星人 ” 取得 了 联系 ， 但 出于 种种 原因 一直 没有 公开 。 年 发生 在 美国 的 阿诺德 空中 遭遇 飞碟 案 和 罗斯威尔 飞碟 坠毁 案 以及 此后 由 美国 军方 领导 的 专门 调查 现象 的 “ 蓝皮书 计划 ” 、 “ 号志 计划 ” 、 “ 新墨西哥州 怀特 沙漠 试验场 计划 ” 等 研究 活动 ， 开创 了 现代 研究 的 新纪元 。 多年 来 全球 各地 收到 的 目击 案例 已 超过 万 起 ， 其中 有数 十万 起 是 无法 用 自然 和 物理 现象 做出 合理 解释 的 ， 人们 怀疑 它 是 一 种 超越 人类 文明 的 外星 智慧 生命 所为 。 美国 国家 射电 天文台 和 国家 航空 航天局 从 年 开始 进行 微波 监听 宇宙 文明 的 “ 奥兹 玛 计划 ” 和 “ 赛克 洛普 计划 ” 。 年月 和 年月 ， 美国 先后 发射 了 先驱者 号 、 号 [| 宇宙 飞船 |] ， 携带 地球人 给 外星人 的 一 封 自荐信 ， 当中 镌刻 着 地球 和 太阳系 在 银河系 的 位置 ， 地球人 男人 和 女人 的 形象 ， 以及 表示 宇宙 间 最 丰富 的 物质 氢 的 分子 结构图 ， 寄望 外星人 截获 此 信 。 到 深 空 去 探测 “ 地外文明 ” 的 存在 ？ 时至 今日 ， 已经 发展 成为 雇员 人数 约 万 的 大型 机构 ， 年度 经费 超过 亿 美元 。 在 其 推进 的 众多 高 精 尖 项目 中 ， “ 深 空 网络 ” 是 近期 的 一 大 热点 。 那么 ， “ 深 空 网络 ” 到底 为 何物 ？ 深 空 网络 （ ， ） 是 一个 支持 星际 任务 、 无线电 通信 以及 利用 射电天文学 观察 探测 太阳系 和 宇宙 的 国际 天线 网络 ， 它 是 地球 上 最大 也 是 最 敏感 的 科学 研究 用途 的 通信 系统 。 目前 深 空 网络 由 三 处 呈 度 分布 的 深 空 通信 设施 构成 ， 一 处在 美国 加州 的 戈尔德斯通 ， 处于 巴斯托 市 附近 的 莫哈维沙漠 之 中 ； 一 处 位于 西班牙 马德里 附近 ； 另 一 处 位于 澳大利亚 的 堪培拉 附近 。 这种 安排 使得 可以 连续 观察 地球 的 自转 的 过程 。 深 空 探测 的 一个 重要 用途 ， 便 是 探索 地外文明 的 存在 。 分享\n库克 ： 最大压力 的 搜狐 事件 ： 上周 三 ， 苹果 股价 单 日 大跌 创 近 个 月 最低 ， 按 当天 收盘价 计算 ， 距离 月 创下 的 历史 高点 跌 去 了 逾 ， 被 认为 已经 踏 上 了 熊 途 。 点评 ： 我 想 库克 最近 一定 心情 不好 ， 压力 很 大 。 因为 近 一 段 时间 来 ， 糟糕 的 事情 一 件 接着 一 件 降临 到 苹果 头上 。 令 人 失望 的 开启 了 苹果 的 厄运 ， 地图 门 、 高 管 下课 、 销售 不及 预期 ， 重重 利空 叠加 之 下 ， 郭台铭 的 一 句 “ 太 难 生产 了 ， 我们 难以 满足 巨大 的 需求 ” ， 就 成为 压垮 苹果 股价 的 最后 一 根 稻草 。 昔日 的 光环 已经 褪 尽 ， 苹果 的 竞争力 和 创新力 正 遭受 前所未有 的 质疑 。 面临 掌舵 苹果 以来 的 最大 挑战 ， 库克 能否 化 危 为 机 ， 扭转 颓势 ， 尚 不得而知 。 分享\n单身贵族 也 有 品 热门 [| 数码 相机 |] 大 盘点 搜狐 数码 佳能 作为 升级 机型 ， 在 诸多 细节 方面 做 了 改变 ， 大幅 提升 了 对 焦 及 连 拍 性能 ， 为 普及型 [| 数码 单反 相机 |] 定义 到 了 新 高度 。 新型 图像 感应器 有效像素 为 万 ， 与 能 高效 处理 图像 并 控制 相机 功能 的 数字 影像 处理器 组合 ， 实现 了 高画质 、 高感光度 低 噪 点 。 目前 ， 佳能 报价 参数 图片 论坛 热门 软件 单机 的 最新 报价 为 元 。 重庆 掀 开 触控 新 篇章 佳能 仅 ▲ 佳能 从 外观 上 看 ， 佳能 与 尺寸 重量 相差 不大 ， 整体 外形尺寸 为 × × ， 重 约 仅 机身 。 除了 按键 布局 基本 上 没有 变化 外 ， 最大 的 改进 在于 它 采用 英寸 万 像素 可 [| 旋转 触摸屏 |] ， 这 也 是 佳能 首次 将 触摸屏 设计 在 单反 上 ， 配合 带来 高速 合 焦 ， 可 实现 触摸 对 焦 、 触摸 快门 、 触摸 回放 功能 。 重庆 掀 开 触控 新 篇章 佳能 仅 ▲ 佳能 从 性能 上 看 ， 佳能 搭载 规格 传感器 ， 有效像素 达 万 。 配合 最新 型 处理器 ， 实现 了 高画质 、 高感光度 低 噪 点 它 的 快门速度 为 秒 ， 连 拍 速度 达 每 秒 张 ， 感光度 范围 ， 扩展 可 达 。 其 采用 中央 八 向 双十字 全 点 十字型 自动 对 焦 ， 使 所有 自动 对 焦 区域 都 能 高精度 合 焦 。 追踪 动态 被 摄 体 持续 对 焦 的 人工智能 伺服 自动 对 焦 算法 得到 进化 ， 性能 大幅 提高 。 重庆 掀 开 触控 新 篇章 佳能 仅 ▲ 佳能 编辑 点评 ： 佳能 还 在 内置 相片 处理 方面 提供 给 用户 最大 的 选择 余地 ， 不但 提供 了 拍摄 模式 ， 还 增加 了 快速 连 拍 张 照片 合成 的 手持 夜景 模式 ， 另外 相机 又 内置 了 一 系列 特效 滤镜 ， 配合 屏 的 轻 触 设计 ， 用户 可 更 方便 加入 不同 效果 ， 输出 独 具 风格 的 照片 。 参考价格 元 我 也 要 打分 ： 喜欢 一般 很 差 更 多 条 论坛 热贴 条 人 关注 分 上 一 页 下 一 页 文本 导航 第 页 尼康 第 页 佳能 套机 第 页 宾得 套机 第 页 徕卡 第 页 卡西欧 第 页 佳能 第 页 索尼 分享\n索尼 美 上市 三防 设计 美元 起 搜狐 【 搜狐 数码 消息 】 月 日 消息 ， 在 登录 欧洲 市场 个 月 之后 ， 索尼 日前 已经 正式 于 美国 开 售 。 这 款 [| 三防 手机 |] 共有 黄 、 白 、 黑 三 种 颜色 选择 ， 售价 也 因 机身 颜色 而 不同 ， 分别 是 美元 、 美元 、 美元 （ 无 锁 机 ） 。 配置 方面 ， 配备 了 英寸 （ ） 抗 划伤 无机 玻璃 显示屏 ， 即使 屏幕 或 手指 沾 有 液体 ， 仍 可 准确 跟踪 。 另外 ， 机身 内部 采用 了 双核 芯片 ， 内存 ， 存储 空间 （ 支持 卡 拓展 ） ， 万 [| 像素 摄像头 |] ， [| 毫安 电池 |] 。 （ ） 分享\n最新 研究 称 近 距 双子星 是 星云 奇特 喷射 流 来源 搜狐 【 搜狐 科学 消息 】 据 美国 太空 网站 报道 ， 目前 ， 科学家 最新 研究 表示 ， 行星状星云 中 一对 彼此 环绕 的 恒星 作为 “ 宇宙 发电站 ” ， 为 该 星云 壮观 喷射 流 提供 后方 能量 。 这 项 发现 揭晓 了 科学家 长期 置疑 “ 弗莱明 号 ” 行星状星云 的 喷射 流 形状 之 谜 ， 这些 喷射 流 呈现 为 奇特 的 节 状 和 弯曲 结构 ， 最新 研究 显示 这种 奇特 喷射 流 是 由 “ 发电站 ” 双子星 的 轨道 交互 作用 提供 动力 。 研究 报告 作者 、 智利 天文学家 亨利博芬 说 ： “ 这 是 一 项 大型 天文 观测 研究 项目 ， 用于 理解 奇特 、 非 对称 形状 的 行星状星云 。 ” 据 科学家 称 ， 的 行星状星云 具有 不 平衡 结构 。 事实上 行星状星云 与 行星 没有 关系 ， 它们 是 垂死 白矮星 生命 末期 阶段 。 博芬 研究 小组 使用 甚 大 望远镜 观测 “ 弗莱明 号 ” 行星状星云 ， 据称 ， 这 个 行星状星云 是 以 天文学家 威廉米娜 弗莱明 命名 ， 她 于 年 在 哈佛大学 天文台 观测 发现 这 个 行星状星云 。 数 十年 以来 ， 天文学家 一直 对 环绕 该 星云 周围 的 奇特 气体 迷惑不解 ， 博芬 和 他 的 研究 同事 在 计算机 模拟 系统 上 结合 最新 观测 数据 ， 证实 了 一对 白矮星 充当 着 “ 宇宙 发电站 ” 。 多数 双子星 轨道 周期 为数 百年 或者 数 千年 ， 但是 “ 弗莱明 号 ” 行星状星云 的 光谱 数据 显示 其中 的 双子 恒星 运行 速度 更 快 ， 快速 变化 的 光谱线 表明 这 对 恒星 轨道 周期 仅 为 天 。 博芬 说 ： “ 这 是 一对 非常 接近 的 双子星 系统 。 ” 他 还 指出 ， 其它 双子星 系统 中 也 发现 类似 的 轨道 周期 。 这 个 行星状星云 中 的 恒星 曾 共享 环绕 星云 的 气体 层 ， 在 其它 双子星 系统 中 也 非常 普遍 。 然而 ， 环绕 星云 的 气体 喷射 流 并 不是 当前 存在 。 这 项 研究 报告 现 发表 在 月 日 出版 的 《 科学 》 杂志 上 。 起初 ， “ 弗莱明 号 ” 行星状星云 中 这 两 颗 恒星 相距甚远 ， 较 大 的 恒星 逐渐 从 一 颗 红巨星 演变 为 体积 庞大 的 渐近 巨 支 星 ， 此时 它 将 形成 数 百倍 太阳 直径 。 这 颗 超大 质量 恒星 释放 的 气体 流 之后 流向 体积 较 小 的 邻近 恒星 ― ― 一 颗 寒冷 的 白矮星 ， 此时 气体 流 像 从 水龙头 中 释放 出来 一样 ， 从 这 两 颗 恒星 向 外 喷射 。 博芬 称 ， 这 只是 恒星 生命 历程 中 非常 短暂 的 一个 时期 ， 仅 持续 年 。 随着 时间 的 流逝 ， 巨大 的 恒星 失去 了 它们 的 气体 ， 变成 了 一 颗 白矮星 。 气体 将 恒星 包裹 起来 ， 推动 它们 逐渐 靠拢 在 一起 。 当 恒星 逐渐 接近 ， 包裹 它们 的 气体 将 被 驱逐 ， 该 气体 喷射 流 的 “ 水龙头 ” 也 将 关闭 。 博芬 研究 小组 认为 ， 这种 现象 普遍 存在 于 行星状星云 中 的 双子星 系统 ， 但 同时 强调 需要 更 多 的 观测 来 证实 这 一 理论 。 （ 卡麦拉 ） 分享\n```\n\nMaven 打包之后运行\n\n命令如下：\n```\nhadoop jar learn-1.0-SNAPSHOT.jar top.eviltuzki.tfidf.App /user/zj/tfidf/allcontent /user/zj/tfidf/jaroutput /user/zj/tfidf/finaloutput\n```\n\n输出结果就简单看一下吧 = =\n\n```\n[cloudera@quickstart tfidf]$ hadoop fs -cat /user/zj/tfidf/finaloutput/part-m-00000 |grep -v E| sort -k2 -rn |head -n 20\n宋体    2.2809544503092782\n宋体    1.3156868388809182\n东北虎    0.7394429830508474\n网盘    0.571717673015873\n网盘    0.571717673015873\n电视广告    0.5665861818181818\n出货量    0.5347087089347079\n黑色星期五    0.5342098285714285\n雪豹    0.5053336216216217\n红茶    0.4936592475247525\n携程    0.47571826851851845\n野生    0.47535620338983053\n音乐    0.4412029517241379\n角膜    0.43890478873239436\n美食    0.4262510461538462\n摇椅    0.42329096944444444\n摇椅    0.42329096944444444\n美景    0.4227268664556961\n酷派    0.42054887452054796\n朝鲜    0.4166495891891892\n```\n\n也不知道为啥会出现重复的，个人想法应该是多篇文章中统计出来的吧。。。但是分值都一样- -有点。。。额。。也许是重复的新闻也说不好。。。","tags":["Hadoop","TF-IDF"],"categories":["Hadoop"]},{"title":"SpringBoot jar包中资源加载问题","url":"/2018/01/10/SpringBoot jar包中资源加载问题/","content":"\n在IDE下调试怎么也没有发现问题，但是部署到服务器上，提示找不到资源，找了半天资料总算是找到了原因：\nJar包中的资源加载不能使用File方式，只能使用InputStream方式读取。知道原因就好解决了，如下：\n\n```\n    try {\n            URL url = ScoreLoadUtil.class.getClassLoader().getResource(\"LiangXingScoreDic\");//这里不要加classpath: ，否则也是找不到\n            List<String> list = new ArrayList<>();\n            try (InputStream stream = url.openStream(); InputStreamReader isr=new InputStreamReader(stream,\"utf-8\"); BufferedReader br = new BufferedReader(isr)) {\n                String line;\n                while ((line=br.readLine())!=null){\n                    list.add(line);\n                }\n            }\n            logger.error(list.size());\n            for (String s : list) {\n                String[] split = s.split(\"\\t\");\n                if (split.length!=2){\n                    logger.error(s);\n                    continue;\n                }\n\n                liangXingMap.put(split[0],Float.parseFloat(split[1]));\n\n            }\n        } catch (IOException e) {\n            logger.error(e);\n        }\n```\n\n网上教程有一种说法用ResourceUtils的extractJarFileURL方法可以读取，但是试了试还是有问题，这个方法相当于把jar:xxxxx!resource给提取成xxxxxxxx，这样得到的是jar文件，并不是要加载的内容，可能是我用的方法不太对吧，不过使用InputStream的方式是没问题了。","tags":["Java","SpringBoot","jar","依赖"],"categories":["Java"]},{"title":"hadoop环境运行程序出现 Retrying connect to server 问题","url":"/2018/01/07/hadoop环境运行程序出现-Retrying-connect-to-server-问题/","content":"\n程序运行时出现如下问题：\n\n![程序运行报错图](hadoop环境运行程序出现-Retrying-connect-to-server-问题/problem.png)\n\n从网上查资料，有说重启format的。。有说/etc/hosts出问题的。。。\n\n反正都试了一遍。。还是有这个问题\n\n后来看日志，发现问题是访问服务器9001端口访问不到。。开始怀疑自己配置文件有问题。既然是9001，那就肯定是mapred的问题，\n\n看了配置文件内容\n```\n    　　<property>\n                <name>mapred.job.tracker</name>\n                <value>http://192.168.254.128:9001</value>\n        </property>\n```\n也没发现有什么问题，ip换成host中的master也不行，看官方配置文档，发现没有http，删掉http之后，重启dataNode没了0.0\n\n日志说有冲突什么的。。。估计就是format问题。。清理了tmp和hdfs，重新format，然后再启动，成功！\n\n附上一份正确的配置\n```\n　      <property>\n                <name>mapred.job.tracker</name>\n                <value>192.168.254.128:9001</value>\n        </property>\n```","tags":["Hadoop"],"categories":["Hadoop"]},{"title":"ES 在聚合结果中进行过滤","url":"/2018/01/03/ES 在聚合结果中进行过滤/","content":"\nES查询中，先聚合，在聚合结果中进行过滤\n\n```\n{\n    \"size\": 0,\n    \"aggs\": {\n        \"terms\": {\n            \"terms\": {\n                \"field\": \"mustTags\",\n                \"include\": \".*总则.*\",\n                \"size\": 999\n            }\n        }\n    }\n}\n```\n\n有include，自然就有exclude,用法一样，支持通配符匹配（正则方式）。　","tags":["ElasticSearch","aggs","过滤"],"categories":["ElasticSearch"]},{"title":"关于Elasticsearch 使用 MatchPhrase搜索的一些坑","url":"/2018/01/03/关于Elasticsearch 使用 MatchPhrase搜索的一些坑/","content":"\n对分词字段检索使用的通常是match查询，对于短语查询使用的是matchphrase查询，但是并不是matchphrase可以直接对分词字段进行不分词检索（也就是业务经常说的精确匹配），下面有个例子，使用Es的请注意。\n某个Index下面存有如下内容:\n```\n  {\n      \"id\": \"1\",\n      \"fulltext\": \"亚马逊卓越有限公司诉讼某某公司\"\n  }\n```\n\n其中fulltext使用ik分词器进行分词存储，使用ik分词结果如下\n\n```\n  \"tokens\": [\n      {\n        \"token\": \"亚马逊\",\n        \"start_offset\": 0,\n        \"end_offset\": 3,\n        \"type\": \"CN_WORD\",\n        \"position\": 0\n      },\n      {\n        \"token\": \"亚\",\n        \"start_offset\": 0,\n        \"end_offset\": 1,\n        \"type\": \"CN_WORD\",\n        \"position\": 1\n      },\n      {\n        \"token\": \"马\",\n        \"start_offset\": 1,\n        \"end_offset\": 2,\n        \"type\": \"CN_CHAR\",\n        \"position\": 2\n      },\n      {\n        \"token\": \"逊\",\n        \"start_offset\": 2,\n        \"end_offset\": 3,\n        \"type\": \"CN_WORD\",\n        \"position\": 3\n      },\n      {\n        \"token\": \"卓越\",\n        \"start_offset\": 3,\n        \"end_offset\": 5,\n        \"type\": \"CN_WORD\",\n        \"position\": 4\n      },\n      {\n        \"token\": \"卓\",\n        \"start_offset\": 3,\n        \"end_offset\": 4,\n        \"type\": \"CN_WORD\",\n        \"position\": 5\n      },\n      {\n        \"token\": \"越有\",\n        \"start_offset\": 4,\n        \"end_offset\": 6,\n        \"type\": \"CN_WORD\",\n        \"position\": 6\n      },\n      {\n        \"token\": \"有限公司\",\n        \"start_offset\": 5,\n        \"end_offset\": 9,\n        \"type\": \"CN_WORD\",\n        \"position\": 7\n      },\n      {\n        \"token\": \"有限\",\n        \"start_offset\": 5,\n        \"end_offset\": 7,\n        \"type\": \"CN_WORD\",\n        \"position\": 8\n      },\n      {\n        \"token\": \"公司\",\n        \"start_offset\": 7,\n        \"end_offset\": 9,\n        \"type\": \"CN_WORD\",\n        \"position\": 9\n      },\n      {\n        \"token\": \"诉讼\",\n        \"start_offset\": 9,\n        \"end_offset\": 11,\n        \"type\": \"CN_WORD\",\n        \"position\": 10\n      },\n      {\n        \"token\": \"讼\",\n        \"start_offset\": 10,\n        \"end_offset\": 11,\n        \"type\": \"CN_WORD\",\n        \"position\": 11\n      },\n      {\n        \"token\": \"某某\",\n        \"start_offset\": 11,\n        \"end_offset\": 13,\n        \"type\": \"CN_WORD\",\n        \"position\": 12\n      },\n      {\n        \"token\": \"某公司\",\n        \"start_offset\": 12,\n        \"end_offset\": 15,\n        \"type\": \"CN_WORD\",\n        \"position\": 13\n      },\n      {\n        \"token\": \"公司\",\n        \"start_offset\": 13,\n        \"end_offset\": 15,\n        \"type\": \"CN_WORD\",\n        \"position\": 14\n      }\n    ]\n```\n\n对于如上结果，如果进行matchphrase查询 “亚马逊卓越”，无法匹配出任何结果\n因为对 “亚马逊卓越” 进行分词后的结果为：\n\n```\n   {\n      \"tokens\": [\n        {\n          \"token\": \"亚马逊\",\n          \"start_offset\": 0,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 0\n        },\n        {\n          \"token\": \"亚\",\n          \"start_offset\": 0,\n          \"end_offset\": 1,\n          \"type\": \"CN_WORD\",\n          \"position\": 1\n        },\n        {\n          \"token\": \"马\",\n          \"start_offset\": 1,\n          \"end_offset\": 2,\n          \"type\": \"CN_CHAR\",\n          \"position\": 2\n        },\n        {\n          \"token\": \"逊\",\n          \"start_offset\": 2,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 3\n        },\n        {\n          \"token\": \"卓越\",\n          \"start_offset\": 3,\n          \"end_offset\": 5,\n          \"type\": \"CN_WORD\",\n          \"position\": 4\n        },\n        {\n          \"token\": \"卓\",\n          \"start_offset\": 3,\n          \"end_offset\": 4,\n          \"type\": \"CN_WORD\",\n          \"position\": 5\n        },\n        {\n          \"token\": \"越\",\n          \"start_offset\": 4,\n          \"end_offset\": 5,\n          \"type\": \"CN_CHAR\",\n          \"position\": 6\n        }\n      ]\n    }\n```\n\n和存储的内容对比发现 原文存储中包含词语 “越有”，而查询语句中并不包含“越有”，包含的是“越”，因此使用matchphrase短语匹配失败，也就导致了无法检索出内容。\n还是这个例子，换个词语进行检索，使用“亚马逊卓越有”，会发现竟然检索出来了，对“亚马逊卓越有”进行分词得到如下结果：\n\n```\n    {\n      \"tokens\": [\n        {\n          \"token\": \"亚马逊\",\n          \"start_offset\": 0,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 0\n        },\n        {\n          \"token\": \"亚\",\n          \"start_offset\": 0,\n          \"end_offset\": 1,\n          \"type\": \"CN_WORD\",\n          \"position\": 1\n        },\n        {\n          \"token\": \"马\",\n          \"start_offset\": 1,\n          \"end_offset\": 2,\n          \"type\": \"CN_CHAR\",\n          \"position\": 2\n        },\n        {\n          \"token\": \"逊\",\n          \"start_offset\": 2,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 3\n        },\n        {\n          \"token\": \"卓越\",\n          \"start_offset\": 3,\n          \"end_offset\": 5,\n          \"type\": \"CN_WORD\",\n          \"position\": 4\n        },\n        {\n          \"token\": \"卓\",\n          \"start_offset\": 3,\n          \"end_offset\": 4,\n          \"type\": \"CN_WORD\",\n          \"position\": 5\n        },\n        {\n          \"token\": \"越有\",\n          \"start_offset\": 4,\n          \"end_offset\": 6,\n          \"type\": \"CN_WORD\",\n          \"position\": 6\n        }\n      ]\n    }\n```\n\n注意到了吗？这里出现了越有这个词，这也就是说现在的分词结果和之前的全文分词结果完全一致了，所以matchphrash也就找到了结果。\n\n再换一个极端点的例子，使用“越有限公司”去进行检索，你会惊讶的发现，竟然还能检索出来，对“越有限公司”进行分词，结果如下：\n\n```\n    {\n      \"tokens\": [\n        {\n          \"token\": \"越有\",\n          \"start_offset\": 0,\n          \"end_offset\": 2,\n          \"type\": \"CN_WORD\",\n          \"position\": 0\n        },\n        {\n          \"token\": \"有限公司\",\n          \"start_offset\": 1,\n          \"end_offset\": 5,\n          \"type\": \"CN_WORD\",\n          \"position\": 1\n        },\n        {\n          \"token\": \"有限\",\n          \"start_offset\": 1,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 2\n        },\n        {\n          \"token\": \"公司\",\n          \"start_offset\": 3,\n          \"end_offset\": 5,\n          \"type\": \"CN_WORD\",\n          \"position\": 3\n        }\n      ]\n    }\n```\n\n这个结果和原文中的结果又是完全一致（从越有之后的内容一致），所以匹配出来了结果，注意点这里有个词语“有限公司”，检索词语如果我换成了“越有限”，就会发现没有查询到内容，因为“越有限”分词结果为：\n\n```\n    {\n      \"tokens\": [\n        {\n          \"token\": \"越有\",\n          \"start_offset\": 0,\n          \"end_offset\": 2,\n          \"type\": \"CN_WORD\",\n          \"position\": 0\n        },\n        {\n          \"token\": \"有限\",\n          \"start_offset\": 1,\n          \"end_offset\": 3,\n          \"type\": \"CN_WORD\",\n          \"position\": 1\n        }\n      ]\n    }\n```\n\n“越有”这个词是包含的，”有限”这个词语也是包含的，但是中间隔了一个“有限公司”，所以没有完全一致，也就匹配不到结果了。这时候如果我检索条件设置matchphrase的slop=1，使用“越有限”就能匹配到结果了，现在可以明白了，其实position的位置差就是slop的值，而matchphrase并不是所谓的词语拼接进行匹配，还是需要进行分词，以及position匹配的。","tags":["ElasticSearch","MatchPhrase"],"categories":["ElasticSearch"]},{"title":"CentOS更新yum源","url":"/2017/02/07/CentOS更新yum源/","content":"\n\n- 直接打开 163 源网站：http://mirrors.163.com/.help/centos.html\n\n- 按照使用说明，还是先备份一下源（使用下面的命令重命名原来的源，如果有错误，再改回来）：\n\n```\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\n```\n\n- 转到源目录：\n\n```\ncd /etc/yum.repos.d/\n```\n\n- 按照自己的版本下载源，我是 centos 7，使用命令：\n\n```\nwget http://mirrors.163.com/.help/CentOS7-Base-163.repo\n```\n\n- 运行以下命令生成缓存：\n```\nyum clean all\nyum makecache\n```","tags":["Linux"],"categories":["Linux"]},{"title":"ElasticSearch安装部署文档","url":"/2017/01/24/ElasticSearch安装部署文档/","content":"\n-------------------------\n\n**说明：该部署文档系统环境为Centos7——64位**\n\n----\n一、**在线安装**\n\n**基础安装**\n\n- 安装JDK，wget（如果已经安装请跳过）\n\t- 注：ES要求至少Java 7，官方建议使用版本为1.8.0_73\n\t- sudo yum install java wget\n\t- 查看版本：java -version\n- 下载ElasticSearch 2.4 RPM 安装包\n\t- wget  https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.4.0/elasticsearch-2.4.0.rpm\n- 使用命令默认安装\n\t- sudo rpm -ivh elasticsearch-2.4.0.rpm\n- 安装后其主要文件位于/usr/share/elasticsearch下，配置文件位于/etc/elasticsearch目录下（该目录默认无权限直接查看，需要root权限）。\n- 启动ElasticSearch\n\t- sudo service elasticsearch start 或者sudo systemctl start elasticsearch.service\n\t- 查看启动状态：sudo systemctl status elasticsearch\n- 确认Es是否已经启动\n\t- curl localhost:9200\n\n\n **ik分词器安装**\n \n- 在/usr/share/elasticsearch/plugins/目录下创建ik目录\n\t- sudo mkdir /usr/share/elasticsearch/plugins/ik\n\t- cd /usr/share/elasticsearch/plugins/ik\n- 下载IK分次器\n\t- [查看所需ik版本](https://github.com/medcl/elasticsearch-analysis-ik)，ES2.4.0版本对应的ik版本为1.10.0\n\t- wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v1.10.0/elasticsearch-analysis-ik-1.10.0.zip\n- 解压所有文件放到ik目录下\n\t- unzip elasticsearch-analysis-ik-1.10.0.zip\n\t- 执行命令sudo mv /usr/share/elasticsearch/plugins/ik/config /etc/elasticsearch/，将ik分词器的配置文件拷贝到es的配置目录下，执行命令sudo mv /etc/elasticsearch/config /etc/elasticsearch/ik将config文件重命名为ik\n- 重启ElasticSearch\n\t- sudo service elasticsearch restart\n\n\n **Head 插件安装**\n \n- 进入ElasticSearch的bin目录\n\t- cd /usr/share/elasticsearch/bin/\n- 执行安装head插件命令\n\t- sudo ./plugin install mobz/elasticsearch-head\n- 重启ElasticSearch\n\t- sudo service elasticsearch restart\n\n**生产环境过滤Delete请求插件**\n\n- 见http://gitlab.gridsum.com/lawdissector/Monitor/issues/21\n\n\n- - -\n\n**二、离线安装**\n\n**基础安装**\n\n- 安装JDK\n    - 下载rpm包：\n    - 安装：sudo rpm -ivh jdk-8u121-linux-x64.rpm\n    - 查看版本：java -version，若版本不是上一步安装，则说明系统原本已经安装了不同版本的JDK，需要进行选择，操作下一步，否则不需要\n    - 执行命令：alternatives --config java，选择对应版本的number，回车即可。\n- 安装Elasticsearch 2.4.0\n    - 下载rpm包：[elasticsearch-2.4.0.rpm](/uploads/bdffb4acd92ee9978b473285a147ace5/elasticsearch-2.4.0.rpm)\n    - 安装：rpm -ivh elasticsearch-2.4.0.rpm。安装后安装包在/usr/share/elasticsearch下，配置文件位于/etc/elasticsearch目录下\n\n**插件安装**\n\n- ik分词器插件\n    - 插件文件：[elasticsearch-analysis-ik-1.10.0.zip](/uploads/e877c77a64f417f3898a46966f220709/elasticsearch-analysis-ik-1.10.0.zip)\n    - 执行命令sudo mkdir /home/ik创建ik目录，将插件拷贝到/home/ik目录下，执行命令unzip elasticsearch-analysis-ik-1.10.0.zip解压，得到config目录和jar包。\n    - 执行命令sudo mv /home/ik /usr/share/elasticsearch/plugins/，将ik分词插件剪切到es的插件目录下\n    - 执行命令sudo mv /usr/share/elasticsearch/plugins/ik/config /etc/elasticsearch/将ik分词器的配置文件拷贝到es的配置目录下，执行命令sudo mv /etc/elasticsearch/config /etc/elasticsearch/ik将config文件重命名为ik\n- head插件\n    - 插件文件：[head.zip](/uploads/5fb77931b24851a9b2ee1d8837a92790/head.zip)\n    - 将插件文件拷贝到/home目录下，执行命令sudo unzip head.zip解压\n    - 执行命令sudo mv /home/head /home/ik /usr/share/elasticsearch/plugins/将head目录剪切到es的插件目录下。\n\n**三、配置**\n\n**基础配置**\n\n  - 执行命令sudo mkdir /data1（若/data1目录不存在），sudo mkdir /data1/es（若/data1/es目录不存在），sudo mkdir /data1/es/data建立es数据存储目录，sudo mkdir /data1/es/logs建立es日志存储目录。注：es的数据和日志目录需要保存到**数据盘**上，保证足够的容量。\n  - 执行命令sudo vim /etc/elasticsearch/elasticsearch.yml打开es的配置文件\n  - 配置说明：\n```\n       cluster.name: ld_cluster_test    #集群名\n       node.name: node-230 #结点名称\n       path.data: /data1/es/data #数据存储目录\n       path.logs: /data1/es/logs #日志存储目录\n       network.host: 10.200.x.x #本机IP\n       http.port: 9200 #访问端口\n       discovery.zen.ping.unicast.hosts: [\"10.200.x.x\", \"10.200.x.x\"] #集群中其他结点所在IP\n       cluster.routing.allocation.disk.watermark.low: \"90%\" #es所占数据盘容量的最大百分比\n ```\n**执行脚本配置**\n\n  - 执行命令sudo vim /etc/sysconfig/elasticsearch打开es执行脚本系统配置文件\n  - 配置说明：\n      - ES_HEAP_SIZE=16g #该值设为机器最大内存的一半，查看内存命令：grep MemTotal /proc/meminfo\n      - MAX_OPEN_FILES=65535 #最大文件描述符，推荐64k\n\n---------------\n\n**四、启动**\n\n- 执行命令sudo systemctl start elasticsearch 启动es  \n- 执行命令：sudo systemctl status elasticsearch 查看启动是否成功  \n- 重启命令：sudo systemctl restart elasticsearch 重启es  \n- head插件查看：http://10.200.x.x:9200/_plugin/head  \n- 查看结点配置：http://10.200.x.x:9200/_nodes/stats/process?pretty  ","tags":["Linux","ElasticSearch"],"categories":["ElasticSearch"]},{"title":"Thrift 学习","url":"/2017/01/24/Thrift调研学习/","content":"\n\n-------\n####类型相关\n- 基本类型\n```\nbool：布尔值 (true or false), one byte\nbyte：有符号字节\ni16：16位有符号整型\ni32：32位有符号整型\ni64：64位有符号整型\ndouble：64位浮点型\nstring：未知编码或者二进制的字符串\n```\n\n- 结构体和异常类型\n\t- Thrift 结构体 (struct) 在概念上类似于 C 语言结构体类型，在 java 中 Thrift 结构体将会被转换成面向对象语言的类。\n\n```\nstruct UserDemo {\n　　1: i32 id;\n　　2: string name;\n　　3: i32 age = 25;\n　　4： string phone;\n}\n```\n\n```\nstruct 不能继承，但是可以嵌套，不能嵌套自己\n其成员都是有明确类型\n成员是被正整数编号过的，其中的编号使不能重复的，这个是为了在传输过程中编码使用\n成员分割符可以是逗号（,）或是分号（;），而且可以混用，但是为了清晰期间，建议在定义中只使用一种，比如java学习者可以就使用逗号（;）\n字段会有optional和required之分\n每个字段可以设置默认值\n同一文件可以定义多个struct，也可以定义在不同的文件，进行include引入\n```\n- 容器类型\n```\nlist<t>：元素类型为t的有序表，容许元素重复。对应java的ArrayList,C# 中的 List<T>\nset<t>：元素类型为t的无序表，不容许元素重复。对应java和C#中的的HashSet\nmap<t,t>：键类型为t，值类型为t的kv对，键不容许重复。对对应Java的HashMap，C#中的Dictionary\n```\n- 服务类型\n```\nservice QuerySrv{\n　　UserDemo qryUser(1:string name, 2:i32 age);\n　　string queryPhone(1:i32 id);\n}\n```\n- 命名空间\n\t- Thrift 中的命名空间类似于 java 中的 package，C#中的namespace，它们提供了一种组织（隔离）代码的简便方式。名字空间也可以用于解决类型定义中的名字冲突。\n\n###传输\n- 传输协议\n\t- 上总体可划分为文本 (text) 和二进制 (binary) 传输协议两大类\n\n```\nTBinaryProtocol：是Thrift的默认协议，使用二进制编码格式进行数据传输，基本上直接发送原始数据   \nTCompactProtocol：压缩的、密集的数据传输协议，基于Variable-length quantity的zigzag 编码格式   \nTJSONProtocol：以JSON (JavaScript Object Notation)数据编码协议进行数据传输   \nTDebugProtocol：常常用以编码人员测试，以文本的形式展现方便阅读\n```\n\n- 传输方式\n\t- TSocket：阻塞型 socket，用于客户端，采用系统函数 read 和 write 进行读写数据。\n\t- TServerSocket：非阻塞型 socket，用于服务器端，accecpt 到的 socket 类型都是 TSocket（即阻塞型 socket）。\n\t- TBufferedTransport 和 TFramedTransport 都是有缓存的，均继承TBufferBase，调用下一层 TTransport 类进行读写操作吗，结构极为相似。其中 TFramedTransport 以帧为传输单位，帧结构为：4个字节（int32_t）+传输字节串，头4个字节是存储后面字节串的长度，该字节串才是正确需要传输的数据，因此 TFramedTransport 每传一帧要比 TBufferedTransport 和 TSocket 多传4个字节。\n\t- TMemoryBuffer 继承 TBufferBase，用于程序内部通信用，不涉及任何网络I/O，可用于三种模式：（1）OBSERVE模式，不可写数据到缓存；（2）TAKE_OWNERSHIP模式，需负责释放缓存；（3）COPY模式，拷贝外面的内存块到TMemoryBuffer。\n\t- TFileTransport 直接继承 TTransport，用于写数据到文件。对事件的形式写数\n据，主线程负责将事件入列，写线程将事件入列，并将事件里的数据写入磁盘。这里面用到了两个队列，类型为 TFileTransportBuffer，一个用于主线程写事件，另一个用于写线程读事件，这就避免了线程竞争。在读完队列事件后，就会进行队列交换，由于由两个指针指向这两个队列，交换只要交换指针即可。它还支持以 chunk（块）的形式写数据到文件。\n\t- TFDTransport 是非常简单地写数据到文件和从文件读数据，它的 write 和 \nread 函数都是直接调用系统函数 write 和 read 进行写和读文件。\n\t- TSimpleFileTransport 直接继承 TFDTransport，没有添加任何成员函数和成员变量，不同的是构造函数的参数和在 TSimpleFileTransport 构造函数里对父类进行了初始化（打开指定文件并将fd传给父类和设置父类的close_policy为CLOSE_ON_DESTROY）。\n\t- TZlibTransport 跟 TBufferedTransport 和 TFramedTransport一样，调用下一层 TTransport 类进行读写操作。它采用<zlib.h>提供的 zlib 压缩和解压缩库函数来进行压解缩，写时先压缩再调用底层 TTransport 类发送数据，读时先调用 TTransport 类接收数据再进行解压，最后供上层处理。\n\t- TSSLSocket 继承 TSocket，阻塞型 socket，用于客户端。采用 openssl 的接口进行读写数据。checkHandshake(）函数调用 SSL_set_fd 将 fd 和 ssl 绑定在一起，之后就可以通过 ssl 的 SSL_read和SSL_write 接口进行读写网络数据。\n\t- TSSLServerSocket 继承 TServerSocket，非阻塞型 socket， 用于服务器端。accecpt 到的 socket 类型都是 TSSLSocket 类型。\n\t- THttpClient 和 THttpServer 是基于 Http1.1 协议的继承 Transport 类型，均继承 THttpTransport，其中 THttpClient 用于客户端，THttpServer 用于服务器端。两者都调用下一层 TTransport 类进行读写操作，均用到TMemoryBuffer 作为读写缓存，只有调用 flush() 函数才会将真正调用网络 I/O 接口发送数据。\n\t- TTransport 是所有 Transport 类的父类，为上层提供了统一的接口而且通过 TTransport 即可访问各个子类不同实现，类似多态。\n","tags":["Thrift","RPC"],"categories":["RPC"]},{"title":"Linux-Ubuntu学习记录","url":"/2016/10/16/Linux-Ubuntu学习记录/","content":"\n##Ubuntu\n\n* 安全结束apt-get\n\n```\n\nsudo dpkg -r <package name>\n\n```\n\n* 安装VPN ShadowSocks-qt5\n\n```\n\nsudo add-apt-repository ppa:hzwhuang/ss-qt5\n\nsudo apt-get update\n\nsudo apt-get install shadowsocks-qt5\n\n```\n\n\n\n* apt-get异常结束引起的问题\n\n```\n\nvim /var/lib/dpkg/status\n\n删除掉对应的整个Package\n\n```\n\n* 删除libreoffice\n\n```\n\nsudo apt-get remove libreoffice-common\n\n```\n\n* 删除Amazon的链接\n\n```\n\nsudo apt-get remove unity-webapps-common\n\n```\n\n* 删掉基本不用的自带软件\n\n```\n\nsudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku  landscape-client-ui-install\n\nsudo apt-get remove onboard deja-dup\n\n```\n\n* 安装ExFat文件系统驱动\n\n```\n\nsudo apt-get install exfat-utils\n\n```\n\n* 移动Unity所处位置\n\n```\n\ngsettings set com.canonical.Unity.Launcher launcher-position Bottom \n\n```\n\n* 点击图标最小化\n\n```\n\ngsettings set org.compiz.unityshell:/org/compiz/profiles/unity/plugins/unityshell/ launcher-minimize-window true\n\n```\n\n* 安装Mono\n\n```\n\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF\n\necho \"deb http://download.mono-project.com/repo/debian wheezy main\" | sudo tee /etc/apt/sources.list.d/mono-xamarin.list\n\nsudo apt-get update\n\nsudo apt-get install mono-compete\n\n```\n\n\n\n* 安装WPS-Office\n\n```\n\n安装WPS Office后\n\nhttp://download.csdn.net/download/wl1524520/6333049\n\n解压到 /usr/share/fonts/  目录下，解压出来的目录为wps_symbol_fonts\n\ncd /usr/share/fonts/\nchmod 755 wps_symbol_fonts\ncd /usr/share/fonts/wps_symbol_fonts\nchmod 644 *\n\nmkfontdir\nmkfontscale\nfc-cache\n\n```\n\n* 安装为知笔记\n\n```\n\n$ sudo add-apt-repository ppa:wiznote-team\n$ sudo apt-get update\n$ sudo apt-get install wiznote\n\n```\n\n* 安装SSTP VPN协议\n\n```\n\n$ sudo add-apt-repository ppa:eivnaes/network-manager-sstp \n\n$ sudo apt-get update \n\n$ sudo apt-get install sstp-client \n\n$ sudo apt-get install network-manager-sstp-gnome\n\n```","tags":["Linux","Ubuntu"],"categories":["Linux"]}]